{"./":{"url":"./","title":"Introduction","keywords":"","body":"MySQL搬砖 目录 1.MySQL介绍与安装 2.MySQL的连接与权限 3.MySQL参数详解 4.MySQL体系介绍 5.MySQL的存储引擎 6.MySQL多实例 7.MySQL的SSL相关 8.MySQL的数据类型 9.表的创建 10.SQL之select 11.SQL之增删改 12.SQL其他补充 13.触发器存储过程函数 14.备份与恢复 15.备份恢复-pxb 16.基准测试 17.性能测试 18.主从复制 19.高可用选型介绍 20.优化 21.SQL优化 22.MySQL_FAQ 附录 附录1-三大软负载均衡器对比 附录2-MySQL5.7新特性 附录3-MySQL的sample数据库安装部署 附录4-MySQL优化框架 附录5-使用profile分析sql 附录6-mysqlcheck的使用 附录7-mha配置.md Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-29 17:48:29 "},"1.introduceandinstall.html":{"url":"1.introduceandinstall.html","title":"1.MySQL介绍与安装","keywords":"","body":" 一、MySQL版本的选择 二、官网介绍 1.官方网站： https://dev.mysql.com/ 2.企业版：略过 3.社区版介绍 4.MySQL文档 5.MySQL下载介绍 三、二进制方式的MySQL安装 1.下载二进制包 2.阅读官方的安装文档 3.安装依赖包 4.创建mysql用户和用户组 5.解压到指定的目录 6.配置数据库目录 7.配置my.cnf 8.初始化 9.配置服务 10.启动服务 11.配置环境变量 12.进行安全的配置 13.将时区导入mysql数据库 14.验证安装 参考 四、安装完成后要干的事情 五、my.cnf参数简要说明 1.常规部分 2.日志设定部分 3.复制部分 4.innodb专属部分 5. 5.7版本专属 六、其他 七、升级与降级 1.升级方法 2.升级路径 3.升级前的准备 4.升级步骤 降级步骤 八、常用工具 一、MySQL版本的选择 MySQL5.6以后，推荐采用官方的版本 percona：percona提供的工具集很多可以多多使用，但是还是用官方的吧 mariadb：无innodb；核心代码较老 二、官网介绍 1.官方网站： https://dev.mysql.com/ 2.企业版：略过 3.社区版介绍 MySQL Community Server： MySQL server MySQL Cluster： MySQL Cluster是一个实时的事务数据库，专为在高吞吐量条件下快速、始终开启数据访问而设计 MySQL Router ：轻量级的中间件，可在应用程序和任何后端MySQL服务器之间提供透明路由。 MySQL Shell：MySQL Shell是一个交互式Javascript，Python或SQL接口，支持MySQL服务器的开发和管理，并且是MySQL服务器的一个组件。 MySQL Workbench ：MySQL Workbench是新一代可视化数据库设计应用程序，可用于高效设计，管理和记录数据库模式。 MySQL Connectors：MySQL提供标准数据库驱动程序连接，以便将MySQL与具有与行业标准ODBC和JDBC兼容的应用程序和工具一起使用。 MySQL Utilities ：MySQL应用的程序包，新版本已经迁移到MySQL shell上面去了。 4.MySQL文档 https://dev.mysql.com/doc/ 离线文档下载： 5.MySQL下载介绍 推荐下载linux-generic的版本 source版本主要用来调试，自己编译对性能提升不明显而且耗时间 推荐使用5.6以上版本，现在8.0已经GA了，所以更要用高版本了！ 三、二进制方式的MySQL安装 1.下载二进制包 https://dev.mysql.com/downloads/mysql/ https://dev.mysql.com/downloads/mysql/5.7.html#downloads linux操作系统下,下载linux-generic 注意! 不要用自己编译的!直接用编译好的版本即可!!! 2.阅读官方的安装文档 大致的步骤如下: shell> groupadd mysql shell> useradd -r -g mysql -s /bin/false mysql shell> cd /usr/local shell> tar zxvf /path/to/mysql-VERSION-OS.tar.gz shell> ln -s full-path-to-mysql-VERSION-OS mysql shell> cd mysql shell> mkdir mysql-files shell> chown mysql:mysql mysql-files shell> chmod 750 mysql-files shell> bin/mysqld --initialize --user=mysql shell> bin/mysql_ssl_rsa_setup ## 5.6这一步是可选的,5.7是必需的! shell> bin/mysqld_safe --user=mysql & # Next command is optional shell> cp support-files/mysql.server /etc/init.d/mysql.server 5.6版本的过程是这样的，有些差别（初始化数据库的时候命令不一样） shell> groupadd mysql shell> useradd -r -g mysql -s /bin/false mysql shell> cd /usr/local shell> tar zxvf /path/to/mysql-VERSION-OS.tar.gz shell> ln -s full-path-to-mysql-VERSION-OS mysql shell> cd mysql shell> scripts/mysql_install_db --user=mysql shell> bin/mysqld_safe --user=mysql & # Next command is optional shell> cp support-files/mysql.server /etc/init.d/mysql.server 另外，在初始化的时候，可能会报错:FATAL ERROR: please install the following Perl modules before executing scripts/mysql_install_db: Data::Dumper 解决方法：安装包autoconf 卸载已经默认安装的包 shell> rpm -e --nodeps pks-name 3.安装依赖包 MySQL依赖于libaio 库。如果这个库没有在本地安装, 数据目录初始化和后续的服务器启动步骤将会失败。故需要先将这个包安装上去. shell> yum install libaio 4.创建mysql用户和用户组 shell> groupadd mysql shell> useradd -r -g mysql -s /bin/false mysql 因为只想让mysql用户仅用于运行mysql服务，而不是登录；此使用useradd -r和-s /bin/false的命令选项来创建对服务器主机没有登录权限的用户。 5.解压到指定的目录 shell> cd /usr/local shell> tar zxvf /path/to/mysql-VERSION-OS.tar.gz shell> ln -s full-path-to-mysql-VERSION-OS mysql 6.配置数据库目录 数据目录：/u01/mysql/mysql_data 参数文件my.cnf：/etc/my.cnf 错误日志log-error：/u01/mysql/log/mysql_error.log 二进制日志log-bin：/u01/mysql/log/mysql_bin.log 慢查询日志slow_query_log_file：/u01/mysql/log/mysql_slow_query.log shell> mkdir -p /u01/mysql/{mysql_data,log,mysql_undolog,mysql_redolog} shell> chown -R mysql.mysql /u01/mysql 注意: 建议在生产环境安装的时候,将data目录和日志目录单独存放,这样对升级较为方便,减少不必要的麻烦 另外一般来说,只有data目录的是mysql.mysql,其实是mysql.root 7.配置my.cnf my.cnf的内容,建议如下: [mysqld] ########basic settings######## server-id = 11 port = 3306 user = mysql #bind_address = 192.168.0.175 #autocommit = 0 character_set_server=utf8mb4 skip_name_resolve = 1 max_connections = 800 max_connect_errors = 1000 datadir = /u01/mysql/mysql_data/ transaction_isolation = READ-COMMITTED explicit_defaults_for_timestamp = 1 join_buffer_size = 134217728 tmp_table_size = 67108864 tmpdir = /tmp max_allowed_packet = 16777216 sql_mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER\" interactive_timeout = 1800 wait_timeout = 1800 read_buffer_size = 16777216 read_rnd_buffer_size = 33554432 sort_buffer_size = 33554432 ########log settings######## log_error = /u01/mysql/log/mysql_error.log slow_query_log = 1 slow_query_log_file = /u01/mysql/log/mysql_slow_query.log log_queries_not_using_indexes = 1 log_slow_admin_statements = 1 log_slow_slave_statements = 1 log_throttle_queries_not_using_indexes = 10 expire_logs_days = 90 long_query_time = 2 min_examined_row_limit = 100 ########replication settings######## master_info_repository = TABLE relay_log_info_repository = TABLE log_bin = bin.log sync_binlog = 1 gtid_mode = on enforce_gtid_consistency = 1 log_slave_updates binlog_format = row relay_log = relay.log relay_log_recovery = 1 binlog_gtid_simple_recovery = 1 slave_skip_errors = ddl_exist_errors ########innodb settings######## innodb_page_size = 8192 innodb_buffer_pool_size = 4G innodb_buffer_pool_instances = 8 innodb_buffer_pool_load_at_startup = 1 innodb_buffer_pool_dump_at_shutdown = 1 innodb_lru_scan_depth = 2000 innodb_lock_wait_timeout = 5 innodb_io_capacity = 4000 innodb_io_capacity_max = 8000 innodb_flush_method = O_DIRECT innodb_file_format = Barracuda innodb_file_format_max = Barracuda innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ innodb_undo_directory = /u01/mysql/mysql_undolog/ innodb_undo_logs = 128 innodb_undo_tablespaces = 3 innodb_flush_neighbors = 1 innodb_log_file_size = 1G #注意,生产环境建议调成4G+ innodb_log_buffer_size = 16777216 innodb_purge_threads = 4 innodb_large_prefix = 1 innodb_thread_concurrency = 64 innodb_print_all_deadlocks = 1 innodb_strict_mode = 1 innodb_sort_buffer_size = 67108864 ########semi sync replication settings######## plugin_dir=/usr/local/mysql/lib/plugin plugin_load = \"rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so\" loose_rpl_semi_sync_master_enabled = 1 loose_rpl_semi_sync_slave_enabled = 1 loose_rpl_semi_sync_master_timeout = 5000 [mysqld-5.7] innodb_buffer_pool_dump_pct = 40 innodb_page_cleaners = 4 innodb_undo_log_truncate = 1 innodb_max_undo_log_size = 2G innodb_purge_rseg_truncate_frequency = 128 binlog_gtid_simple_recovery=1 log_timestamps=system transaction_write_set_extraction=MURMUR32 show_compatibility_56=on 8.初始化 需要注意的一个地方是:5.7较5.6的改进和替换的脚本 5.7版本： bin/mysqld --initialize --user=mysql 5.6版本： scripts/mysql_install_db --user=mysql 5.7初始化的时候默认会给root用户生成一个随机的密码，可以在error.log日志中找到 shell> grep 'temporary password' /u01/mysql/log/mysql_error.log 如果不想要随机密码，而是和5.6一样采用免密码的方式，则需要在初始化的时候加上参数--initialize-insecure 生成ssl shell> bin/mysql_ssl_rsa_setup 9.配置服务 [root@nazeebo mysql]# cp support-files/mysql.server /etc/init.d/suremysql [root@nazeebo mysql]# chkconfig --add suremysql ##自启动 [root@nazeebo mysql]# chkconfig --list 从上面的命名可以看到，suremysql是自己命名的，所以生产上看需要来自定义 10.启动服务 [root@nazeebo mysql]# service suremysql start Starting MySQL... [ OK ] [root@nazeebo mysql]# ps -ef | grep mysql root 333 1 1 15:32 pts/2 00:00:00 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/u01/mysql/mysql_data/ --pid-file=/u01/mysql/mysql_data//nazeebo.pid mysql 1300 333 33 15:32 pts/2 00:00:01 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/u01/mysql/mysql_data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=/u01/mysql/log/mysql_error.log --pid-file=/u01/mysql/mysql_data//nazeebo.pid --port=3306 root 1345 32073 0 15:32 pts/2 00:00:00 grep mysql root 32697 32371 0 15:28 pts/3 00:00:00 tail -f mysql_error.log 注意：如果没有按照第9步去配置一个service，那么可以直接用 mysqld_safe --user=mysql & 来进行启动，mysqld_safe是一个守护进程 11.配置环境变量 在/etc/profile 中加入: export PATH=$PATH:/usr/local/mysql/bin 12.进行安全的配置 [root@nazeebo bin]# mysql_secure_installation Securing the MySQL server deployment. Enter password for user root: The existing password for the user account root has expired. Please set a new password. New password: Re-enter new password: VALIDATE PASSWORD PLUGIN can be used to test passwords and improve security. It checks the strength of password and allows the users to set only those passwords which are secure enough. Would you like to setup VALIDATE PASSWORD plugin? Press y|Y for Yes, any other key for No: y There are three levels of password validation policy: LOW Length >= 8 MEDIUM Length >= 8, numeric, mixed case, and special characters STRONG Length >= 8, numeric, mixed case, special characters and dictionary file Please enter 0 = LOW, 1 = MEDIUM and 2 = STRONG: 0 Using existing password for root. Estimated strength of the password: 100 Change the password for root ? ((Press y|Y for Yes, any other key for No) : no ... skipping. By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? (Press y|Y for Yes, any other key for No) : y Success. Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? (Press y|Y for Yes, any other key for No) : y Success. By default, MySQL comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? (Press y|Y for Yes, any other key for No) : y - Dropping test database... Success. - Removing privileges on test database... Success. Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? (Press y|Y for Yes, any other key for No) : y Success. All done! 注意:在MySQL5.7中修改密码用下面的SQL语句: sql> update mysql.user set authentication_string=password('123456') where user='root'; 或者: sql> SET PASSWORD = 'new passwd'; sql> SET PASSWORD = PASSWORD(‘new password’); #5.6的写法 13.将时区导入mysql数据库 shell> mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root -p mysql 说明:mysql内部有一个时区变量time_zone，会影响函数NOW()与CURTIME()的显示，而且会影响TIMESTAMP列的存储，因为TIMESTAMP列的值在存储时会从当前时区转换到UTC，取数据时再从UTC转换为当前时区。 time_zone的默认值时System，也可以设置为'+10:00' or '-8:00'.意思是与UTC的偏移一样。 如果需要设置为Europe/Helsinki', 'US/Eastern', or 'MET'.之类的名称，需要手动load数据到mysql的time zone information table,命令如上。 14.验证安装 [root@nazeebo bin]# mysqladmin version -u root -p Enter password: mysqladmin Ver 8.42 Distrib 5.7.21, for linux-glibc2.12 on x86_64 Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Server version 5.7.21-log Protocol version 10 Connection Localhost via UNIX socket UNIX socket /tmp/mysql.sock Uptime: 22 min 14 sec Threads: 1 Questions: 8648 Slow queries: 0 Opens: 121 Flush tables: 1 Open tables: 114 Queries per second avg: 6.482 参考 https://dev.mysql.com/doc/refman/5.7/en/binary-installation.html 四、安装完成后要干的事情 1.注意安装过程中的第12步“进行安全的配置” 2.修改root用户的默认密码 3.创建应用使用的用户 4.授予权限 五、my.cnf参数简要说明 下面列举一些重要的参数说明 1.常规部分 [mysqld] ########basic settings######## server-id = 11 //用于标识 port = 3306 //端口号 user = mysql //哪个用户 #bind_address = 192.168.0.175 #autocommit = 0 //是否自动提交事务，0代表不自动，1代表自动 character_set_server=utf8mb4 //字符集 skip_name_resolve = 1 max_connections = 800 max_connect_errors = 1000 datadir = /u01/mysql/mysql_data/ transaction_isolation = READ-COMMITTED explicit_defaults_for_timestamp = 1 join_buffer_size = 134217728 tmp_table_size = 67108864 tmpdir = /tmp max_allowed_packet = 16777216 sql_mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER\" interactive_timeout = 1800 wait_timeout = 1800 read_buffer_size = 16777216 read_rnd_buffer_size = 33554432 sort_buffer_size = 33554432 2.日志设定部分 ########log settings######## log_error = /u01/mysql/log/mysql_error.log slow_query_log = 1 slow_query_log_file = /u01/mysql/log/mysql_slow_query.log log_queries_not_using_indexes = 1 log_slow_admin_statements = 1 log_slow_slave_statements = 1 log_throttle_queries_not_using_indexes = 10 expire_logs_days = 90 long_query_time = 2 min_examined_row_limit = 100 3.复制部分 ########replication settings######## master_info_repository = TABLE relay_log_info_repository = TABLE log_bin = bin.log sync_binlog = 1 gtid_mode = on enforce_gtid_consistency = 1 log_slave_updates binlog_format = row relay_log = relay.log relay_log_recovery = 1 binlog_gtid_simple_recovery = 1 slave_skip_errors = ddl_exist_errors ########semi sync replication settings######## plugin_dir=/usr/local/mysql/lib/plugin plugin_load = \"rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so\" loose_rpl_semi_sync_master_enabled = 1 loose_rpl_semi_sync_slave_enabled = 1 loose_rpl_semi_sync_master_timeout = 5000 4.innodb专属部分 ########innodb settings######## innodb_page_size = 8192 innodb_buffer_pool_size = 4G innodb_buffer_pool_instances = 8 innodb_buffer_pool_load_at_startup = 1 innodb_buffer_pool_dump_at_shutdown = 1 innodb_lru_scan_depth = 2000 innodb_lock_wait_timeout = 5 innodb_io_capacity = 4000 innodb_io_capacity_max = 8000 innodb_flush_method = O_DIRECT innodb_file_format = Barracuda innodb_file_format_max = Barracuda innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ innodb_undo_directory = /u01/mysql/mysql_undolog/ innodb_undo_logs = 128 //建议提前规划好，后期改较为麻烦 innodb_undo_tablespaces = 3 //建议提前规划好，后期改较为麻烦 innodb_flush_neighbors = 1 innodb_log_file_size = 1G //注意,生产环境建议调成4G+ innodb_log_buffer_size = 16777216 innodb_purge_threads = 4 innodb_large_prefix = 1 innodb_thread_concurrency = 64 innodb_print_all_deadlocks = 1 innodb_strict_mode = 1 innodb_sort_buffer_size = 67108864 5. 5.7版本专属 [mysqld-5.7] innodb_buffer_pool_dump_pct = 40 innodb_page_cleaners = 4 innodb_undo_log_truncate = 1 innodb_max_undo_log_size = 2G innodb_purge_rseg_truncate_frequency = 128 binlog_gtid_simple_recovery=1 log_timestamps=system transaction_write_set_extraction=MURMUR32 show_compatibility_56=on 六、其他 有可能同一个系统下有多个my.cnf文件，所以my.cnf文件的读取顺序可以通过命令来查看 [root@nazeebo ~]# mysqld --help -vv|grep my.cnf /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf my.cnf, $MYSQL_TCP_PORT, /etc/services, built-in default 可以在mysql启动的时候加上 --defaults-files来指定配置文件； 如果没有指定的话，则会读取所有的my.cnf文件中的配置，如果有相同的项，则会覆盖之前的值 七、升级与降级 一般来说，建议数据文件(datadir所对应的位置)的存放位置和MySQL的相关二进制文件位置分开，这样方便对数据库做版本的升级和降级。 1.升级方法 就地升级：关闭旧的MySQL版本，用新版本替换旧的MySQL二进制文件或包，在现有的数据目录下重新启动MySQL，并运行 mysql_upgrade。 逻辑升级：使用 mysqldump从旧的MySQL版本导出现有数据 ，安装新的MySQL版本，将转储文件加载到新的MySQL版本，并运行 mysql_upgrade。 2.升级路径 仅在通用可用性（GA）版本之间支持升级。 支持从MySQL 5.6升级到5.7。在升级到下一个版本之前，建议升级到最新版本。例如，在升级到MySQL 5.7之前升级到最新的MySQL 5.6版本。 不支持跳过版本的升级。例如，不支持从MySQL 5.5直接升级到5.7。 支持发布系列中的升级。例如，从MySQL 5.7.x到5.7.y被支持。跳过发布也支持。例如，从MySQL 5.7.x到5.7.z。 3.升级前的准备 在升级之前，创建当前数据库和日志文件的备份。备份应包含mysql系统数据库，其中包含MySQL系统表。 查看 release note，其中提供了有关MySQL 5.7中新增功能的信息，或与老版本中的功能不同，其中一些更改可能导致不兼容。 参阅 MySQL 5.7中删除的功能。如果使用其中任何一项功能，升级需要对这些功能进行更改。 参阅MySQL 5.7中添加，弃用或删除服务器和状态变量和选项。如果使用这些项目中的任何一项，则升级需要进行配置更改。 参阅影响升级到MySQL 5.7的更改。注意在升级之前或之后可能需要采取操作的更改。 参阅升级复制设置 如果使用了分布式事务InnoDB，XA RECOVER在升级之前运行以检查未提交的XA事务。如果返回结果，则通过发出XA COMMIT或 XA ROLLBACK声明来提交或回滚XA事务。 建议在安装或升级到新的MySQL版本时重建和重新安装MySQL语言界面。这适用于MySQL接口，例如PHP mysql扩展，Perl DBD::mysql模块和Python MySQLdb模块。 4.升级步骤 下面将展示一个简单的升级过程，目标是将5.6.40升级到5.7.22。 大致步骤如下： 安全的停库 去掉mysql的软link 用新的版本link mysql (这个类似Oracle的数据库软件升级) 修改相应的my.cnf配置文件 启动mysql服务 查看mysql的err log upgrade系统表 (这个类似Oracle的数据库实例升级) 4.1 环境： //软件 [root@nazeebo local]# ll |grep mysql lrwxrwxrwx 1 root root 35 Jun 13 14:09 mysql -> mysql-5.6.40-linux-glibc2.12-x86_64 drwxr-xr-x 13 root root 4096 Jun 13 14:23 mysql-5.6.40-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 328563044 Feb 26 20:10 mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz -rw-r--r-- 1 root root 643790848 Mar 4 21:18 mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz //版本 [root@nazeebo local]# mysqladmin version -u root -p Enter password: mysqladmin Ver 8.42 Distrib 5.6.40, for linux-glibc2.12 on x86_64 Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Server version 5.6.40-log Protocol version 10 Connection Localhost via UNIX socket UNIX socket /tmp/mysql.sock Uptime: 20 min 55 sec Threads: 2 Questions: 10 Slow queries: 0 Opens: 70 Flush tables: 1 Open tables: 63 Queries per second avg: 0.007 [root@nazeebo local]# 4.2 安全地停库 [root@nazeebo local]# systemctl stop suremysql [root@nazeebo log]# tail -f /u01/mysql/log/mysql_error.log 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'CSV' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'MEMORY' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'MRG_MYISAM' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'MyISAM' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'sha256_password' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'mysql_old_password' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'mysql_native_password' 2018-06-13 14:53:34 23144 [Note] Shutting down plugin 'binlog' 2018-06-13 14:53:34 23144 [Note] /usr/local/mysql/bin/mysqld: Shutdown complete 4.3 unlink mysql [root@nazeebo local]# unlink mysql [root@nazeebo local]# ll total 949620 drwxr-xr-x 5 root root 4096 Jun 13 11:42 aegis drwxr-xr-x. 2 root root 4096 Nov 5 2016 bin drwxr-xr-x. 2 root root 4096 Nov 5 2016 etc drwxr-xr-x. 2 root root 4096 Nov 5 2016 games drwxr-xr-x. 2 root root 4096 Nov 5 2016 include drwxr-xr-x. 2 root root 4096 Nov 5 2016 lib drwxr-xr-x. 2 root root 4096 Nov 5 2016 lib64 drwxr-xr-x. 2 root root 4096 Nov 5 2016 libexec drwxr-xr-x 13 root root 4096 Jun 13 14:23 mysql-5.6.40-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 328563044 Feb 26 20:10 mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz -rw-r--r-- 1 root root 643790848 Mar 4 21:18 mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz drwxr-xr-x. 2 root root 4096 Nov 5 2016 sbin drwxr-xr-x. 6 root root 4096 Jun 13 11:42 share drwxr-xr-x. 2 root root 4096 Nov 5 2016 src 4.4 链接新的版本目录为mysql [root@nazeebo local]# ln -s mysql-5.7.22-linux-glibc2.12-x86_64 mysql [root@nazeebo local]# ll total 949624 drwxr-xr-x 5 root root 4096 Jun 13 11:42 aegis drwxr-xr-x. 2 root root 4096 Nov 5 2016 bin drwxr-xr-x. 2 root root 4096 Nov 5 2016 etc drwxr-xr-x. 2 root root 4096 Nov 5 2016 games drwxr-xr-x. 2 root root 4096 Nov 5 2016 include drwxr-xr-x. 2 root root 4096 Nov 5 2016 lib drwxr-xr-x. 2 root root 4096 Nov 5 2016 lib64 drwxr-xr-x. 2 root root 4096 Nov 5 2016 libexec lrwxrwxrwx 1 root root 35 Jun 13 14:57 mysql -> mysql-5.7.22-linux-glibc2.12-x86_64 drwxr-xr-x 13 root root 4096 Jun 13 14:23 mysql-5.6.40-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 328563044 Feb 26 20:10 mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz drwxr-xr-x 9 root root 4096 Jun 13 14:56 mysql-5.7.22-linux-glibc2.12-x86_64 -rw-r--r-- 1 root root 643790848 Mar 4 21:18 mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz drwxr-xr-x. 2 root root 4096 Nov 5 2016 sbin drwxr-xr-x. 6 root root 4096 Jun 13 11:42 share drwxr-xr-x. 2 root root 4096 Nov 5 2016 src [root@nazeebo local]# 注意此时只是软件的版本升级到了5.7.22，而之间建立好的数据库本身还是在5.6 4.5 启动mysql数据库 因为只是重新链接了mysql的目录到新的版本上，所以环境变量、服务之类的不需要变更 [root@nazeebo local]# systemctl start suremysql 4.6 查看mysql的error日志 这个时候在mysql的error日志中会发现有大量的报错，我们接下来需要upgrade数据字典 2018-06-13T15:00:18.514744+08:00 0 [ERROR] Native table 'performance_schema'.'replication_group_member_stats' has the wrong structure 2018-06-13T15:00:18.514765+08:00 0 [ERROR] Native table 'performance_schema'.'prepared_statements_instances' has the wrong structure 2018-06-13T15:00:18.514791+08:00 0 [ERROR] Native table 'performance_schema'.'user_variables_by_thread' has the wrong structure 2018-06-13T15:00:18.514818+08:00 0 [ERROR] Native table 'performance_schema'.'status_by_account' has the wrong structure 2018-06-13T15:00:18.514844+08:00 0 [ERROR] Native table 'performance_schema'.'status_by_host' has the wrong structure 2018-06-13T15:00:18.514865+08:00 0 [ERROR] Native table 'performance_schema'.'status_by_thread' has the wrong structure 2018-06-13T15:00:18.514885+08:00 0 [ERROR] Native table 'performance_schema'.'status_by_user' has the wrong structure 2018-06-13T15:00:18.514905+08:00 0 [ERROR] Native table 'performance_schema'.'global_status' has the wrong structure 2018-06-13T15:00:18.514923+08:00 0 [ERROR] Native table 'performance_schema'.'session_status' has the wrong structure 2018-06-13T15:00:18.514940+08:00 0 [ERROR] Native table 'performance_schema'.'variables_by_thread' has the wrong structure 2018-06-13T15:00:18.514969+08:00 0 [ERROR] Native table 'performance_schema'.'global_variables' has the wrong structure 2018-06-13T15:00:18.514990+08:00 0 [ERROR] Native table 'performance_schema'.'session_variables' has the wrong structure 2018-06-13T15:00:18.515103+08:00 0 [ERROR] Incorrect definition of table mysql.db: expected column 'User' at position 2 to have type char(32), found type char(16). 2018-06-13T15:00:18.515124+08:00 0 [ERROR] mysql.user has no `Event_priv` column at position 28 2018-06-13T15:00:18.515265+08:00 0 [ERROR] Event Scheduler: An error occurred when initializing system tables. Disabling the Event Scheduler. 2018-06-13T15:00:18.515461+08:00 0 [Note] /usr/local/mysql/bin/mysqld: ready for connections. Version: '5.7.22-log' socket: '/tmp/mysql.sock' port: 3306 MySQL Community Server (GPL) 另外，此时进去看database的列表 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | test | +--------------------+ 4 rows in set (0.00 sec) 发现5.7的sys库还没有安装上 4.7 upgrade系统表 [root@nazeebo local]# mysql_upgrade -s -p Enter password: The --upgrade-system-tables option was used, databases won't be touched. Checking if update is needed. Checking server version. Running queries to upgrade MySQL server. Upgrading the sys schema. Upgrade process completed successfully. Checking if update is needed. 注意，参数-s 一定要加，代表的是只更新系统表，不会去更新数据表 如果不加-s参数，则会将库里面的所有表都是5.7.22的方式重新创建一次，生产环境慎用！ 因为数据文件是二进制的，所以无需升级 唯一不需要加-s参数的时候是：对一些老版本的存储格式需要新的特性来提升性能的时候 完成upgrade之后，再进去查询版本和库的列表 [root@nazeebo local]# mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 5 Server version: 5.7.22-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) mysql> select version(); +------------+ | version() | +------------+ | 5.7.22-log | +------------+ 1 row in set (0.00 sec) 发现已经多出了5.7专有的sys库，以及版本以及变更为5.7.22 最后，我们再查询一下error日志，看是否还有报错等待去解决。 降级步骤 与升级的步骤类似，最后的upgrade，替换为执行一段downgrade的脚本，来让系统表回到指定的版本去 八、常用工具 workbench的使用 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:33:58 "},"2.connectandrole.html":{"url":"2.connectandrole.html","title":"2.MySQL的连接与权限","keywords":"","body":" 一、MySQL的连接方式 1.密码登陆 2.免密码登陆 二、MySQL权限详解 1.MySQL的权限的定义 2.权限管理 3.权限在MySQL数据库中的验证流程: 4.日常操作示例 三、MySQL中的rbac模型 1.角色的定义 2.模拟角色操作 一、MySQL的连接方式 1.密码登陆 默认使用root用户 mysql -p 适用于本地socket连接 mysql -S /tmp/mysql.sock -uroot -pxxx 适用任何远程方式连接，前提是在mysql.user表中已经有这个记录了 mysql -uxxx -pxxx -hxxx 要注意一个localhost，127.0.0.1，空用户的问题 2.免密码登陆 方法1：my.cnf中增加[client] 的标签 对定义不同的客户端 [mysql] 这个是属于/usr/local/mysql/bin/mysql二进制那个程序使用的 user=\"root\" password=\"密码\" [mysqladmin] 这个是属于/usr/local/mysql/bin/mysqladmin二进制那个程序使用的 user=\"root\" password=\"密码\" 每个不同的客户端使用不同的密码，而当使用了[client]标签则可以统一使用1个密码 [client] user=\"root\" password=\"密码\" 方法2：使用login-path 1.根据用户名和密码生成login-path的别名 [root@nazeebo ~]# mysql_config_editor set -G login-path-test -S /tmp/mysql.sock -uroot -p Enter password: [root@nazeebo ~]# 2.打印输出所有的login-path [root@nazeebo ~]# mysql_config_editor print --all [login-path-test] user = root password = ***** socket = /tmp/mysql.sock 3.使用login-path登陆，这个时候就不需要输入用户名和密码了 [root@nazeebo ~]# mysql --login-path=login-path-test Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 759 Server version: 5.7.22-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> 4.login-path的存放位置在~/.mylogin.cnf [root@nazeebo ~]# ls ~/.mylogin.cnf /root/.mylogin.cnf [root@nazeebo ~]# more ~/.mylogin.cnf [root@nazeebo ~]# 方法3：类似方案1使用[client]，在home目录下创建~/.my.cnf cat ~/.my.cnf [client] user=\"root\" password=\"密码\" 二、MySQL权限详解 1.MySQL的权限的定义 一个完整的用户标识 = 用户名+IP 假设一台主机的ip地址为192.168.0.2 sure@localhost sure@127.0.0.1 sure@192.168.0.2 以上三个用户标识是不同的三个用户标识，虽然它们所指的是同一个主机 2.权限管理 2.1 系统表权限信息 相关数据字典 mysql.user //全局所有库的权限 mysql.db //指定库的权限 mysql.tbale_priv //指定表的权限 mysql.column_priv //指定列的权限 desc table_name //查看表结构的定义 2.2 常用权限 SQL语句：select、insert、update、delete、index 存储过程：create routine、alter routine、execute、trigger 管理权限：super、reload、show database、shutdown 查看所有的权限，链接： https://dev.mysql.com/doc/refman/5.7/en/privileges-provided.html 2.3 显示当前用户的权限 show grants; show grants for current_user; show grants for current_user(); 2.4 配置可选资源 2.4.1 MAX_QUERIES_PER_HOUR 用来限制用户每小时运行的查询数量 mysql> grant select on *.* to 'sure'@'%' identified by '123456' with max_queries_per_hour 5; Query OK, 0 rows affected (0.00 sec) mysql> select user(); +----------------+ | user() | +----------------+ | sure@127.0.0.1 | +----------------+ 1 row in set (0.00 sec) ...... ...... 当执行到第6次的时候，就报错： mysql> select user(); ERROR 1226 (42000): User 'sure' has exceeded the 'max_questions' resource (current value: 5) mysql> 2.4.2 MAX_UPDATES_PER_HOUR 用来限制用户每小时的修改数据库数据的数量。 mysql> grant select on *.* to 'sure'@'%' with max_updates_per_hour 5; Query OK, 0 rows affected (0.00 sec) 2.4.3 MAX_CONNECTIONS_PER_HOUR 用来限制用户每小时打开新连接的数量。 mysql> grant select on *.* to 'sure'@'%' with max_connections_per_hour 5; Query OK, 0 rows affected (0.00 sec) 2.4.4 MAX_USER_CONNECTIONS 用来限制有多少用户连接MYSQL服务器 mysql> grant select on *.* to 'sure'@'%' with max_user_connections 2; Query OK, 0 rows affected (0.00 sec) 2.4.5 计数清0 想将所有账户当前的记数重设为0，可以执行FLUSH USER_RESOURCES语句。还可以通过重载授权表来重设记数。 mysql> flush user_resources; 3.权限在MySQL数据库中的验证流程: 用户名和ip是否被允许 查看mysql.user表 查看mysql.db表 查看mysql.table_priv表 查看mysql.column_priv表 权限的相关建议： 删除所有用户名为空的账户 不允许密码为空的永不存在 管理员账号可以给所有库权限 开发应用账户只需要给相应库的权限 4.日常操作示例 4.1 创建用户及授权 //创建一个叫用户标识 'nazeebo'@'127.0.0.1'，密码为123456 mysql> create user 'nazeebo'@'127.0.0.1' identified by '123456'; Query OK, 0 rows affected (0.00 sec) //授权 'nazeebo'@'127.0.0.1'用户 mysql库下面表的所有权限，如果是所有库则用*.* mysql> grant all on mysql.* to 'nazeebo'@'127.0.0.1' ; Query OK, 0 rows affected (0.01 sec) //grant会先搜索用户'nazeebo'@'127.0.0.1' 是否存在，不存在则先创建，如果不带identified则密码为空；之后再授权 mysql> grant all on mysql.* to 'nazeebo'@'127.0.0.1' identified by '123456'; Query OK, 0 rows affected, 1 warning (0.01 sec) //会发现有个warning，查看后意思是建议用create+grant的方式来代替grant创建用户 mysql> show warnings; +---------+------+------------------------------------------------------------------------------------------------------------------------------------+ | Level | Code | Message | +---------+------+------------------------------------------------------------------------------------------------------------------------------------+ | Warning | 1287 | Using GRANT for creating new user is deprecated and will be removed in future release. Create new user with CREATE USER statement. | +---------+------+------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) //创建一个用户'lowa'以及所有的192.168.0.x的网段，密码为123456，它可以对所有库的表都有操作权限，并且它有给其他用户授权的权限 mysql> grant all privileges on *.* to 'lowa'@'192.168.0.%' identified by '123456' with grant option; Query OK, 0 rows affected, 1 warning (0.00 sec) 4.2 查看一个用户的权限 mysql> show grants for 'lowa'@'192.168.0.%'; +-----------------------------------------------------------------------+ | Grants for lowa@192.168.0.% | +-----------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO 'lowa'@'192.168.0.%' WITH GRANT OPTION | +-----------------------------------------------------------------------+ 1 row in set (0.00 sec) 4.3 回收权限 revoke关键字只回收权限，并不删除用户 语法用grant， to改为from mysql> revoke ALL PRIVILEGES ON *.* from 'lowa'@'192.168.0.%'; Query OK, 0 rows affected (0.00 sec) mysql> show grants for 'lowa'@'192.168.0.%'; +--------------------------------------------------------------+ | Grants for lowa@192.168.0.% | +--------------------------------------------------------------+ | GRANT USAGE ON *.* TO 'lowa'@'192.168.0.%' WITH GRANT OPTION | +--------------------------------------------------------------+ 1 row in set (0.00 sec) mysql> 4.MySQL权限信息 mysql> select * from mysql.user where user='sure'\\G *************************** 1. row *************************** Host: % User: sure Select_priv: Y // Insert_priv: N Update_priv: N Delete_priv: N Create_priv: N Drop_priv: N Reload_priv: N Shutdown_priv: N Process_priv: N File_priv: N Grant_priv: N References_priv: N Index_priv: N Alter_priv: N Show_db_priv: N Super_priv: N Create_tmp_table_priv: N Lock_tables_priv: N Execute_priv: N Repl_slave_priv: N Repl_client_priv: N Create_view_priv: N Show_view_priv: N Create_routine_priv: N Alter_routine_priv: N Create_user_priv: N Event_priv: N Trigger_priv: N Create_tablespace_priv: N ssl_type: ssl_cipher: x509_issuer: x509_subject: max_questions: 5 max_updates: 5 max_connections: 5 max_user_connections: 2 plugin: mysql_native_password authentication_string: *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 password_expired: N password_last_changed: 2018-06-13 16:47:49 password_lifetime: NULL account_locked: N 1 row in set (0.01 sec) 三、MySQL中的rbac模型 1.角色的定义 role和Oracle数据库的role类似，批量的对用户进行管理，同一个role下的所有用户的权限一样。 MySQL 5.7版本通过mysql.proxies_prvi来实现 2.模拟角色操作 1.首先创建一个用户select_role_group，当成role mysql> create user 'select_role_group'@'%' identified by '123456'; Query OK, 0 rows affected (0.00 sec) 2.创建2个用户 yeye和nainai mysql> create user 'yeye'@'%' identified by '123456'; Query OK, 0 rows affected (0.01 sec) mysql> create user 'nainai'@'%' identified by '123456'; Query OK, 0 rows affected (0.01 sec) 3.将select_role_group的权限映射给yeye和nainai mysql> grant proxy on 'select_role_group'@'%' to 'yeye'@'%'; Query OK, 0 rows affected (0.01 sec) mysql> grant proxy on 'select_role_group'@'%' to 'nainai'@'%'; Query OK, 0 rows affected (0.00 sec) 4.授予select_role_group查询的权限 mysql> grant select on *.* to 'select_role_group'@'%'; Query OK, 0 rows affected (0.00 sec) 5.查看select_role_group、yeye、nainai的权限 mysql> show grants for 'select_role_group'@'%'; +------------------------------------------------+ | Grants for select_role_group@% | +------------------------------------------------+ | GRANT SELECT ON *.* TO 'select_role_group'@'%' | +------------------------------------------------+ 1 row in set (0.00 sec) mysql> show grants for 'yeye'@'%'; +------------------------------------------------------+ | Grants for yeye@% | +------------------------------------------------------+ | GRANT USAGE ON *.* TO 'yeye'@'%' | | GRANT PROXY ON 'select_role_group'@'%' TO 'yeye'@'%' | +------------------------------------------------------+ 2 rows in set (0.00 sec) mysql> show grants for 'nainai'@'%'; +--------------------------------------------------------+ | Grants for nainai@% | +--------------------------------------------------------+ | GRANT USAGE ON *.* TO 'nainai'@'%' | | GRANT PROXY ON 'select_role_group'@'%' TO 'nainai'@'%' | +--------------------------------------------------------+ 2 rows in set (0.00 sec) 6.查看相应的数据字典的信息 mysql> select * from mysql.proxies_priv; +-----------+--------+--------------+-------------------+------------+----------------+---------------------+ | Host | User | Proxied_host | Proxied_user | With_grant | Grantor | Timestamp | +-----------+--------+--------------+-------------------+------------+----------------+---------------------+ | localhost | root | | | 1 | | 2018-06-13 14:24:39 | | nazeebo | root | | | 1 | | 2018-06-13 14:24:39 | | % | yeye | % | select_role_group | 0 | root@localhost | 0000-00-00 00:00:00 | | % | nainai | % | select_role_group | 0 | root@localhost | 0000-00-00 00:00:00 | +-----------+--------+--------------+-------------------+------------+----------------+---------------------+ 4 rows in set (0.00 sec) mysql> exit Bye 7.以yeye为例登陆数据库进行查询测试 [root@nazeebo ~]# mysql -uyeye -p -h127.0.0.1 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 36 Server version: 5.7.22-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> select user(); +----------------+ | user() | +----------------+ | yeye@127.0.0.1 | +----------------+ 1 row in set (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) 在这个地方可以看到可以有mysql库的查询权限 mysql> select user,host from mysql.user; +-------------------+-------------+ | user | host | +-------------------+-------------+ | nainai | % | | select_role_group | % | | sure | % | | system | % | | yeye | % | | nazeebo | 127.0.0.1 | | root | 127.0.0.1 | | lowa | 192.168.0.% | | root | ::1 | | | localhost | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | | | nazeebo | | root | nazeebo | +-------------------+-------------+ 15 rows in set (0.00 sec) 在这可以看到因为只授权了select的权限，所以create database的时候会报错 mysql> create database dandan; ERROR 1044 (42000): Access denied for user 'select_role_group'@'%' to database 'dandan' mysql> Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:33:52 "},"3.parameterintro.html":{"url":"3.parameterintro.html","title":"3.MySQL参数详解","keywords":"","body":" 一、参数的查看、分类及修改 1.分类 2.查看show variables 3.修改参数 3.1 设置全局参数： 3.2 设置session参数： 3.3 有些参数既是global的也是session的，可以用如下sql查看 二、参数详解 1.基本设置的相关参数 server-id port = 3306 user = mysql bind_address autocommit character_set_server skip_name_resolve skip_networking max_connections max_connect_errors datadir transaction_isolation explicit_defaults_for_timestamp join_buffer_size tmp_table_size tmpdir net_buffer_length max_allowed_packet sql_mode interactive_timeout wait_timeout read_buffer_size read_rnd_buffer_size sort_buffer_size lower_case_table_names 2.日志有关的参数 log_error slow_query_log slow_query_log_file long_query_time log_queries_not_using_indexes log_slow_admin_statements log_slow_slave_statements log_throttle_queries_not_using_indexes expire_logs_day min_examined_row_limit 3.复制设置有关的参数 master_info_repository relay_log_info_repository log_bin sync_binlog gtid_mode enforce_gtid_consistency log_slave_updates binlog_format relay_log relay_log_recovery binlog_gtid_simple_recovery slave_skip_errors 4.innodb相关参数 innodb_page_size innodb_buffer_pool_size innodb_buffer_pool_instances 热数据加载的两个参数 innodb_data_file_path innodb_lru_scan_depth innodb_lock_wait_timeout innodb_io_capacity innodb_io_capacity_max innodb_flush_method innodb_file_per_table innodb_file_format_check innodb_file_format innodb_file_format_max innodb_log_group_home_dir innodb_undo_directory innodb_undo_logs innodb_undo_tablespaces innodb_flush_neighbors innodb_log_file_size innodb_log_buffer_size innodb_purge_threads innodb_large_prefix innodb_thread_concurrency innodb_print_all_deadlocks innodb_strict_mode innodb_sort_buffer_size innodb_flush_log_at_trx_commit 5.半同步设置有关参数 6.MySQL 5.7特性有关参数 innodb_buffer_pool_dump_pct innodb_page_cleaners innodb_undo_log_truncate innodb_max_undo_log_size innodb_purge_rseg_truncate_frequency binlog_gtid_simple_recovery log_timestamps transaction_write_set_extraction show_compatibility_56 一、参数的查看、分类及修改 1.分类 全局参数(GLOBAL) : 可以查看information_schema.GLOBAL_VARIABLES 与会话参数(session)：可以查看information_schema.SESSION_VARIABLES 可修改参数与不可修改参数 用户可以在线修改非只读参数，只读参数需要预先设置在配置文件中，重启后方能生效，有点类似于Oracle的pfile 所有在线修改的参数(global/session)重启后都会丢失 2.查看show variables 不加like则是显示全部 mysql> show variables like '%commit%'; +-----------------------------------------+-------+ | Variable_name | Value | +-----------------------------------------+-------+ | autocommit | ON | | binlog_group_commit_sync_delay | 0 | | binlog_group_commit_sync_no_delay_count | 0 | | binlog_order_commits | ON | | innodb_api_bk_commit_interval | 5 | | innodb_commit_concurrency | 0 | | innodb_flush_log_at_trx_commit | 1 | | slave_preserve_commit_order | OFF | +-----------------------------------------+-------+ 8 rows in set (0.00 sec) 3.修改参数 3.1 设置全局参数： mysql> set global max_connect_errors=20000; Query OK, 0 rows affected (0.00 sec) mysql> set max_connect_errors=20000; ERROR 1229 (HY000): Variable 'max_connect_errors' is a GLOBAL variable and should be set with SET GLOBAL mysql> 3.2 设置session参数： mysql> set NET_RETRY_COUNT=15; Query OK, 0 rows affected (0.00 sec) mysql> show variables like 'NET_RETRY_COUNT'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | net_retry_count | 15 | +-----------------+-------+ 1 row in set (0.00 sec) 3.3 有些参数既是global的也是session的，可以用如下sql查看 select * from information_schema.GLOBAL_VARIABLES a,information_schema.SESSION_VARIABLES b where a.VARIABLE_NAME=b.VARIABLE_NAME; 需要注意的是： 加global修改代表是全局，可以在其他session查询到修改的值 不加global修改代表是session，不能在其他session中查询到修改的值 二、参数详解 首先强调一下：myisam的相关参数基本可以不用管了，现在没有特殊理由一般都会是采用innodb作为存储引擎，另外生产环境建议关闭query cache，用nosql来代替。 因为参数众多，因此我拿my.cnf里面配置了的参数来重点说明 [mysqld] ########basic settings######## server-id = 11 port = 3306 user = mysql #bind_address = 192.168.0.175 #autocommit = 0 character_set_server=utf8mb4 skip_name_resolve = 1 max_connections = 800 max_connect_errors = 100000 datadir = /u01/mysql/mysql_data/ transaction_isolation = READ-COMMITTED explicit_defaults_for_timestamp = 1 join_buffer_size = 134217728 tmp_table_size = 67108864 tmpdir = /tmp max_allowed_packet = 16777216 sql_mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER\" interactive_timeout = 1800 wait_timeout = 1800 read_buffer_size = 16777216 read_rnd_buffer_size = 33554432 sort_buffer_size = 33554432 lower_case_table_names = 1 ########log settings######## log_error = /u01/mysql/log/mysql_error.log slow_query_log = 1 slow_query_log_file = /u01/mysql/log/mysql_slow_query.log log_queries_not_using_indexes = 1 log_slow_admin_statements = 1 log_slow_slave_statements = 1 log_throttle_queries_not_using_indexes = 10 expire_logs_days = 90 long_query_time = 2 min_examined_row_limit = 100 ########replication settings######## master_info_repository = TABLE relay_log_info_repository = TABLE log_bin = bin.log sync_binlog = 1 gtid_mode = on enforce_gtid_consistency = 1 log_slave_updates binlog_format = row relay_log = relay.log relay_log_recovery = 1 binlog_gtid_simple_recovery = 1 slave_skip_errors = ddl_exist_errors ########innodb settings######## innodb_page_size = 8192 innodb_buffer_pool_size = 4G innodb_buffer_pool_instances = 8 innodb_buffer_pool_load_at_startup = 1 innodb_buffer_pool_dump_at_shutdown = 1 innodb_lru_scan_depth = 2000 innodb_lock_wait_timeout = 5 innodb_io_capacity = 4000 innodb_io_capacity_max = 8000 innodb_flush_method = O_DIRECT innodb_file_format = Barracuda innodb_file_format_max = Barracuda innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ innodb_undo_directory = /u01/mysql/mysql_undolog/ innodb_undo_logs = 128 innodb_undo_tablespaces = 3 innodb_flush_neighbors = 1 innodb_log_file_size = 1G #注意,生产环境建议调成4G+ innodb_log_buffer_size = 16777216 innodb_purge_threads = 4 innodb_large_prefix = 1 innodb_thread_concurrency = 64 innodb_print_all_deadlocks = 1 innodb_strict_mode = 1 innodb_sort_buffer_size = 67108864 ########semi sync replication settings######## plugin_dir=/usr/local/mysql/lib/plugin plugin_load = \"rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so\" loose_rpl_semi_sync_master_enabled = 1 loose_rpl_semi_sync_slave_enabled = 1 loose_rpl_semi_sync_master_timeout = 5000 [mysqld-5.7] innodb_buffer_pool_dump_pct = 40 innodb_page_cleaners = 4 innodb_undo_log_truncate = 1 innodb_max_undo_log_size = 2G innodb_purge_rseg_truncate_frequency = 128 binlog_gtid_simple_recovery=1 log_timestamps=system transaction_write_set_extraction=MURMUR32 show_compatibility_56=on 根据上面的标签来 1.基本设置的相关参数 ########basic settings######## server-id = 11 port = 3306 user = mysql #bind_address = 192.168.0.175 #autocommit = 0 character_set_server=utf8mb4 skip_name_resolve = 1 max_connections = 800 max_connect_errors = 100000 datadir = /u01/mysql/mysql_data/ transaction_isolation = READ-COMMITTED explicit_defaults_for_timestamp = 1 join_buffer_size = 134217728 tmp_table_size = 67108864 tmpdir = /tmp max_allowed_packet = 16777216 sql_mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER\" interactive_timeout = 1800 wait_timeout = 1800 read_buffer_size = 16777216 read_rnd_buffer_size = 33554432 sort_buffer_size = 33554432 server-id MySQLl server唯一标示，一般以服务器IP的后两位就可以 在主从同步中使用 MySQL的同步的数据中是包含server-id的，用于标识该语句最初是从哪个server写入的，所以server-id一定要有的 每一个同步中的slave在master上都对应一个master线程，该线程就是通过slave的server-id来标识的；每个slave在master端最多有一个master线程，如果两个slave的server-id 相同，则后一个连接成功时，前一个将被踢掉。 这里至少有这么一种考虑：slave主动连接master之后，如果slave上面执行了slave stop；则连接断开，但是master上对应的线程并没有退出；当slave start之后，master不能再创建一个线程而保留原来的线程，那样同步就可能有问题； 在mysql做主主同步时，多个主需要构成一个环状，但是同步的时候有要保证一条数据不会陷入死循环，这里就是靠server-id来实现的。 port = 3306 MySQLl使用的端口 默认为3306 user = mysql 用户 bind_address bind_address = 192.168.0.175 绑定的IP地址 autocommit autocommit = 0 事务处理的自动提交模式。默认值为 1，因此自动提交功能是启用的，并且语句会立即生效。本质上，每条语句都是其自身的事务。将这个值设置为 0，可以禁用自动提交功能，如此一来，后续语句便只有等到提交完成（可以使用 COMMIT 语句，或者将 autocommit 设置为1来完成提交）之后才能生效。如果提交还未发生，则可以通过 ROLLBACK 来取消事务里的语句。将 autocommit 这时为1，可以重新启用自动提交（并且会隐式提交所有挂起的事务）。 character_set_server character_set_server=utf8mb4 服务器的默认字符集 一般和collation_server（服务器默认字符集所对应的默认排序方式，启动：直接设置；作用范围：全局、会话；动态）对应一样 skip_name_resolve skip_name_resolve = 1 此参数默认是禁用的。 启用它之后，可以禁止主机名解析，并且在权限表里必须通过IP地址或使用localhost来指定这些主机。 skip_networking 默认是禁用此参数，表示服务器允许使用TCP/IP连接。 如果启用它，则会禁用TCP/IP连接。客户端只可以从本地主机进行连接，且必须使用非TCP/IP接口。 Unix客户端可使用Unix套接字文件。 Windows客户端可以使用共享内存或命名管道（如果这些链接类型被弃用了的话）连接。 max_connections max_connections = 800 客户端连接的最大并发数。 默认值为151。 max_connect_errors max_connect_errors = 100000 默认值为10，也即mysqld线程没重新启动过，一台物理服务器只要连接 异常中断累计超过10次，就再也无法连接上mysqld服务，为此建议大家设置此值至少大于等于10W 一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况。 max_connect_errors的值与性能并无太大关系 mysqladmin flush-hosts命令来解锁已经被屏蔽的主机，参考状态参数Connect_errors_xxx。datadir datadir = /u01/mysql/mysql_data/ 数据文件目录 transaction_isolation transaction_isolation = READ-COMMITTED 默认为 REPEATABLE READ 事务隔离级别设置的不同，对二进制日志登记格式影响非常大 关于MySQL的事务处理及隔离级别：READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE explicit_defaults_for_timestamp explicit_defaults_for_timestamp = 1 MySQL 中有这样的一个默认行为，如果一行数据中某些列被更新了，如果这一行中有timestamp类型的列，那么这个timestamp列的数据也会被自动更新到 更新操作所发生的那个时间点；这个操作是由explicit_defaults_for_timestamp这个变更控制的。 explicit_defaults_for_timestamp 参数会直接影响表结构，也就是说explicit_defaults_for_timestamp的作用时间是在表定义的时候。 在MySQL 5.7版本之前，且在MySQL 5.6.6版本之后（explicit_defaults_for_timestamp参数在MySQL 5.6.6开始加入）的版本中，如果没有设置explicit_defaults_for_timestamp=1的情况下： 在默认情况下，如果TIMESTAMP列没有显示的指明null属性，那么该列会被自动加上not null属性（而其他类型的列如果没有被显示的指定not null，那么是允许null值的），如果往这个列中插入null值，会自动的设置该列的值为current timestamp值。 表中的第一个TIMESTAMP列，如果没有指定null属性或者没有指定默认值，也没有指定ON UPDATE语句。那么该列会自动被加上DEFAULT CURRENT_TIMESTAMP和ON UPDATE CURRENT_TIMESTAMP属性。 第一个TIMESTAMP列之后的其他的TIMESTAMP类型的列，如果没有指定null属性，也没有指定默认值，那么该列会被自动加上DEFAULT ‘0000-00-00 00:00:00’属性。如果insert语句中没有为该列指定值，那么该列中插入’0000-00-00 00:00:00’，并且没有warning。 在MySQL 5.6.6及以后的版本和MySQL 5.7之前的版本中，如果在配置文件中没有指定explicit_defaults_for_timestamp参数，启动时error日志中会报如下警告：[Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details). 如果在启动的时候在配置文件中指定了explicit_defaults_for_timestamp=1，MySQL会按照如下的方式处理TIMESTAMP列： 此时如果TIMESTAMP列没有显示的指定not null属性，那么默认的该列可以为null，此时向该列中插入null值时，会直接记录null，而不是current timestamp。 不会自动的为表中的第一个TIMESTAMP列加上DEFAULT CURRENT_TIMESTAMP和ON UPDATE CURRENT_TIMESTAMP属性，除非你在建表的时候显示的指明。 如果TIMESTAMP列被加上了not null属性，并且没有指定默认值。这时如果向表中插入记录，但是没有给该TIMESTAMP列指定值的时候，如果strict sql_mode被指定了，那么会直接报错。如果strict sql_mode没有被指定，那么会向该列中插入’0000-00-00 00:00:00’并且产生一个warning。 join_buffer_size join_buffer_size = 134217728 当join是all,index,rang或者Index_merge的时候使用的buffer 实际上这种join被称为FULL JOIN 实际上参与join的每一个表都需要一个join buffer 所以在join出现的时候，至少是2个表 join buffer的这只在mysql5.1.23版本之前最大为4G，但是从5.1.23版本开始，再出了windows之外的64为平台上可以超出4GB的限制 系统默认是128KB tmp_table_size tmp_table_size = 67108864 MySQL内部使用的各种临时表（即服务器在处理SQL语句的过程中自动创建的表）的最大允许长度。 如果某个临时表的长度超过了max_heap_table_size和tmp_table_size当中较小的那个值，那么服务器会把它从内部内存表转换为MyISAM表，保存到磁盘上。 如果有足够多的内存的话，那么增大此参数的值可以使服务器在内存里维护更大的临时表，而不必把它们转换为磁盘文件格式。 tmpdir tmpdir = /tmp 服务器用于创建临时文件的那个目录的路径名。 此参数的值可以是一个目录列表，它们将轮换着使用。 在Unix里，目录名之间使用冒号（:）隔开；在Windows里，目录名之间需要用分号（;）隔开。 net_buffer_length 它指的是服务器与客户端程序进行通信时使用的连接和结果缓冲区的初始大小 此缓冲区可以扩展到max_allowed_packet个字节大小 参数的取值范围是1KB~1MB 默认为16KB 会话值是只读的 max_allowed_packet max_allowed_packet = 16777216 服务器和客户之间通讯的使用的缓冲区长度 该缓冲区的初始大小为net_buffer_length个字节，但是会根据需要增大到max_allowed_packet个字节 这个值也会限制MySQL服务器所能处理的字符串的最大长度 此参数的默认值和最大值分别是1MB和1GB 它的会话值是只读的 sql_mode sql_mode = \"STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER\" 服务器的SQL模式。 这个参数将改变MySQL服务器的某些行为，使它更符合SQL语言标准或是与其他数据库服务器或老版本的MySQL服务器保持兼容。此参数的值应该是一个空串（这将清除以前设置的SQL模式）或者是由下面将要介绍的一个或多个模式值以逗号分隔而构成的一系列值。 自MySQL 5.6.6起，其默认值为NO_ENGINE_SUBSTITUTION；而对于之前的版本，其值为空串。 有些模式值很简单，它们可以单独使用以启用某种特定的行为。 其他的则是复合模式，每种复合SQL模式涵盖多种简单SQL模式，这使得用于可以方便地一次设置多种SQL模式。 模式值不区分大小写。 下面列出了一些简单的SQL模式值。 ALLOW_INVALID_DATES：在严格模式里，禁止对DATE和DATETIME值进行全面的日期有效性检查。唯一的要求是月份的取值范围必须为1~12，日期的取值范围必须为1到31。但是TIMASTAMP值是个例外：不管是否启用了这个SQL模式，它们都必须是有效的。 ANSI_QUOTES：把双引号自负解释为供标识符（如数据库名、表名和列名）使用的引号字符，而不是供字符串使用的引号字符。（不管这个模式是否启用，都可以用反引号来当作名字的引号字符。） ERROR_FOR_DIVISION_BY_ZERO：对于行插入或修改操作，即使是在严格模式下，以零为除数的出发（或求余数）运算得到的结果通常是NULL，且不会返回任何警告信息。启用ERROR_FOR_DIVISION_BY_ZERO模式将更改这种行为。如果没有启用严格模式，那么以零为除数时结果将为NULL值，但会返回一条警告信息；如果启用了严格模式，那么在执行INSERT或UPDATE语句期间遇到以零为除数的情况时，将产生一个错误，并且该语句会失败。如果想要禁止在插入或更新是出现错误，并且产生一个NULL值和警告信息，可以使用INSERT IGNORE或UPDATE IGNORE。 HIGH_NOT_PRECEDENCE：此模式可以更改NOT操作符的优先级，使其与！操作符的优先级相同。 IGNORE_SPACE：让服务器忽略内建函数名与引入参数表的那个左括号“（”之间的空格。默认情况下，那个左括号必须紧跟在函数名的后面，其中间不允许有间隔。此模式会使函数名被当作保留字。 NO_AUTO_CREATE_USER：防止GRANT语句创建不安全的新账户。也就是说，如果某个账户不存在，那么GRANT会执行失败，并且不会创建账户，除非该语句包含一个指定有非空密码的IDENTIFIED BY子句，或者包含有一个指定身份验证插件的IDENTIFIED WITH子句。 NO_AUTO_VALUE_ON_ZERO：通常情况下，把0插入一个AUTO_INCREMENT列，等效于插入NULL值：MySQL将自动生成下一个序列编号，并把它保存在该列里。如果启用了此模式，那么往AUTO_INCREMENT列里插入0将会把数字0存入该列。 NO_BACKSLASH_ESCAPES：如果启用了这个模式，那么反斜线字符（“\\”）将被当作一个没有特殊含义的普通字符，而不是当作一个字符串的转义字符。 NO_DIR_IN_CREATE：忽略CREATE TABLE和ALTER TABLE语句时，该模式所指定的存储引擎不可用——此时，这个模式便决定着服务器将如何处理它们。如果启用了此模式，那么会出现一个错误，并且该表不会被创建（或更改）。如果禁用了此模式，那么允许替换为默认的存储引擎。 NO_ZERO_DATE：在严格模式下，拒绝接收’0000-00-00’作为一个有效日期值通常情况下，MySQL允许存储“零”日期值。这个模式可以通过使用INSERT IGNORE语句代替INSERT语句的办法来覆盖。 NO_ZERO_IN_DATE：在严格模式下，拒绝接收月或日部分是零的日期值。（年份是零的日期值是允许的。）通常情况下，MySQL允许存储这样的日期值。在非严格模式下，或者如果用户发出的是INSERT IGNORE语句，MySQL将把这样的日期值保存为’0000-00-00’。 ONLY_FULL_GROUP_BY：通常情况下，MySQL允许SELECT语句的输出列列表里带有非聚合型列，或者使用不是列在GROUP BY子句里的HAVING子句。例如：select a,b,count(*) from t group by a; ONLY_FULL_GROUP_BY标志要求非聚合型输出列（或HAVING列）都被列在GROUP BY里：select a,b,count(*) from t group by a,b; PAD_CHAR_TO_FULL_LENGTH：通常情况下，服务器在检索CHAR列值时会删除其尾部空格。如果启用了这个模式，MySQL服务器将禁止删除CHAR列的尾部空格，这样，检索到的值的长度就等于列的定义宽度。 PIPES_AS_CONCAT：如果启用了这个模式，那么||将被解释为字符串连接操作符，而不会解释为逻辑或。 REAL_AS_FLOAT：如果启用了这个模式，那么数据类型REAL将于FLOAT同义，而不是等同于DOUBLE。 STRICT_ALL_TABLES：如果启用了这个模式，那么所有的存储引擎都将对输入数据做更严格的检查，这将导致MySQL拒绝接收绝大多数非法值。如果想要更加严格，可以使用TRADITIONAL模式。 STRICT_TRANS_TABLES：如果启用了这个模式，那么事务型存储引擎将输入数据值做严格的检查，这将导致MySQL拒绝接受绝大多数非法值。在此基础上，只要有可能（例如，遇到插入单个行的INSERT语句），非事务型存储引擎也将对输入数据做严格的检查。如果想要更加严格，可以使用TRADITIONAL模式。 下表列出的是复合SQL模式，以及每种复合模式所包含的模式内容。 复合模式 组成模式 ANSI ANSI_QUOTES, IGNORE_SPACE, PIPES_AS_CONCAT, REAL_AS_FLOAT DB2 ANSI_QUOTES, IGNORE_SPACE, NO_FIELD_OPTIONS, NO_KEY_OPTIONS, NO_TABLE_OOPTIONS, PEPES_AS_CONCAT MAXDB ANSI_QUOTES, IGNORE_SPACE, NO_AUTO_CREATE_USER, NO_FIELD_OPTIONS, NO_KEY_OPTIONS, NO_TABLE_OPTIONS, PEPES_AS_CONCAT MSSQL ANSI_QUOTES, IGNORE_SPACE, NO_FIELD_OPTIONS, NO_KEY_OPTIONS, NO_TABLE_OOPTIONS, PEPES_AS_CONCAT MYSQL323 HIGH_NOT_PRECEDENCE, NO_FIELD_OPTIONS MYSQL40 HIGH_NOT_PRECEDENCE, NO_FIELD_OPTIONS ORACLE ANSI_QUOTES, IGNORE_SPACE, NO_AUTO_CREATE_USER, NO_FIELD_OPTIONS, NO_KEY_OPTIONS, NO_TABLE_OPTIONS, PEPES_AS_CONCAT POSTGRESQL ANSI_QUOTES, IGNORE_SPACE, NO_FIELD_OPTIONS, NO_KEY_OPTIONS, NO_TABLE_OOPTIONS, PEPES_AS_CONCAT TRADITIONAL ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER, NO_ZERO_DATE, NO_ZERO_IN_DATE, STRICT_ALL_TABLES, STRICT_TRANS_TABLES 之所以称之为TRADITIONAL模式，是因为它启用这样的模式——它们使得MySQL在处理输入值时，可以表现得像那些会拒绝无效数据的传统数据库一样。它有点像严格模式，但是对于更加严格的检查又包含了几个附加的约束。 interactive_timeout interactive_timeout = 1800 交互模式下的没有操作后的超时时间，单位为秒。 wait_timeout wait_timeout = 1800 非交互模式的没有操作后的超时时间，单位为秒。 read_buffer_size read_buffer_size = 16777216 对表进行顺序扫描的那个线程所使用的缓存区的大小 缓冲区会根据每个客户端的需要进行分配read_rnd_buffer_size read_rnd_buffer_size = 33554432 在排序后，读取结果数据的缓冲区大小sort_buffer_size sort_buffer_size = 33554432 默认为256KB sort_buffer_size 是一个connection级参数，在每个connection（session）第一次需要使用这个buffer的时候，一次性分配设置的内存。 sort_buffer_size 并不是越大越好，由于是connection级的参数，过大的设置+高并发可能会耗尽系统内存资源。例如：500个连接将会消耗 500*sort_buffer_size(8M)=4G内存 当sort_buffer_size 超过2KB的时候，就会使用mmap() 而不是 malloc() 来进行内存分配，导致效率降低。 lower_case_table_names lower_case_table_names = 1 Linux或类Unix平台，对文件名称大小写敏感，也即对数据库、表、存储过程等对象名称大小写敏 感，为减少开发人员的开发成本，为此推荐大家设置该参数使对象名称都自动转换成小写；2.日志有关的参数 log_error = /u01/mysql/log/mysql_error.log slow_query_log = 1 slow_query_log_file = /u01/mysql/log/mysql_slow_query.log log_queries_not_using_indexes = 1 log_slow_admin_statements = 1 log_slow_slave_statements = 1 log_throttle_queries_not_using_indexes = 10 expire_logs_days = 90 long_query_time = 2 min_examined_row_limit = 100 log_error log_error = /u01/mysql/log/mysql_error.log 错误日志文件的名字 如果不设置此参数，服务器会吧出错信息输出到控制台中断 如果在服务器启动时指定了此参数，但未设置具体值，则日志文件名为数据目录里的HOSTNAME.err，其中，HOSTNAME为服务器主机的名字 如果其文件是以相对路径形式给出的，则服务器会将它解释为相对于数据目录 如果在指定文件名时没有带扩展名，mysqld会添加一个扩展名.err 非常重要的参数，重要性和Oracle的alert日志类似 slow_query_log slow_query_log = 1 用于指定是否要启用慢查询日志记录 如果要启用，则log_output参数会控制日志的输出目标 slow_query_log_file slow_query_log_file = /u01/mysql/log/mysql_slow_query.log 慢查询日志文件的名字 在启用了FILE日志目标时，会用到它 它的默认值是数据目录里的HOSTNAME-slow.log文件，其中，HOSTNAME是服务器主机的名字 如果其文件名是以相对路径形式给出的，则服务器会将它解释为相对于数据目录long_query_time 最小值和默认值分别为0和10。 此参数值的单位是秒 慢查询时间限度，超过这个限度，mysqld认为是一个慢查询 如果某个查询命令的执行时间大于了这个值（以及检查的记录会超过min_examined_row_limit行），则它也会被认为是一个“慢”查询，并且会导致状态参数slow_queries增加 如果已启用慢查询日志记录功能，则服务器会将该查询写入该日志 该值可以包含小数部分（即微秒）。 只有日志目标是一个文件，而不是mysql.slow_query表时，才会记录小数部分 log_queries_not_using_indexes log_queries_not_using_indexes = 1 如果运行的SQL语句没有使用索引，则mysql数据库同样会将这条SQL语句记录到慢查询日志文件中 为1时，会记录任何不使用索引的sql，而且会无视long_query_time参数 log_slow_admin_statements log_slow_admin_statements = 1 默认情况下不会记录DDL操作，不管执行时间多长，除非将log_slow_admin_statements参数设置为1，而这个参数只在5.6.11后支持log_slow_slave_statements log_slow_slave_statements=1 默认slave不会记录主库传过来的慢查询 当该参数为1时，会记录从库传过来的慢查询 log_throttle_queries_not_using_indexes log_throttle_queries_not_using_indexes = 10 在log_queries_not_using_indexes为1的情况下，默认没走索引的sql有多少就记录多少，而设置了log_throttle_queries_not_using_indexes为N后，表示1分钟内该SQL最多记录N条，这个参数在5.6.5后支持 expire_logs_day expire_logs_days = 90 默认为0 (不自动删除) 设置binlog自动删除过期时间，单位为天 MySQL服务器将自动删除在expire_logs_days天之前创建的日志文件，并更新该二进制日志的索引文件 MySQL服务器将在它每次启动以及每次打开一个新的二进制日志文件时执行这个到期检查 min_examined_row_limit min_examined_row_limit = 100 默认值为0 一个查询至少需要检查min_examined_row_limit个行才被允许记录到慢查询日志 3.复制设置有关的参数 ########replication settings######## master_info_repository = TABLE relay_log_info_repository = TABLE log_bin = on sync_binlog = 1 gtid_mode = on enforce_gtid_consistency = 1 log_slave_updates binlog_format = row relay_log = relay.log relay_log_recovery = 1 binlog_gtid_simple_recovery = 1 slave_skip_errors = ddl_exist_errors master_info_repository master_info_repository = TABLE 从服务器是将主服务器的日志信息写入文件，还是写入表 如果该值为FILE（默认值），则从服务器日志文件有—master-info-file选项指定 如果该值为TABLE，则服务器会把日志记录到mysql.slave_master_inro表中 此参数是在MySQL 5.6.2里引入的 relay_log_info_repository relay_log_info_repository = TABLE 从服务器是将中继日志信息写入文件，还是写入表 如果该值为FILE（默认值），那么从服务器会把日志记录到—relay-log-info-file选项所指定的文件里 如果该值为TABLE，那么服务器会把日志记录到mysql.slave_relay_log_info_file表里 此参数的在MySQL 5.6.2里引入的 log_bin log_bin = on 是否启用二进制日志记录功能 需要注意的是，--log-bin选项设置的是log_bin_basename，而非log_bin 发散一个： -- 查询bin-log是否开启 SHOW VARIABLES LIKE '%log_bin%'; -- 显示第一个bin-log的信息 SHOW BINLOG EVENTS; -- 获取bin-log列表 SHOW BINARY LOGS; -- 查询某个bin-log信息 SHOW BINLOG EVENTS IN 'bin-log.000001'; -- 查看mysql服务器下面bin-log二进制文件方法: mysqlbinlog /u01/mysql/log/BIN-log.000009 再来个实际的例子，瞬间明了： mysql> show variables like '%log_bin%'; +---------------------------------+---------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------+ | log_bin | ON | | log_bin_basename | /u01/mysql/mysql_data/bin | | log_bin_index | /u01/mysql/mysql_data/bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+---------------------------------+ 6 rows in set (0.00 sec) sync_binlog sync_binlog = 1 默认值为0 像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log N>0 ： 每向二进制日志文件写入N条SQL或N个事务后，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去 N=0 ： 不主动刷新二进制日志文件的数据到磁盘上，而是由操作系统决定； 如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。 一般与innodb_flush_log_at_trx_commit同时设置 推荐配置组合： N=1,1 — 适合数据安全性要求非常高，而且磁盘IO写能力足够支持业务，比如充值消费系统； N=1,0 — 适合数据安全性要求高，磁盘IO写能力支持业务不富余，允许备库落后或无复制； N=2,0或2,m(0 N=0,0 — 磁盘IO写能力有限，无复制或允许复制延迟稍微长点能接受，例如：日志性登记业务； gtid_mode gtid_mode = on GTID是MySQL 5.6的新特性，其全称是Global Transaction Identifier，可简化MySQL的主从切换以及Failover。GTID用于在binlog中唯一标识一个事务。当事务提交时，MySQL Server在写binlog的时候，会先写一个特殊的Binlog Event，类型为GTID_Event，指定下一个事务的GTID，然后再写事务的Binlog。主从同步时GTID_Event和事务的Binlog都会传递到从库，从库在执行的时候也是用同样的GTID写binlog，这样主从同步以后，就可通过GTID确定从库同步到的位置了。也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过File_name和File_position找点儿了。 GTID(Global Transaction ID)是对于一个已提交事务的编号，并且是一个全局唯一的编号。 GTID实际上是由UUID+TID组成的。其中UUID是一个MySQL实例的唯一标识。TID代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。下面是一个GTID的具体形式： 3E11FA47-71CA-11E1-9E33-C80AA9429562:23 配置方式为gtid_mode=ON/OFF gtid_mode的类型为枚举类型，枚举值可以为ON和OFF，所以应该通过ON或者OFF来控制gtid_mode，不要把它配置成0或者1，否则结果可能不符合预期 开启gtid_mode时，log-bin和log-slave-updates也必须开启，否则MySQL Server拒绝启动 除此以外，enforce-gtid-consistency也必须开启，否则MySQL Server也拒绝启动。enforce-gtid-consistency是因为开启grid_mode以后，许多MySQL的SQL和GTID是不兼容的，比如开启ROW 格式时，CREATE TABLE ... SELECT，在binlog中会形成2个不同的事务，GTID无法唯一。另外在事务中更新MyISAM表也是不允许的。 enforce_gtid_consistency enforce_gtid_consistency = 1 与gtid一起使用 开始该参数，保证数据的一致性 log_slave_updates log_slave_updates 与gtid一起使用 将master服务器上获取数据变更的信息记录到从服务器的二进制文件中 binlog_format binlog_format = row 二进制的日志记录格式。 其可取值包括：STATEMENT、ROW和MIXED，分别代表的是基于语句的日志记录格式、基于行的日志记录格式和混合型日志记录格式。 如果使用unhealthy格式，则MySQL服务器将根据具体情况在基于语句的和基于行的日志记录格式之间自动切换。默认格式为STATEMENT。 运行时，如果要更改此参数或者会话值，客户端必须拥有SUPER权限。 三种模式介绍： STATEMENT模式（SBR） 每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题) ROW模式（RBR） 不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。 MIXED模式（MBR） 以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。 建议采用row模式，因为： SBR 的缺点： 不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。 调用具有不确定因素的 UDF（user-defined functions） 时复制也可能出问题 使用以下函数的语句也无法被复制： LOAD_FILE() UUID() USER() FOUND_ROWS() SYSDATE() (除非启动时启用了 --sysdate-is-now 选项) INSERT ... SELECT 会产生比 RBR 更多的行级锁 复制需要进行全表扫描(WHERE 语句中没有使用到索引)的 UPDATE 时，需要比 RBR 请求更多的行级锁 对于有 AUTO_INCREMENT 字段的 InnoDB表而言，INSERT 语句会阻塞其他 INSERT 语句 对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 RBR 模式下，只会对那个发生变化的记录产生影响 存储函数(不是存储过程)在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事 确定了的 UDF 也需要在从服务器上执行 数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错 执行复杂语句如果出错的话，会消耗更多资源 RBR 的优点： 任何情况都可以被复制，这对复制来说是最安全可靠的 和其他大多数数据库系统的复制技术一样 多数情况下，从服务器上的表如果有主键的话，复制就会快了很多 复制以下几种语句时的行锁更少： INSERT ... SELECT 包含 AUTO_INCREMENT 字段的 INSERT 没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句 执行 INSERT，UPDATE，DELETE 语句时锁更少 从服务器上采用多线程来执行复制成为可能 当然ROW模式也有自己的缺点： binlog 大了很多 复杂的回滚时 binlog 中会包含大量的数据 主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题 UDF 产生的大 BLOB 值会导致复制变慢 无法从 binlog 中看到都复制了写什么语句 当在非事务表上执行一段堆积的SQL语句时，最好采用 SBR 模式，否则很容易导致主从服务器的数据不一致情况发生 relay_log relay_log = relay.log 中继日志文件的名字 relay_log_recovery relay_log_recovery = 1 默认是禁用的 此参数在从服务器崩溃之后非常有用 在启动时启用它，可以使从服务器删除所有的还未处理的中继日志，并再次从主服务器获取它们 binlog_gtid_simple_recovery binlog_gtid_simple_recovery = 1 影响GTID的一个参数: 5.7.6以下中默认simplified_binlog_gtid_recovery=false 5.7.6以上中默认binlog_gtid_simple_recovery=true slave_skip_errors slave_skip_errors = ddl_exist_errors 用于指定一个错误列表 在列表里的错误出现时，从服务器会忽略它们，而不是将复制过程挂起。（不过，与利用这个选项来忽略错误的做法相比，还是找出问题的根源并彻底解决更好。） 如果此参数的值为all，则会忽略所有的错误。 否则，此参数的值应该是以逗号分隔的一个或者多个出错编号。 4.innodb相关参数 ########innodb settings######## innodb_page_size = 8192 innodb_buffer_pool_size = 4G innodb_buffer_pool_instances = 8 innodb_buffer_pool_load_at_startup = 1 innodb_buffer_pool_dump_at_shutdown = 1 innodb_lru_scan_depth = 2000 innodb_lock_wait_timeout = 5 innodb_io_capacity = 4000 innodb_io_capacity_max = 8000 innodb_flush_method = O_DIRECT innodb_file_format = Barracuda innodb_file_format_max = Barracuda innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ innodb_undo_directory = /u01/mysql/mysql_undolog/ innodb_undo_logs = 128 innodb_undo_tablespaces = 3 innodb_flush_neighbors = 1 innodb_log_file_size = 1G #注意,生产环境建议调成4G+ innodb_log_buffer_size = 16777216 innodb_purge_threads = 4 innodb_large_prefix = 1 innodb_thread_concurrency = 64 innodb_print_all_deadlocks = 1 innodb_strict_mode = 1 innodb_sort_buffer_size = 67108864 innodb_page_size innodb_page_size = 8192 InnoDB表空间里的页面大小。 默认大小为16KB，允许值由4KB、8KB和16KB。 该设置只有在InnoDB初始化表空间的时候才会生效，因此应该在初始化MySQL之前，或者在删除并重新创建InnoDB表空间文件之前设置它。innodb_buffer_pool_size innodb_buffer_pool_size = 4G #建议调整为实际服务器内存大小的50--90% innodb最重要的一个参数！ innodb用它来缓存被访问过的表和索引文件，建议设置为物理内存的50%--90% 如果过多分配给数据库，有可能导致系统内存不够，出现swap或者oom的现象 5.7版本中已经可以在线修改 innodb_buffer_pool_instances innodb_buffer_pool_instances = 8 如果innodb_buffer_pool_size的值至少为1GB，则需要将InnoDB缓冲池划分为innodb_buffer_pool_instances个区域 默认值是1（单个缓冲池），最大值是64。表示innodb缓冲区可以划分为多个区域，可以理解为把innodb_buffer_pool划分为多个实例，提高并发性。 为达到最好的效果，需要对innodb_buffer_pool_size和innodb_buffer_pool_instances的值进行选择，以便每个实例都至少为1GB 在MySQL 5.5.4里引入的 通过show engine innodb status可以看到每个instance使用内存的情况只有当innodb_buffer_pool 大于1G的时候，这个参数才生效。 热数据加载的两个参数 innodb_buffer_pool_load_at_startup与 innodb_buffer_pool_dump_at_shutdown 当数据库宕机后，重启数据库后有可能感觉查询速度非常的慢。这个是因为数据还没有被buffer到缓冲区去，这样对IO的压力很大。如果要把热数据快速加载起来，需要开启下面2个参数： mysql> show variables like 'innodb_buffer_pool_load_at%'; +------------------------------------+-------+ | Variable_name | Value | +------------------------------------+-------+ | innodb_buffer_pool_load_at_startup | ON | +------------------------------------+-------+ 1 row in set (0.00 sec) mysql> show variables like 'innodb_buffer_pool_dump_at%'; +-------------------------------------+-------+ | Variable_name | Value | +-------------------------------------+-------+ | innodb_buffer_pool_dump_at_shutdown | ON | +-------------------------------------+-------+ 1 row in set (0.01 sec) mysql> show variables like 'innodb_buffer_pool_file%'; +-----------------------------+----------------+ | Variable_name | Value | +-----------------------------+----------------+ | innodb_buffer_pool_filename | ib_buffer_pool | +-----------------------------+----------------+ innodb_buffer_pool_dump_at_shutdown参数表示在数据库shutdown的时候把数据dump出来，保存到ib_buffer_pool文件中。当实例再次启动的时候，innodb_buffer_pool_load_at_startup表示把元数据快速的加载回内存。在这儿的元数据就是space number和page number的列表信息。 mysql> select space,page_number from information_schema.innodb_buffer_page limit 5; +-------+-------------+ | space | page_number | +-------+-------------+ | 0 | 7 | | 0 | 3 | | 0 | 2 | | 0 | 4 | | 0 | 11 | +-------+-------------+ 5 rows in set (0.70 sec) innodb_data_file_path mysql> show variables like 'innodb_data_file%'; +-----------------------+------------------------+ | Variable_name | Value | +-----------------------+------------------------+ | innodb_data_file_path | ibdata1:12M:autoextend | +-----------------------+------------------------+ 1 row in set (0.01 sec) 该参数指定系统表空间文件的路径和ibdata1文件的大小。默认为10M，建议调大到至少1G。 innodb_lru_scan_depth innodb_lru_scan_depth = 2000 InnoDB会使用一个后台操作来查找需要从其缓冲池刷新到磁盘的脏页 这个参数控制的是这个操作能够查看到的页面列表（按最近最少使用的顺序排序）的长度 对默认值1024的合理更改包括：对于拥有繁重写操作工作负载和大型缓冲池的服务器，可以减小这个值；而对于I/O能力还有盈余的服务器，可以增加这个值。 innodb_lock_wait_timeout innodb_lock_wait_timeout = 5 MySQL在允许其他事务修改那些最终受事务回滚的数据之前要等待多长时间(秒数) InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 innodb_lock_wait_timeout来解决。 这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。 通过设置合适的锁等待超时阈值，可以避免这种情况发生。 innodb_io_capacity innodb_io_capacity = 4000 InnoDB对于后台任务每秒执行I/O操作次数的近似限制 默认值为200，最小值为100。 对于慢速旋转的磁盘，可能需要将这个值调低一点。 对于SSD磁盘，可以将其适当调高，请参考innodb_io_capacity_maxinnodb_io_capacity_max innodb_io_capacity_max = 8000 如果innodb_io_capacity的值在紧急情况下不够高，那么innodb_io_capacity_max会成为InnoDB可以将该限制扩展到的最大值。 其默认值为innodb_io_capacity默认值的两倍，它受限制于服务器所使用的最低值2000。 此参数是在MySQL 5.6.6里引入 innodb_flush_method innodb_flush_method = O_DIRECT 给InnoDB用来刷新文件的方法。它只适用于Unix系统 参数的三种值： fdatasync：默认为fdatasync,调用fsync()去刷数据文件与redo log的buffer O_DSYNC：innodb会使用O_SYNC方式打开和刷写redo log,使用fsync()刷写数据文件 O_DIRECT：innodb使用O_DIRECT打开数据文件，使用fsync()刷写数据文件跟redo log 在Windows里，此参数的值总是为async_unbuffered innodb_file_per_table innodb_file_per_table=1 控制是否使用独立表空间模式 设置为1，InnoDB将为每个新表分别创建一个独立表空间：在数据库目录里为每一个新表单独创建一个.ibd文件来存放该表的内容。在这种情况下，系统表空间只会用于InnoDB数据目录条目，而不会用于数据或索引存储。 建议设置为1 innodb_file_format_check innodb_file_format_check=on InnoDB系统表空间包含有一个标志，它表示的是表空间里使用的最高版本的文件格式。 此参数会在服务器启动时设置，主要用于控制InnoDB是否要检查这个标志，以确定此格式版本比InnoDB支持的那个版本更高。 如果启用此参数（默认值），并且该格式版本更高，那么启动会失败，并产生一个错误。如果该格式版本不够高，那么InnoDB会将innodb_file_format_max设置成该格式。 innodb_file_format innodb_file_format = Barracuda 默认格式为Antelope；另一个允许值为Barracuda。 如果启用了innodb_file_per_table，则它指的是InnoDB新表所使用的格式。 使用Barracuda可以启用不被Antelope支持的功能，如COMPRESSED行格式。innodb_file_format_max innodb_file_format_max = Barracuda 参考innodb_file_format_check的描述 innodb_log_group_home_dir innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ InnoDB应该将其日志文件写入的那个目录的路径名 innodb_undo_directory innodb_undo_directory = /u01/mysql/mysql_undolog/ 如果innodb_undo_logs和innodb_undo_tablespaces都是非零值，则它指的是InnoDB在其中创建独立恢复日志表空间的那个目录。 默认值为“.”，它表示的是InnoDB在其中创建其他日志文件的那个默认目录。 MySQL 5.6.3里引入的 innodb_undo_logs innodb_undo_logs = 128 在一个事务里，InnoDB在系统表空间里会使用多少回滚段。 默认值为128。 在MySQL 5.6.3里引入的，用于替换innodb_rollback_segments。 innodb_undo_tablespaces innodb_undo_tablespaces = 3 InnoDB针对独立恢复日志所使用的那个表空间文件数量 默认值为0 innodb_flush_neighbors innodb_flush_neighbors = 1 InnoDB是单独刷新缓冲池的脏面，还是连同位于同一范围（页面组）内的相邻页面一起刷新。 刷新相邻页面，可以将写操作结合在一起，减少磁盘设备旋转过程中的寻道时间开销。 MySQL 5.6.3里引入的，是一个布尔量，其默认值为ON。 自MySQL 5.6.6起，这个参数允许的值包括： 0：不刷新相邻页面 1：刷新相邻页面 2：刷新同一范围里的所有相邻页面 innodb_log_file_size innodb_log_file_size = 1G #注意,生产环境建议调成4G+ 每个InnoDB日志文件的大小。innodb_log_file_size和innodb_log_files_in_group的乘积决定了InnoDB日志的总大小 默认为 5M 用来在 MySQL crash后的恢复，所以设置合理的大小对于mysql的性能非常重要 通过show engine innodb status\\G可以查看mysql checkpoint情况，可以算出上次checkpoint和最后一次checkpoint的中间值，官方文档建议最好不要超过innodb_log_files_in_group*innodb_log_file_size的0.75，由此可以推算出innodb_log_file_size比较合适的值。 在MySQL 5.5和5.5以前innodb的logfile最大设置为4GB,在5.6以后的版本中logfile最大的可以设为512GB 当MySQL crash后，在重启之前需要将老的innodb logfile删除，参考： https://www.percona.com/blog/2016/05/31/what-is-a-big-innodb_log_file_size/ https://dev.mysql.com/doc/refman/5.6/en/innodb-data-log-reconfiguration.html innodb_log_buffer_size innodb_log_buffer_size = 16777216 InnoDB事务日志缓冲区的大小 取值范围通常是1MB~8MB 默认为1MB innodb_purge_threads innodb_purge_threads = 4 InnoDB使用了多少后台线程来实现清除操作（将所有事务都不再需要的待删除行删除掉） 默认值为0 在MySQL 5.5.4里引入 innodb_large_prefix innodb_large_prefix = 1 InnoDB索引的最大索引前缀长度通常是767字节 如果启用此参数，那么对于那些使用COMPRESSED或DYNAMIC行格式的表，允许前缀最高达到3072个字节 默认值为OFF MySQL 5.5.14里引入 innodb_thread_concurrency innodb_thread_concurrency = 64 InnoDB尝试维护的线程数量上限 innodb_print_all_deadlocks innodb_print_all_deadlocks = 1 InnoDB是否会将诊断信息写到与事务死锁有关的错误日志里 innodb_strict_mode innodb_strict_mode = 1 InnoDB是否对表和索引的创建和修改语句的语法进行较严格要求。 如果启用了此参数，那么InnoDB会把有冲突的子句当作错误；否则，它们会被当作警告 类似于启用了严格的SQL默认 innodb_sort_buffer_size innodb_sort_buffer_size = 67108864 （64M） InnoDB在索引创建期间用于合并排序的缓冲区大小（单位为字节） 默认大小为1MB 在MySQL 5.6.4里最小值为512KB；在MySQL 5.6.5及以上的版本里，最小值为64KB 在MySQL 5.6.4里引入，在MySQL 5.6.4之前，使用的是固定大小1MB。 innodb_flush_log_at_trx_commit innodb_flush_log_at_trx_commit = 1 默认为1 控制log buffer写入log file和控制flush操作，三种模式： innodb_flush_log_at_trx_commit=0，log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行。该模式下，在事务提交的时候，不会主动触发写入磁盘的操作 innodb_flush_log_at_trx_commit=1，每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去 nnodb_flush_log_at_trx_commit=2，每次事务提交时MySQL都会把log buffer的数据写入log file.但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作 注意： 由于进程调度策略问题,这个“每秒执行一次 flush(刷到磁盘)操作”并不是保证100%的“每秒” 三种模式比较： 当设置为0，该模式速度最快，但不太安全，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失。 当设置为1，该模式是最安全的，但也是最慢的一种方式。在mysqld 服务崩溃或者服务器主机crash的情况下，binary log 只有可能丢失最多一个语句或者一个事务。。 当设置为2，该模式速度较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。 一般和sync_binlog搭配使用，推荐配置组合： N=1,1 — 适合数据安全性要求非常高，而且磁盘IO写能力足够支持业务，比如充值消费系统； N=1,0 — 适合数据安全性要求高，磁盘IO写能力支持业务不富余，允许备库落后或无复制； N=2,0或2,m(0 N=0,0 — 磁盘IO写能力有限，无复制或允许复制延迟稍微长点能接受，例如：日志性登记业务； 5.半同步设置有关参数 ########semi sync replication settings######## plugin_dir=/usr/local/mysql/lib/plugin plugin_load = \"rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so\" loose_rpl_semi_sync_master_enabled = 1 loose_rpl_semi_sync_slave_enabled = 1 loose_rpl_semi_sync_master_timeout = 5000 6.MySQL 5.7特性有关参数 [mysqld-5.7] innodb_buffer_pool_dump_pct = 40 innodb_page_cleaners = 4 innodb_undo_log_truncate = 1 innodb_max_undo_log_size = 2G innodb_purge_rseg_truncate_frequency = 128 binlog_gtid_simple_recovery=1 log_timestamps=system transaction_write_set_extraction=MURMUR32 show_compatibility_56=on innodb_buffer_pool_dump_pct innodb_buffer_pool_dump_pct=40 表示转储每个bp instance LRU上最热的page的百分比 通过设置该参数可以减少转储的page数 innodb_page_cleaners innodb_page_cleaners = 4 从5.7开始，innodb支持多个刷新buffer pool实例的脏数据的清理线程，innodb_page_cleaners即线程数量 innodb_undo_log_truncate innodb_undo_log_truncate = 1 innodb_undo_log_truncate参数设置为1，即开启在线回收（收缩）undo log日志文件，支持动态设置 当innodb_undo_log_truncate打开，触发回收时： 1、当undo 表空间超过innodb_max_undo_log_size 大小会标记为truncation，选择一个undo表空间进行截断， in a round-robin fashion ，避免两个表空间同时截断 2、回滚段在undo表空间是不活跃的，并且不会被新的事物所使用，现有事物使用的回滚段，允许完成。 3、清空、释放那些不在需要的回滚段 4、当所有undo表空间的回滚段释放，undo表空间会执行一个truncate 操作，undo表空间变为初始化大小值。 5、回滚段被重新激活，他们可以分配新的事物 必须在初始化前设置innodb_undo_log_truncate 此参数为非0，后期可以通过修改参数文件/etc/my.cnf，调整undo表空间的数量，然后重启 innodb_max_undo_log_size innodb_max_undo_log_size = 2G mysql> SELECT @@innodb_max_undo_log_size; +----------------------------+ | @@innodb_max_undo_log_size | +----------------------------+ | 2147483648 | +----------------------------+ 1 row in set (0.00 sec) 当超过这个阀值（默认是1G），会触发truncate回收（收缩）动作，truncate后空间缩小到10M。 当undo 表空间超过innodb_max_undo_log_size 大小会标记为truncation，选择一个undo表空间进行截断， in a round-robin fashion ，避免两个表空间同时截断 innodb_purge_rseg_truncate_frequency innodb_purge_rseg_truncate_frequency = 128 控制回收（收缩）undo log的频率 undo log空间在它的回滚段没有得到释放之前不会收缩，想要增加释放回滚区间的频率，就得降低innodb_purge_rseg_truncate_frequency设定值。 undo 表空间一般不能直接truncate，需要在所有回滚段释放完后，才能truncate， purge system每128次释放一次回滚段 默认128是最大值 binlog_gtid_simple_recovery binlog_gtid_simple_recovery=1 log_timestamps log_timestamps=system 为了方便对于不知道是什么原因导致日志时间差异，以及不知道如何解决的用户，MySQL 在 5.7.2 版本中新增了一个参数log_timestamps，用来解决此问题。 这个参数主要是控制 error log、slow_log、genera log，等等记录日志的显示时间参数，但不会影响 general log 和 slow log 写到表 (mysql.general_log, mysql.slow_log) 中的显示时间。 在查询行的时候，可以使用 CONVERT_TZ() 函数，或者设置会话级别的系统参数 time_zone 来转换成所需要的时区。 可以被设置的值有：UTC 和 SYSTEM，默认使用 UTC。 它还支持动态设置，不过建议在配置文件中就写上，以免重启之后造成不必要的麻烦。 transaction_write_set_extraction transaction_write_set_extraction=MURMUR32 5.7.6版本引入 用于定义一个记录事务的算法，这个算法使用hash标识来记录事务。 如果使用MGR，那么这个hash值需要用于分布式冲突检测何处理，在64位的系统，官网建议设置该参数使用 XXHASH64 算法。 如果线上并没有使用该功能，应该设为off show_compatibility_56 show_compatibility_56=on 从mysql5.7.6开始information_schema.global_status已经开始被舍弃，为了兼容性，此时需要打开 show_compatibility_56 mysql> select * from information_schema.global_status limit 3; ERROR 3167 (HY000): The 'INFORMATION_SCHEMA.GLOBAL_STATUS' feature is disabled; see the documentation for 'show_compatibility_56' --查看show_compatibility_56 mysql> show variables like '%show_compatibility_56%'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | show_compatibility_56 | OFF | +-----------------------+-------+ 1 row in set (0.01 sec) --把show_compatibility_56打开 mysql> set global show_compatibility_56=on; Query OK, 0 rows affected (0.00 sec) mysql> show variables like '%show_compatibility_56%'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | show_compatibility_56 | ON | +-----------------------+-------+ 1 row in set (0.00 sec) mysql> select * from information_schema.global_status limit 3; +-----------------------+----------------+ | VARIABLE_NAME | VARIABLE_VALUE | +-----------------------+----------------+ | ABORTED_CLIENTS | 0 | | ABORTED_CONNECTS | 0 | | BINLOG_CACHE_DISK_USE | 0 | +-----------------------+----------------+ 3 rows in set, 1 warning (0.00 sec) 在MySQL 5.6版本, 系统和状态参数信息从下面语句获取: SHOW VARIABLES SHOW STATUS And from these INFORMATION_SCHEMA tables: INFORMATION_SCHEMA.GLOBAL_VARIABLES INFORMATION_SCHEMA.SESSION_VARIABLES INFORMATION_SCHEMA.GLOBAL_STATUS INFORMATION_SCHEMA.SESSION_STATUS 在MySQL 5.7.6后，performance_schema包含以下的表作为系统和状态参数信息的新来源： performance_schema.global_variables performance_schema.session_variables performance_schema.variables_by_thread performance_schema.global_status performance_schema.session_status performance_schema.status_by_thread performance_schema.status_by_account performance_schema.status_by_host performance_schema.status_by_user Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-10-23 16:13:12 "},"4.jiagoujieshao.html":{"url":"4.jiagoujieshao.html","title":"4.MySQL体系介绍","keywords":"","body":" 一、MySQL体系架构 1.对外提供通用接口 Connectors 2 MySQL Server层 2.1 连接层 2.2 SQL层 2.3Management Serveices & Utilities 3.插件式存储引擎 4.MySQL物理存储结构 4.1 MySQL参数文件my.cnf 4.2 表结构的组成 4.3 错误日志 4.4 general 日志 4.5 慢查询日志 4.6 插件 一、MySQL体系架构 上图为官方提供的架构图 从图上看，可以看到分了两部分，对外的通用接口和内部结构。 内部主要分为两层：MySQL Server层 和 存储引擎层。而我们常说的MySQL体系结构其实就是内部这两层。 1.对外提供通用接口 Connectors 支持不同语言与 MySQL 的交互 mysql> show variables like '%connections%'; +----------------------+-------+ | Variable_name | Value | +----------------------+-------+ | max_connections | 800 | | max_user_connections | 0 | +----------------------+-------+ 2 rows in set (0.00 sec) max_connections：就是整个MySQL实例的最大连接数限制max_user_connections：是单个用户的最大连接数，这里未指明是哪个用户，是任意一个用户 经常会遇见”MySQL: ERROR 1040: Too many connections”的情况，一种是访问量确实很高，MySQL服务器抗不住，这个时候就要考虑增加从服务器分散读压力，另外一种情况是MySQL配置文件中max_connections值过小： mysql> show variables like ‘max_connections‘; +—————–+——-+ | Variable_name　　　 | Value | +—————–+——-+ | max_connections | 256　　 | +—————–+——-+ 这台MySQL服务器最大连接数是256，然后查询一下服务器响应的最大连接数： mysql> show global status like ‘Max_used_connections‘; MySQL服务器过去的最大连接数是245，没有达到服务器连接数上限256，应该没有出现1040错误，比较理想的设置是 Max_used_connections / max_connections * 100% ≈ 85% 最大连接数占上限连接数的85％左右，如果发现比例在10%以下，MySQL服务器连接数上限设置的过高了。 2 MySQL Server层 MySQL Server层又分为连接层和SQL层。 2.1 连接层 为解决资源的频繁分配﹑释放所造成的问题，为数据库连接建立一个“缓冲池”。 预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完后再放回去。 进行身份验证、线程重用、连接限制、检查内存、数据缓存。 管理用户的连接，线程处理等需要缓存的需求。 2.2 SQL层 SQL层主要有如下： 2.2.1 SQL接口 进行DML、DDL，存储过程、视图、触发器等操作和管理；用户SQL命令接口 2.2.2 解析器 SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能： a . 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的 b. 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的 2.2.3 查询优化器 对SQL语句查询进行优化，“选取、投影和连接” SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询。 用一个例子就可以理解： select uid,name from user where gender = 1; 这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤 这个select 查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤将这两个查询条件联接起来生成最终查询结果 2.2.4 缓存和缓冲区 由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 主要注意几个参数： mysql> show variables like '%query_cache%' ; +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | have_query_cache | YES | | query_cache_limit | 1048576 | | query_cache_min_res_unit | 4096 | | query_cache_size | 1048576 | | query_cache_type | OFF | | query_cache_wlock_invalidate | OFF | +------------------------------+---------+ 6 rows in set (0.00 sec) 注意： 生产环境建议关闭query cache 关闭query cache只设置query_cache_size =0不启作用，要配合使用query_cache_type=OFF使用 2.3Management Serveices & Utilities 系统管理和控制工具：从备份和恢复的安全性、复制、集群、管理、配置、迁移和元数据等方面管理数据库 3.插件式存储引擎 MySQL的存储引擎是插件式的。它根据MySQL AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制，这种访问机制就叫存储引擎，目前常见的存储引擎见下： MyISAM：它查询速度快，有较好的索引优化和数据压缩技术。但不支持事务。 InnoDB： 支持事务，并且提供行级的锁定，应用也相当广泛。 BDB：不再从底层支持BDB Memory：适合存储临时数据 Archive：适合存储历史数据 会在下一章再详细的介绍存储引擎（innodb） 物理文件层 支持的文件类型 EXT3、EXT4、NTFS、NFS 文件内容 数据文件 日志文件 4.MySQL物理存储结构 4.1 MySQL参数文件my.cnf 4.2 表结构的组成 frm：表结构定义文件 MYI：索引文件 MYD：数据文件 4.3 错误日志 4.4 general 日志 4.5 慢查询日志 4.6 插件 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:35:18 "},"5.cuncunyinqin.html":{"url":"5.cuncunyinqin.html","title":"5.MySQL的存储引擎","keywords":"","body":" 一、存储引擎的概念 二、MySQL的存储引擎 1.innodb存储引擎 2.myisam存储引擎 3.memory存储引擎 4.csv存储引擎 5.federated存储引擎 三、存储引擎的选择 四、innodb与myisam的对比 一、存储引擎的概念 用来处理数据库的相关CRUD操作 查看MySQL支持的引擎。 mysql> show engines; +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES | | CSV | YES | CSV storage engine | NO | NO | NO | | MyISAM | YES | MyISAM storage engine | NO | NO | NO | | BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO | | PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO | | MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO | | ARCHIVE | YES | Archive storage engine | NO | NO | NO | | MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO | | FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ 9 rows in set (0.00 sec) 官方存储引擎 MyISAM InnoDB – 推荐；其他引擎已经体停止维护和开发 Memory Federated CSV Archive 第三方存储引擎 TokuDB – 开源，适合插入密集型 InfoBright – 商业，开源版本有数据量限制。属于列存储，面向OLAP场景 Spider 查看默认的存储引擎 mysql> SHOW VARIABLES LIKE '%storage_engine%'; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.00 sec) 二、MySQL的存储引擎 1.innodb存储引擎 InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： 1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 5、InnoDB被用在众多需要高性能的大型数据库站点上 6 InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 2.myisam存储引擎 • MySQL5.1版本之前的默认存储引擎 • 堆表数据结构 • 表锁设计 • 支持数据静态压缩 • 不支持事物 • 数据容易丢失 • 索引容易损坏 • 唯一优点 ◦ 数据文件可以直接拷贝到另一台服务器使用 现在MySQL中还有用MyISAM的表，主要是历史原因。数据库文件以MY 开头的基本都是MyISAM的表 MyISAM还在使用的原因 • 历史原因，需要逐步替换 • 部分如User，DB等系统表(MyISAM引擎)，可以直接拷贝，比较方便 • 性能好，或者存储小不是MyISAM的优点，也不是存在的原因 MyISAM文件组成 • frm 表结构文件 • MYI 索引文件 • MYD 数据文件 ◦ 数据文件是堆表数据结构，堆是无序数据的集合 ◦ MYI 中的叶子节点，指向MYD 中的数据页 ◦ 当数据移动到页外时，需要修改对应指针 myisamchk myisamchk 通过扫描MYD文件来重建MYI文件；如果MYD文件中某条记录有问题，将跳过该记录 3.memory存储引擎 Memory介绍 全内存存储的引擎 数据库重启后数据丢失 支持哈希索引 不支持事物 Memory特性 千万不要用Memory存储引擎去做缓存(Cache) , 性能上不及Redis和Memcahced Memory 不能禁用，当涉及内部排序操作的临时表时，使用该存储引擎 max_heap_table_size 决定使用内存的大小，默认时16M 无论该表使用的什么引擎，只要使用到临时表，或者指定Memory，都受参数影响 当上面设置的内存放不下数据时，(>=5.6)转为MyISAM,(>=5.7)转为InnoDB 注意磁盘上临时路径空间的大小( tmpdir ) 内存使用为会话(SESSION)级别，当心内核OOM 支持哈希索引，且仅支持等值查询 mysql> show global status like \"%tmp%tables\"; +-------------------------+-------+ | Variable_name | Value | +-------------------------+-------+ | Created_tmp_disk_tables | 37 | --内存放不下，转成磁盘存储的数量，如果过大，考虑增大内存参数 | Created_tmp_tables | 307 | --创建临时表的数量 +-------------------------+-------+ 2 rows in set (0.00 sec) mysql> show variables like 'tmpdir'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | tmpdir | /tmp | --memory转成磁盘存储的路径 +---------------+-------+ 1 row in set (0.00 sec) 4.csv存储引擎 CSV介绍 • CSV - Comma-Separated Values，使用逗号分隔 • 不支持特殊字符 • CSV是一种标准文件格式 • 文件以纯文本形式存储表格数据 • 使用广泛 CSV文件组成 • frm 表结构 • CSV 数据文件 • CSM 元数据信息 CSV特性 • MySQL CSV存储引擎运行时，即创建CSV 文件 • 通过MySQL标准接口来查看和修改CSV文件 • 无需将CSV文件导入到数据库，只需创建相同字段的表结构，拷贝CSV文件即可 • CSV存储引擎表每个字段必须是NOT NULL 属性 5.federated存储引擎 Federated介绍 • 允许本地访问远程MySQL数据库中表的数据 • 本地不存储任何数据文件 • 类似Oracle中的DBLink • Federated存储引擎默认不开启, 需要在my.cnf 的[mysqld] 标签下添加federated • MySQL的Federated不支持异构数据库访问，MariaDB中的FederatedX 支持 Federated 语法 scheme://user_name[:password]@host_name[:port_num]/db_name/tbl_name CONNECTION='mysql://username:password@hostname:port/database/tablename' 示例： CREATE TABLE `T1` ( `A` VARCHAR(100), UNIQUE KEY (`A` (30)) ) ENGINE=FEDERATED CONNECTION='MYSQL://nazeebo:123456@127.0.0.1:3306/TEST/T1'; 三、存储引擎的选择 不同的存储引擎都有各自的特点，以适应不同的需求，如下表所示： 1.如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择 2.如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率 3.如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果 4.如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive 5.使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 以当前的发展来看，选默认的innodb存储引擎是99.9999%没错的！^_^ 四、innodb与myisam的对比 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:35:16 "},"6.duoshili.html":{"url":"6.duoshili.html","title":"6.MySQL多实例","keywords":"","body":" 一、介绍 1.优缺点 优点： 缺点： 2.常见应用场景 3.MySQL多实例实现的3种方式 二、部署演示 一、介绍 mysql多实例，简单理解就是在一台服务器上，MySQL 服务开启多个不同的端口（如3306、3307），运行多个服务进程。这些 MySQL 服务进程通过不同的 socket来监听不同的数据端口，进而互不干涉的提供各自的服务。 在同一台服务器上，MySQL 多实例会去共用一套 MySQL 应用程序，因此你在部署 MySQL 的时候只需要部署一次 MySQL 程序即可，无需多次部署。但是，MySQL 多实例之间会各自使用不同的 my.cnf 配置文件、启动程序和数据文件。在提供服务方面，MySQL 多实例在逻辑上看起来是各自独立，互不干涉的，并且多个实例之间是根据配置文件的设定值，来获取相关服务器的硬件资源。 下面用一个比喻，来帮助大家理解 MySQL 多实例的本质。 mysql 多实例相当于合租房，合租房里面有多个租客，每个租客都租有一个卧室，这个卧室就相当于 MySQL 的一个实例。整个合租房就相当于一台服务器。合租房里面的洗衣机、卫生间、阳台就相当于我们服务器上的各种硬件资源，比如CPU、MEM、DISK等，这些东西都是公共资源，大家共用的。 另外，多实例并不仅仅是 MySQL 才有，其实日常运维中碰到的很多服务都可以部署使用多实例，并且在生产环境中也非常热衷去使用，甚至在门户网站应用也很广泛，例如nginx多实例、apache多实例、redis多实例等等。 1.优缺点 优点： 有效利用服务器资源 当单个服务器资源过剩时，可以充分利用剩余的资源来提供更多的服务 节约服务器资源 当公司资金紧张，但数据库又需要数据库之间各自提供服务时，并且还想使用主从同步等技术，此时多实例就再好不过了 方便后期架构扩展 当公司的某个项目才启动时，启动初期并不一定有很大的用户量，因此可以先用一组物理数据库服务器，在上面部署多个实例，方便后续架构扩展、迁移 缺点： 资源互相抢占问题 当某个服务实例并发很高或者有慢查询时，整个实例会消耗更多的内存、CPU和IO资源，这将导致服务器上的其它实例提供服务的质量下降。这就比如说合租房的各个租客，每当早晨上班时，都会洗漱，此时卫生间的占用率就大，各个租客总会发生等待。 2.常见应用场景 当一个公司业务访问量不太大，又想节俭成本，并且还希望不同业务的数据库服务能够各自尽量独立，提供服务能够互相不受影响。另外还需要应用主从同步等技术来提供数据库备份或读写分离服务，以及方便后期业务量增大时，数据库架构的扩展和迁移。此时，Mysql 多实例就再好不过了。比如，我们可以通过在 3 台服务器部署 6-9 个实例，然后交叉做主从同步备份及读写分离，来实现 6-9 台服务器才能够达到的效果 公司业务访问量不是太大的时候，服务器的资源基本都是过剩状态。此时就很适合 Mysql 多实例的应用。如果对 SQL语句 优化做的比较好，Mysql 多实例 是一个很值得去使用的技术。即使后期业务并发很大，只要合理分配好系统资源，也不会有太大的问题 为了规避 Mysql 对 SMP 架构不支持的缺陷，我们可以使用 Mysql 多实例绑定处理器的办法（NUMA处理器必须支持，不过现在大部分处理器都支持的）将不同的数据库分配到不同的实例上提供数据服务； 传统游戏行业的 MMO/MMORPG以及Web Game，会将每个服都对应一个数据库，而且可能经常要做很多数据查询和数据订正工作。此时，为了减少维护而出错的概率，我们也可以采用多实例的部署方式，按区的概念来分配数据库。 3.MySQL多实例实现的3种方式 基于多配置文件 通过使用多个配置文件来启动不同的进程，以此来实现多实例。 优点：逻辑简单，配置简单 缺点：管理起来不方便 基于mysqld_multi 通过官方自带的 mysqld_multi 工具，使用单独配置文件来实现多实例 优点： 便于集中管理管理 缺点： 不方便针对每个实例配置进行定制 基于IM 使用 MySQL 实例管理器（MYSQLMANAGER），这个方法好像比较好不过也有点复杂 优点：便于集中管理 缺点：耦合度高。IM一挂，实例全挂，不方便针对每个实例配置进行定制 二、部署演示 略 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:35:13 "},"7.aboutssl.html":{"url":"7.aboutssl.html","title":"7.MySQL的SSL相关","keywords":"","body":" 一、介绍 SSL协议提供的功能主要有： 二、MySQL5.7 SSL配置和启用 1.安装时就配置SSL 2.如果没有在安装，在后期配置SSL的方法 三、开启SSL 查看ssl的是否开启 开启ssl 四、SSL的使用 1.默认SSL是开启的 2.使用证书认证登录 五、使用SSL前后性能对比(QPS) 六、总结 一、介绍 SSL（Secure Socket Layer：安全套接字层）利用数据加密、身份验证和消息完整性验证机制，为基于TCP等可靠连接的应用层协议提供安全性保证，是维护Client - Server之间加密通讯的一套安全协议。 SSL协议提供的功能主要有： 数据传输的机密性：利用对称密钥算法对传输的数据进行加密。 身份验证机制：基于证书利用数字签名方法对服务器和客户端进行身份验证，其中客户端的身份验证是可选的。 消息完整性验证：消息传输过程中使用MAC算法来检验消息的完整性。 如果用户的传输不是通过SSL的方式，那么其在网络中数据都是以明文进行传输的，而这给别有用心的人带来了可乘之机。所以，现在很多大型网站都开启了SSL功能。同样地，在数据库方面，如果客户端连接服务器获取数据不是使用SSL连接，那么在传输过程中，数据就有可能被窃取。 二、MySQL5.7 SSL配置和启用 1.安装时就配置SSL 在MySQL5.7版本安装初始化阶段，我们发现比之前版本（5.6）多了一步操作，而这个操作就是安装SSL的。 bin/mysqld --initialize --user=mysql bin/mysql_ssl_rsa_setup 当运行完这个命令后，默认会在data_dir目录下生成以下pem文件，这些文件就是用于启用SSL功能的： [root@nazeebodan mysql_data]# ll *.pem -rw------- 1 mysql mysql 1679 Sep 13 10:13 ca-key.pem #CA私钥 -rw-r--r-- 1 mysql mysql 1107 Sep 13 10:13 ca.pem #自签的CA证书，客户端连接也需要提供 -rw-r--r-- 1 mysql mysql 1107 Sep 13 10:13 client-cert.pem #客户端连接服务器端需要提供的证书文件 -rw------- 1 mysql mysql 1679 Sep 13 10:13 client-key.pem #客户端连接服务器端需要提供的私钥文件 -rw------- 1 mysql mysql 1679 Sep 13 10:13 private_key.pem #私钥/公钥对的私有成员 -rw-r--r-- 1 mysql mysql 451 Sep 13 10:13 public_key.pem #私钥/公钥对的共有成员 -rw-r--r-- 1 mysql mysql 1107 Sep 13 10:13 server-cert.pem #服务器端证书文件 -rw------- 1 mysql mysql 1675 Sep 13 10:13 server-key.pem #服务器端私钥文件 2.如果没有在安装，在后期配置SSL的方法 重新执行mysql_ssl_rsa_setup 重启数据库 1.重新执行mysql_ssl_rsa_setup [root@nazeebodan mysql]# pwd /usr/local/mysql [root@nazeebodan mysql]# bin/mysql_ssl_rsa_setup --datadir=/u01/mysql/mysql_data --user=mysql --uid=mysql Generating a 2048 bit RSA private key ...............+++ ..........+++ writing new private key to 'ca-key.pem' ----- Generating a 2048 bit RSA private key ..............................................+++ ..........+++ writing new private key to 'server-key.pem' ----- Generating a 2048 bit RSA private key ..............................................................+++ ....+++ writing new private key to 'client-key.pem' ----- 注意：上面的 --uid=mysql加上后，就不需要再去 chown -R mysql.mysql *.pem 了 2.重启数据库 [root@nazeebodan mysql]# service suremysql stop Shutting down MySQL.. [ OK ] [root@nazeebodan mysql]# service suremysql start Starting MySQL.. [ OK ] 三、开启SSL 查看ssl的是否开启 mysql> show variables like 'port'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | port | 3306 | +---------------+-------+ 1 row in set (0.00 sec) mysql> show variables like \"%ssl%\"; +---------------+----------+ | Variable_name | Value | +---------------+----------+ | have_openssl | DISABLED | --SSL被禁止 | have_ssl | DISABLED | | ssl_ca | | | ssl_capath | | | ssl_cert | | | ssl_cipher | | | ssl_crl | | | ssl_crlpath | | | ssl_key | | +---------------+----------+ 9 rows in set (0.00 sec) 开启ssl [root@nazeebodan mysql]# pwd /usr/local/mysql [root@nazeebodan mysql]# bin/mysql_ssl_rsa_setup --datadir=/u01/mysql/mysql_data --user=mysql --uid=mysql Generating a 2048 bit RSA private key ...............+++ ..........+++ writing new private key to 'ca-key.pem' ----- Generating a 2048 bit RSA private key ..............................................+++ ..........+++ writing new private key to 'server-key.pem' ----- Generating a 2048 bit RSA private key ..............................................................+++ ....+++ writing new private key to 'client-key.pem' ----- 注意： 上面的 --uid=mysql加上后，就不需要再去 chown -R mysql.mysql *.pem 了 [root@nazeebodan mysql]# service suremysql stop Shutting down MySQL.. [ OK ] [root@nazeebodan mysql]# service suremysql start Starting MySQL.. [ OK ] [root@nazeebodan mysql]# mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> show variables like \"%ssl%\"; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | have_openssl | YES | | have_ssl | YES | | ssl_ca | ca.pem | | ssl_capath | | | ssl_cert | server-cert.pem | | ssl_cipher | | | ssl_crl | | | ssl_crlpath | | | ssl_key | server-key.pem | +---------------+-----------------+ 9 rows in set (0.00 sec) mysql> 四、SSL的使用 1.默认SSL是开启的 1.创建一个用户sure，并且让用户登录时不需要使用ssl，即不授予ssl的require mysql> create user 'sure'@'%' identified by '123456'; Query OK, 0 rows affected (0.00 sec) mysql> mysql> grant all on *.* to 'sure'@'%'; Query OK, 0 rows affected (0.00 sec) mysql> select * from mysql.user where user='sure'\\G *************************** 1. row *************************** Host: % User: sure Select_priv: Y Insert_priv: Y Update_priv: Y Delete_priv: Y Create_priv: Y Drop_priv: Y Reload_priv: Y Shutdown_priv: Y Process_priv: Y File_priv: Y Grant_priv: N References_priv: Y Index_priv: Y Alter_priv: Y Show_db_priv: Y Super_priv: Y Create_tmp_table_priv: Y Lock_tables_priv: Y Execute_priv: Y Repl_slave_priv: Y Repl_client_priv: Y Create_view_priv: Y Show_view_priv: Y Create_routine_priv: Y Alter_routine_priv: Y Create_user_priv: Y Event_priv: Y Trigger_priv: Y Create_tablespace_priv: Y ssl_type: -- 此处为空,标识没有收取ssl的权限 ssl_cipher: x509_issuer: x509_subject: max_questions: 0 max_updates: 0 max_connections: 0 max_user_connections: 0 plugin: mysql_native_password authentication_string: *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 password_expired: N password_last_changed: 2018-09-13 10:23:51 password_lifetime: NULL account_locked: N 1 row in set (0.00 sec) 2.在其他服务器（root@lowa）上用这个新创建的用户登录 [root@lowa ~]# mysql -usure -p123456 -hnazeebodan mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 3 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> \\s -------------- mysql Ver 14.14 Distrib 5.7.23, for linux-glibc2.12 (x86_64) using EditLine wrapper Connection id: 3 Current database: Current user: sure@172.18.53.223 SSL: Cipher in use is DHE-RSA-AES256-SHA --这个显示已经使用了ssl登录了 Current pager: stdout Using outfile: '' Using delimiter: ; Server version: 5.7.23-log MySQL Community Server (GPL) Protocol version: 10 Connection: nazeebodan via TCP/IP Server characterset: utf8mb4 Db characterset: utf8mb4 Client characterset: utf8 Conn. characterset: utf8 TCP port: 3306 Uptime: 11 min 36 sec Threads: 2 Questions: 15 Slow queries: 0 Opens: 114 Flush tables: 1 Open tables: 107 Queries per second avg: 0.021 -------------- mysql> 3.上面测试中我们没有使用--ssl参数，也是用了ssl登录的，原因是因为默认ssl登录是开启的 [root@nazeebodan ~]# mysql --help | grep ssl --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) 4.再次使用sure用户登录，并加上关闭ssl登录的参数 [root@lowa ~]# mysql -usure -p123456 -hnazeebodan --skip-ssl mysql: [Warning] Using a password on the command line interface can be insecure. WARNING: --ssl is deprecated and will be removed in a future version. Use --ssl-mode instead. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> \\s -------------- mysql Ver 14.14 Distrib 5.7.23, for linux-glibc2.12 (x86_64) using EditLine wrapper Connection id: 4 Current database: Current user: sure@172.18.53.223 SSL: Not in use --这里显示已经禁用了ssl Current pager: stdout Using outfile: '' Using delimiter: ; Server version: 5.7.23-log MySQL Community Server (GPL) Protocol version: 10 Connection: nazeebodan via TCP/IP Server characterset: utf8mb4 Db characterset: utf8mb4 Client characterset: utf8 Conn. characterset: utf8 TCP port: 3306 Uptime: 13 min 28 sec Threads: 2 Questions: 20 Slow queries: 0 Opens: 114 Flush tables: 1 Open tables: 107 Queries per second avg: 0.024 -------------- mysql> 5.修改用户，让用户必须使用ssl登录 mysql> alter user 'sure'@'%' require ssl; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.00 sec) 6.再次尝试登录，发现如果加上忽略ssl的选项，登录会报错： [root@lowa ~]# mysql -usure -p123456 -hnazeebodan --skip-ssl mysql: [Warning] Using a password on the command line interface can be insecure. WARNING: --ssl is deprecated and will be removed in a future version. Use --ssl-mode instead. ERROR 1045 (28000): Access denied for user 'sure'@'172.18.53.223' (using password: YES) 7.不忽略ssl登录，登录成功 [root@lowa ~]# mysql -usure -p123456 -hnazeebodan --skip-ssl mysql: [Warning] Using a password on the command line interface can be insecure. WARNING: --ssl is deprecated and will be removed in a future version. Use --ssl-mode instead. ERROR 1045 (28000): Access denied for user 'sure'@'172.18.53.223' (using password: YES) [root@lowa ~]# mysql -usure -p123456 -hnazeebodan mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 6 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> \\s -------------- mysql Ver 14.14 Distrib 5.7.23, for linux-glibc2.12 (x86_64) using EditLine wrapper Connection id: 6 Current database: Current user: sure@172.18.53.223 SSL: Cipher in use is DHE-RSA-AES256-SHA Current pager: stdout Using outfile: '' Using delimiter: ; Server version: 5.7.23-log MySQL Community Server (GPL) Protocol version: 10 Connection: nazeebodan via TCP/IP Server characterset: utf8mb4 Db characterset: utf8mb4 Client characterset: utf8 Conn. characterset: utf8 TCP port: 3306 Uptime: 20 min 52 sec Threads: 2 Questions: 27 Slow queries: 0 Opens: 115 Flush tables: 1 Open tables: 108 Queries per second avg: 0.021 2.使用证书认证登录 1.创建用户sure_x509，登录时需要x509的证书 mysql> create user 'sure_x509'@'%' identified by '123456' require x509; Query OK, 0 rows affected (0.00 sec) mysql> grant all on *.* to 'sure_x509'@'%'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) mysql> select * from mysql.user where user='sure_x509'\\G *************************** 1. row *************************** Host: % User: sure_x509 Select_priv: Y Insert_priv: Y Update_priv: Y Delete_priv: Y Create_priv: Y Drop_priv: Y Reload_priv: Y Shutdown_priv: Y Process_priv: Y File_priv: Y Grant_priv: N References_priv: Y Index_priv: Y Alter_priv: Y Show_db_priv: Y Super_priv: Y Create_tmp_table_priv: Y Lock_tables_priv: Y Execute_priv: Y Repl_slave_priv: Y Repl_client_priv: Y Create_view_priv: Y Show_view_priv: Y Create_routine_priv: Y Alter_routine_priv: Y Create_user_priv: Y Event_priv: Y Trigger_priv: Y Create_tablespace_priv: Y ssl_type: X509 ssl_cipher: x509_issuer: x509_subject: max_questions: 0 max_updates: 0 max_connections: 0 max_user_connections: 0 plugin: mysql_native_password authentication_string: *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 password_expired: N password_last_changed: 2018-09-13 10:36:14 password_lifetime: NULL account_locked: N 1 row in set (0.00 sec) mysql> 2.不忽略ssl登录，发现登录失败 [root@lowa ~]# mysql -usure_x509 -p123456 -hnazeebodan mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 1045 (28000): Access denied for user 'sure_x509'@'172.18.53.223' (using password: YES) [root@lowa ~]# 3.将证书传到相应的登录节点 [root@nazeebodan mysql_data]# scp client-cert.pem client-key.pem root@lowa:/tmp client-cert.pem 100% 1107 2.7MB/s 00:00 client-key.pem 100% 1679 3.3MB/s 00:00 [root@nazeebodan mysql_data]# 4.再次尝试登录，登录成功 [root@lowa ~]# mysql -usure_x509 -p123456 -hnazeebodan --ssl-cert=/tmp/client-cert.pem --ssl-key=/tmp/client-key.pem mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 5.7.23-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> \\s -------------- mysql Ver 14.14 Distrib 5.7.23, for linux-glibc2.12 (x86_64) using EditLine wrapper Connection id: 8 Current database: Current user: sure_x509@172.18.53.223 SSL: Cipher in use is DHE-RSA-AES256-SHA --这里使用了SSL及证书X509了 Current pager: stdout Using outfile: '' Using delimiter: ; Server version: 5.7.23-log MySQL Community Server (GPL) Protocol version: 10 Connection: nazeebodan via TCP/IP Server characterset: utf8mb4 Db characterset: utf8mb4 Client characterset: utf8 Conn. characterset: utf8 TCP port: 3306 Uptime: 28 min 8 sec Threads: 2 Questions: 37 Slow queries: 0 Opens: 115 Flush tables: 1 Open tables: 108 Queries per second avg: 0.021 五、使用SSL前后性能对比(QPS) 服务器配置：CPU:32核心 内存:128G 磁盘：SSD 为了尽量准确测试QPS，采用全内存查询，按照并发线程数分类：1线程、4线程、8线程、16线程、24线程、32线程、64线程； 具体数据如下： 从测试数据可以发现，开启SSL后，数据库QPS平均降低了23%左右，相对还是比较影响性能的。从SSL实现方式来看，建立连接时需要进行握手、加密、解密等操作。所以耗时基本都在建立连接阶段，这对于使用短链接的应用程序可能产生更大的性能损耗，比如采用PHP开发。不过如果使用连接池或者长连接可能会好许多。 六、总结 MySQL5.7默认是开启SSL连接，如果强制用户使用SSL连接，那么应用程序的配置也需要明确指定SSL相关参数，否则程序会报错。 虽然SSL方式使得安全性提高了，但是相对地使得QPS也降低23%左右。所以要谨慎选择： 对于非常敏感核心的数据，或者QPS本来就不高的核心数据，可以采用SSL方式保障数据安全性； 对于采用短链接、要求高性能的应用，或者不产生核心敏感数据的应用，性能和可用性才是首要，建议不要采用SSL方式； Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 07:25:55 "},"8.datatypeintro.html":{"url":"8.datatypeintro.html","title":"8.MySQL的数据类型","keywords":"","body":" MySQL的数据类型介绍 一、整型 1.INT类型使用建议 2.unsigned的注意事项 3.zerofill的注意事项 4.auto_increment 二、浮点型 三、字符串类型 1.char(N)说明 2.varchar(N)说明 3.char和varchar的区别 4.BLOB和TEXT 四、集合类型enum 和 set 1.集合的插入 2.集合的排序 五、日期类型 1.TIMESTAMP 和 DATETIME 2.微秒解读 3.日期函数 六、JSON类型 1.JSON格式示例(wiki百科) 2. JSON 和 BLOB 的对比 3. 结构化和非结构化 4. json示例 5. json的相关函数 6. json 字段创建索引 七、字符集相关 1. MySQL字符集包括： 2. collation（排序规则） 3. 乱码问题 MySQL的数据类型介绍 一、整型 类型 存储空(单位:字节) 取值区间(有符号) 取值区间(无符号) tinyint 1 [ -128,127 ] [0,255] smallint 2 [-32768 , 32767] [0,65535] mediumint 3 [-8388608 , 8388607] [0 , 16777215] int 4 [-2147483648 , 2147483647] [0 , 4294967295] bigint 8 [ -9223372036854775808 , 9223372036854775807] [0 , 18446744073709551615] 1.INT类型使用建议 推荐不使用unsigned 自增int类型主键建议使用bigint 2.unsigned的注意事项 mysql> create table test_unsigned(a int unsigned, b int unsigned); Query OK, 0 rows affected (0.04 sec) mysql> insert into test_unsigned values(1, 2); Query OK, 1 row affected (0.01 sec) //注意这个地方就报错了！ mysql> select a - b from test_unsigned; ERROR 1690 (22003): BIGINT UNSIGNED value is out of range in '(`test`.`test_unsigned`.`a` - `test`.`test_unsigned`.`b`)' mysql> select b-a from test_unsigned; +------+ | b-a | +------+ | 1 | +------+ 1 row in set (0.00 sec) // 这样可以得到负数 mysql> set sql_mode = 'no_unsigned_subtraction'; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> select a - b from test_unsigned; +-------+ | a - b | +-------+ | -1 | +-------+ 1 row in set (0.00 sec) 3.zerofill的注意事项 对于INT(N)来说，N无论写成多大，都是占4个字节的空间，而非写成几就能存几位 N不是带代表能存多少位，只是显示宽度。例如 INT(4) 和 INT(10)其实存的东西是一样的长度。 zerofill 表示当存储的数字长度 mysql> create table test_int_n(a int(3) zerofill); Query OK, 0 rows affected (0.03 sec) //不满 N=3时，左边用0填充 mysql> insert into test_int_n values(1); Query OK, 1 row affected (0.01 sec) mysql> select * from test_int_n; +------+ | a | +------+ | 001 | +------+ 1 row in set (0.00 sec) //超过N=3的长度时，是什么数字，就显示什么数字 mysql> insert into test_int_n values(1111); Query OK, 1 row affected (0.00 sec) mysql> select * from test_int_n; +------+ | a | +------+ | 001 | | 1111 | +------+ 2 rows in set (0.00 sec) // mysql> select a, HEX(a) from test_int_n; +------+--------+ | a | HEX(a) | +------+--------+ | 001 | 1 | -- 实际存储的还是1 | 1111 | 457 | -- 1111对于的16进制就是457 +------+--------+ 2 rows in set (0.00 sec) 4.auto_increment 自增，每张表最多一个，必须是索引的一部分 //没有指定key，创建的时候就会报错 mysql> create table test_auto_increment(a int auto_increment); ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key //指定了key，则创建成功 mysql> create table test_auto_increment(a int auto_increment primary key); Query OK, 0 rows affected (0.02 sec) //插入null，意思就是自增开始，从1开始 mysql> insert into test_auto_increment values(NULL); Query OK, 1 row affected (0.01 sec) mysql> select * from test_auto_increment; +---+ | a | +---+ | 1 | +---+ 1 row in set (0.00 sec) //插入0，自增为2 mysql> insert into test_auto_increment values(0); Query OK, 1 row affected (0.01 sec) mysql> select * from test_auto_increment; +---+ | a | +---+ | 1 | | 2 | +---+ 2 rows in set (0.00 sec) //插入-1，则为-1 mysql> insert into test_auto_increment values(-1); Query OK, 1 row affected (0.01 sec) mysql> select * from test_auto_increment; +----+ | a | +----+ | -1 | | 1 | | 2 | +----+ 3 rows in set (0.00 sec) //插入null，继续从目前最大的值开始自增，从2开始 mysql> insert into test_auto_increment values(NULL); Query OK, 1 row affected (0.00 sec) mysql> select * from test_auto_increment; +----+ | a | +----+ | -1 | | 1 | | 2 | | 3 | +----+ 4 rows in set (0.00 sec) //再次插入-1 ，报错，说明-1是直接插入值，而非使用自增 mysql> insert into test_auto_increment values(-1); ERROR 1062 (23000): Duplicate entry '-1' for key 'PRIMARY' mysql> insert into test_auto_increment values('0'); Query OK, 1 row affected (0.00 sec) mysql> select * from test_auto_increment; +----+ | a | +----+ | -1 | | 1 | | 2 | | 3 | | 4 | +----+ 5 rows in set (0.00 sec) //这个是一个将自增从0开始的办法，先插入-1，再把 -1 update为 0 mysql> update test_auto_increment set a = 0 where a = -1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_auto_increment; +---+ | a | +---+ | 0 | | 1 | | 2 | | 3 | | 4 | +---+ 5 rows in set (0.00 sec) //插入3个值，第一个是从4开始自增所以为5，第二个是直接插入100，第三个是从100开始自增所以为101 mysql> insert into test_auto_increment values(NULL), (100), (NULL); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from test_auto_increment; +-----+ | a | +-----+ | 0 | | 1 | | 2 | | 3 | | 4 | | 5 | | 100 | | 101 | +-----+ 8 rows in set (0.00 sec) //插入99，因为没有99这个值，所以直接插入进去 mysql> insert into test_auto_increment values(99); Query OK, 1 row affected (0.00 sec) mysql> select * from test_auto_increment; +-----+ | a | +-----+ | 0 | | 1 | | 2 | | 3 | | 4 | | 5 | | 99 | | 100 | | 101 | +-----+ 9 rows in set (0.00 sec) 注意： AUTO_INCREMENT 是实例启动时，取当前表的最大值，然后 +1 即为下次自增的值。（MAX + 1) 数字 0 这个值比较特殊， 插入0和插入NULL的效果是一样的，都是代表自增 insert into tablename select NULL; 等价于insert into tablename values (NULL); 二、浮点型 类型 占用空间 精度 精确性 float 4 单精度 低 double 8 双精度 低 decimal 变长 高精度 非常高 M*G/G 不一定=M float(M,D) double(M,D) decimal(M,D) 表示显示M位整数，其中D位位于小数点后面 避免使用浮点类型，因为它并不属于精确的类型。 在生产环境中，不建议使用float和double，对于财务系统或者说和钱有关的，必须使用decimal。 即使使用了decimal，但是在数值运算中还是会转成浮点来运算，而且在计算过程中会出现四舍五入的情况。 //创建一个含有decimal类型的表 mysql> show create table test_decimal \\G *************************** 1. row *************************** Table: test_decimal Create Table: CREATE TABLE `test_decimal` ( `id` int(10) NOT NULL, `salary` decimal(6,2) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) //插入一个超过范围的6位的数，在表的定义写的是decimal(6,2)，代表一共6位数，其中有2位为小数 //在5.7版本可用插入，但会有waring提示；在5.6版本直接报错 //查看插入的结果，就是最接近123456的一个数 mysql> insert into test_decimal(id,salary) values(1,123456); Query OK, 1 row affected, 1 warning (0.01 sec) mysql> show warnings; +---------+------+-------------------------------------------------+ | Level | Code | Message | +---------+------+-------------------------------------------------+ | Warning | 1264 | Out of range value for column 'salary' at row 1 | +---------+------+-------------------------------------------------+ 1 row in set (0.00 sec) mysql> select * from test_decimal; +----+---------+ | id | salary | +----+---------+ | 1 | 9999.99 | +----+---------+ 1 row in set (0.00 sec) //插入一个不超过范围的数，则正常显示 mysql> insert into test_decimal(id,salary) values(1,1234); Query OK, 1 row affected (0.01 sec) mysql> select * from test_decimal; +----+---------+ | id | salary | +----+---------+ | 1 | 9999.99 | | 1 | 1234.00 | +----+---------+ 2 rows in set (0.00 sec) //插入一个小数超范围的数，则会四舍五入 mysql> insert into test_decimal(id,salary) values(1,1234,5678); ERROR 1136 (21S01): Column count doesn't match value count at row 1 mysql> insert into test_decimal(id,salary) values(1,1234.5678); Query OK, 1 row affected, 1 warning (0.00 sec) mysql> select * from test_decimal; +----+---------+ | id | salary | +----+---------+ | 1 | 9999.99 | | 1 | 1234.00 | | 1 | 1234.57 | +----+---------+ 3 rows in set (0.00 sec) 三、字符串类型 说明 N的含义 是否有字符集 最大长度 CHAR(N) 定长字符 字符 是 255 VARCHAR(N) 变长字符 字符 是 16384 BINARY(N) 定长二进制字节 字节 否 255 VARBINARY(N) 变长二进制字节 字节 否 16384 TINYBLOB 二进制大对象 字节 否 256 BLOB 二进制大对象 字节 否 16K MEDIUMBLOB 二进制大对象 字节 否 16M LONGBLOB 二进制大对象 字节 否 4G TINYTEXT 大对象 字节 是 256 TEXT 大对象 字节 是 16K MEDIUMTEXT 大对象 字节 是 16M LONGTEXT 大对象 字节 是 4G BLOB=>VARBINARY TEXT=>VARCHAR 注意事项 1.在BLOB和TEXT列上创建索引的时候，必须指定索引前缀的长度 2.varchar和varbinary前缀长度是可选的 3.blob和te列不能有默认值 4.blob和text列排序时只使用该列的前 max_sort_length个字节 1.char(N)说明 假设当前table的字符集的最大长度为W , 则char(N) 的最大存储空间为(N * W)Byte 假设使用UTF-8 ，则char(10)可以最小存储10个字节的字符，最大存储30个字节的字符，其实是另一种意义上的varchar 当存储的字符数小于N 时，尾部使用空格填充，并且填充最小字节的空格 mysql> create table test_char(a char(10)); Query OK, 0 rows affected (0.02 sec) mysql> show create table test_char\\G *************************** 1. row *************************** Table: test_char Create Table: CREATE TABLE `test_char` ( `a` char(10) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) mysql> insert into test_char values('abc'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_char values('启明星'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_char values('启明星hh'); Query OK, 1 row affected (0.00 sec) mysql> insert into test_char values('启明hh星'); Query OK, 1 row affected (0.00 sec) mysql> insert into test_char values('启明hh星啊'); Query OK, 1 row affected (0.01 sec) mysql> select a, length(a) from test_char; +----------------+-----------+ | a | length(a) | +----------------+-----------+ | abc | 3 | | 启明星 | 9 | | 启明星hh | 11 | | 启明hh星 | 11 | | 启明hh星啊 | 14 | +----------------+-----------+ 5 rows in set (0.01 sec) mysql> select a, hex(a) from test_char; +----------------+------------------------------+ | a | hex(a) | +----------------+------------------------------+ | abc | 616263 | | 启明星 | E590AFE6988EE6989F | | 启明星hh | E590AFE6988EE6989F6868 | | 启明hh星 | E590AFE6988E6868E6989F | | 启明hh星啊 | E590AFE6988E6868E6989FE5958A | +----------------+------------------------------+ 5 rows in set (0.00 sec) mysql> select hex(' '); +----------+ | hex(' ') | +----------+ | 20 | +----------+ 1 row in set (0.00 sec) 用hexdump来比较一下： -- 1:abc -- 2:启明星 -- 3:启明星hh -- 4:启明hh星 -- 5:启明ab星啊 [root@nazeebo test]# hexdump -C test_char.ibd ... ... 00006070 73 75 70 72 65 6d 75 6d 0a 00 00 00 10 00 24 00 |supremum......$.| 00006080 00 00 00 02 07 00 00 00 00 0a b5 fe 00 00 00 48 |...............H| 00006090 01 10 61 62 63 20 20 20 20 20 20 20 0a 00 00 00 |..abc ....| 000060a0 18 00 24 00 00 00 00 02 08 00 00 00 00 0a b6 ff |..$.............| 000060b0 00 00 00 4c 01 10 e5 90 af e6 98 8e e6 98 9f 20 |...L........... | 000060c0 0b 00 00 00 20 00 25 00 00 00 00 02 09 00 00 00 |.... .%.........| 000060d0 00 0a bb a2 00 00 00 4d 01 10 e5 90 af e6 98 8e |.......M........| 000060e0 e6 98 9f 68 68 0b 00 00 00 28 00 25 00 00 00 00 |...hh....(.%....| 000060f0 02 0a 00 00 00 00 0a bc a3 00 00 00 49 01 10 e5 |............I...| 00006100 90 af e6 98 8e 68 68 e6 98 9f 0e 00 00 00 30 ff |.....hh.......0.| 00006110 5f 00 00 00 00 02 0b 00 00 00 00 0a c1 a6 00 00 |_...............| 00006120 00 4a 01 10 e5 90 af e6 98 8e 68 68 e6 98 9f e5 |.J........hh....| 00006130 95 8a 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00006140 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| ... 省略一部分输出 ... [root@nazeebo test]# 2.varchar(N)说明 mysql> create table test_varchar(a varchar(10)); Query OK, 0 rows affected (0.03 sec) mysql> show create table test_varchar \\G *************************** 1. row *************************** Table: test_varchar Create Table: CREATE TABLE `test_varchar` ( `a` varchar(10) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) mysql> insert into test_varchar values('abc'); Query OK, 1 row affected (0.00 sec) mysql> insert into test_varchar values('启明星'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_varchar values('启明星hh'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_varchar values('启明hh星'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_varchar values('启明hh星啊'); Query OK, 1 row affected (0.01 sec) mysql> select a, hex(a) from test_varchar; +----------------+------------------------------+ | a | hex(a) | +----------------+------------------------------+ | abc | 616263 | | 启明星 | E590AFE6988EE6989F | | 启明星hh | E590AFE6988EE6989F6868 | | 启明hh星 | E590AFE6988E6868E6989F | | 启明hh星啊 | E590AFE6988E6868E6989FE5958A | +----------------+------------------------------+ 5 rows in set (0.01 sec) mysql> select a, length(a) from test_varchar; +----------------+-----------+ | a | length(a) | +----------------+-----------+ | abc | 3 | | 启明星 | 9 | | 启明星hh | 11 | | 启明hh星 | 11 | | 启明hh星啊 | 14 | +----------------+-----------+ 5 rows in set (0.00 sec) [root@nazeebo test]# hexdump -C test_varchar.ibd ... ... 00006070 73 75 70 72 65 6d 75 6d 03 00 00 00 10 00 1d 00 |supremum........| 00006080 00 00 00 02 0c 00 00 00 00 0a c6 ab 00 00 00 51 |...............Q| 00006090 01 10 61 62 63 09 00 00 00 18 00 23 00 00 00 00 |..abc......#....| 000060a0 02 0d 00 00 00 00 0a c7 ac 00 00 00 4c 01 10 e5 |............L...| 000060b0 90 af e6 98 8e e6 98 9f 0b 00 00 00 20 00 25 00 |............ .%.| 000060c0 00 00 00 02 0e 00 00 00 00 0a cc af 00 00 00 4d |...............M| 000060d0 01 10 e5 90 af e6 98 8e e6 98 9f 68 68 0b 00 00 |...........hh...| 000060e0 00 28 00 25 00 00 00 00 02 0f 00 00 00 00 0a cd |.(.%............| 000060f0 b0 00 00 00 4b 01 10 e5 90 af e6 98 8e 68 68 e6 |....K........hh.| 00006100 98 9f 0e 00 00 00 30 ff 67 00 00 00 00 02 10 00 |......0.g.......| 00006110 00 00 00 0a d2 b3 00 00 00 4c 01 10 e5 90 af e6 |.........L......| 00006120 98 8e 68 68 e6 98 9f e5 95 8a 00 00 00 00 00 00 |..hh............| 00006130 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| ... ... 3.char和varchar的区别 char用于定长，范围0-255，如果字符数没有到达定义的长度，会在后面用空格补全存入数据库；如果超过指定长度大小，会被截断。 varchar用于变长，范围0-65535，存储时按大小存取不会补空格，超过长度会截取。 使用varchar类型时，和字符集有关，会多用1~2个字节来记录字节长度，当数据位战友的字节数小于255时，用1个字节来记录长度，当数据位战友的字节数大于255时，用2个字节来记录长度，另外一位用来记录是否为null值 MySQL每一行的最大字节数为65535 使用UTF8字符集的时候，每个字符最多占3个字节，最大长度不超过(65535-2-1)/3=21844 使用GBK字符集的时候，每个字符最多占用2个字节，最大长度不超（65535-2-1）/ 2 = 36766 4.BLOB和TEXT 在BLOB和TEXT上创建索引时，必须指定索引前缀的长度 mysql> create table test_text(a int primary key, b text, key(b)); ERROR 1170 (42000): BLOB/TEXT column 'b' used in key specification without a key length mysql> create table test_text(a int primary key, b text, key(b(64))); Query OK, 0 rows affected (0.02 sec) mysql> select @@max_sort_length; +-------------------+ | @@max_sort_length | +-------------------+ | 1024 | +-------------------+ 1 row in set (0.00 sec) mysql> BLOB和TEXT列不能有默认值 BLOB和TEXT列排序时只使用该列的前max_sort_length个字节 四、集合类型enum 和 set enum允许最多65536个值 set允许最多64个值 通过sql_mode进行约束 1.集合的插入 //创建一个表，含有enum类型，插入几条数据 //虽然enum写的是字符串，单其实存储的整型，效率还行 mysql> create table test_col( -> user varchar(10), -> sex enum('male','female') -> ); Query OK, 0 rows affected (0.02 sec) mysql> insert into test_col values (\"tom\", \"male\"); Query OK, 1 row affected (0.00 sec) //插入错误的enum，会有warings，并且相应的值被截断直接为空 mysql> insert into test_col values (\"tom\", \"xmale\"); Query OK, 1 row affected, 1 warning (0.01 sec) mysql> show warnings; +---------+------+------------------------------------------+ | Level | Code | Message | +---------+------+------------------------------------------+ | Warning | 1265 | Data truncated for column 'sex' at row 1 | +---------+------+------------------------------------------+ 1 row in set (0.00 sec) mysql> select * from test_col; +------+------+ | user | sex | +------+------+ | tom | male | | tom | | +------+------+ 2 rows in set (0.00 sec) //设置sql_mode，发现错误的enum类型是插入不进去的 mysql> set sql_mode='strict_trans_tables'; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> insert into test_col values (\"bob\", \"xmale\"); ERROR 1265 (01000): Data truncated for column 'sex' at row 1 mysql> select * from test_col; +------+------+ | user | sex | +------+------+ | tom | male | | tom | | +------+------+ 2 rows in set (0.00 sec) 建议业务上都设置成严格模式 另外，虽然enum写的是字符串，单其实存储的是int类型数组(相当于male=0，female=1)，性能还是可以的 2.集合的排序 mysql> show create table test_col_sort\\G *************************** 1. row *************************** Table: test_col_sort Create Table: CREATE TABLE `test_col_sort` ( `user` char(10) DEFAULT NULL, `type` enum('aaa','zzz','bbb','yyy','fff') DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) //插入数据 mysql> insert into test_col_sort(user,type) values('user1','aaa'),('user2','bbb'),('user3','yyy'),('user4','zzz'); Query OK, 4 rows affected (0.01 sec) Records: 4 Duplicates: 0 Warnings: 0 //order by type 就等于按照enum里面的顺序，[0,1,2,3] mysql> select * from test_col_sort order by type asc; +-------+------+ | user | type | +-------+------+ | user1 | aaa | | user4 | zzz | | user2 | bbb | | user3 | yyy | +-------+------+ 4 rows in set (0.00 sec) //order by cast(type as char) ，意思是将type转换为char再进行排序 mysql> select * from test_col_sort order by cast(type as char) asc; +-------+------+ | user | type | +-------+------+ | user1 | aaa | | user2 | bbb | | user3 | yyy | | user4 | zzz | +-------+------+ 4 rows in set (0.00 sec) //order by concat mysql> select * from test_col_sort order by concat(type) asc; +-------+------+ | user | type | +-------+------+ | user1 | aaa | | user2 | bbb | | user3 | yyy | | user4 | zzz | +-------+------+ 4 rows in set (0.00 sec) 五、日期类型 日期类型 占用字节 表示范围 DATETIME 8 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 DATE 3 1000-01-01 ~ 9999-12-31 TIMESTAMP 4 1970-01-01 00:00:00UTC ~ 2038-01-19 03:14:07UTC YEAR 1 YEAR(2):1970-2070, YEAR(4):1901-2155 TIME 3 -838:59:59 ~ 838:59:59 1.TIMESTAMP 和 DATETIME datetime与timestamp最大的区别在于时区 mysql> create table test_time(a timestamp, b datetime); Query OK, 0 rows affected (0.02 sec) mysql> insert into test_time values (now(), now()); Query OK, 1 row affected (0.01 sec) mysql> select * from test_time; +---------------------+---------------------+ | a | b | +---------------------+---------------------+ | 2018-06-29 00:28:40 | 2018-06-29 00:28:40 | +---------------------+---------------------+ 1 row in set (0.00 sec) mysql> select @@time_zone; +-------------+ | @@time_zone | +-------------+ | SYSTEM | +-------------+ 1 row in set (0.00 sec) mysql> set time_zone='+00:00'; Query OK, 0 rows affected (0.00 sec) mysql> select @@time_zone; +-------------+ | @@time_zone | +-------------+ | +00:00 | +-------------+ 1 row in set (0.00 sec) //设置了时区后，两者有了差别 mysql> select * from test_time; +---------------------+---------------------+ | a | b | +---------------------+---------------------+ | 2018-06-28 16:28:40 | 2018-06-29 00:28:40 | +---------------------+---------------------+ 1 row in set (0.00 sec) 2.微秒解读 MySQL5.6.4版本开始支持微秒 支持类型包括：time 、datetime与 、timestamp type_name(fsp) fsp //用法 type_name(fsp) fsp select now(5); +---------------------------+ | now(5) | +---------------------------+ | 2018-06-28 16:34:10.64251 | +---------------------------+ 1 row in set (0.00 sec) mysql> select now(6); +----------------------------+ | now(6) | +----------------------------+ | 2018-06-28 16:34:36.658036 | +----------------------------+ 1 row in set (0.00 sec) // 最多支持6位精度 mysql> select now(7); ERROR 1426 (42000): Too-big precision 7 specified for 'now'. Maximum is 6. mysql> mysql> create table test_time_fac (t datetime(6)); Query OK, 0 rows affected (0.02 sec) mysql> insert into test_time_fac values(now(6)); Query OK, 1 row affected (0.01 sec) mysql> select * from test_time_fac; +----------------------------+ | t | +----------------------------+ | 2018-06-28 16:35:04.557430 | +----------------------------+ 1 row in set (0.00 sec) 3.日期函数 函数 说明 备注 NOW 返回sql执行时的时间 如果不考虑其他因素，可以理解为写完SQL，敲下回车瞬间的时间 current_timestamp 与now一样 sysdate 返回执行函数时的时间 MySQL处理你的函数时的时间，统一SQL语句中，大于NOW date_add(date,interval expr unit) 增加时间 可用ADD，然后unit给负数 date_sub(date,interval expr unit) 减少时间 date_format 格式化时间显示 3.1 NOW 和 SYSDATE的区别 mysql> select now(6),sysdate(6),sleep(5),now(6),sysdate(6); +----------------------------+----------------------------+----------+----------------------------+----------------------------+ | now(6) | sysdate(6) | sleep(5) | now(6) | sysdate(6) | +----------------------------+----------------------------+----------+----------------------------+----------------------------+ | 2018-06-29 00:38:59.002591 | 2018-06-29 00:38:59.002708 | 0 | 2018-06-29 00:38:59.002591 | 2018-06-29 00:39:04.002832 | +----------------------------+----------------------------+----------+----------------------------+----------------------------+ 1 row in set (5.00 sec) 两个now(6)都相等，因为是SQL执行时的时间(可以简单理解为按回车的时间) 两个sysdate(6)差了5秒，差不多刚好是sleep(5)的时间 3.2 date_add的使用方法 //加5天 mysql> select now(),date_add(now(), interval 5 day); +---------------------+---------------------------------+ | now() | date_add(now(), interval 5 day) | +---------------------+---------------------------------+ | 2018-06-29 00:41:03 | 2018-07-04 00:41:03 | +---------------------+---------------------------------+ 1 row in set (0.00 sec) //加负的5个月=倒退5个月 mysql> select now(),date_add(now(), interval -5 month); +---------------------+------------------------------------+ | now() | date_add(now(), interval -5 month) | +---------------------+------------------------------------+ | 2018-06-29 00:41:28 | 2018-01-29 00:41:28 | +---------------------+------------------------------------+ 1 row in set (0.00 sec) //减5个月 mysql> select now(),date_sub(now(), interval 5 month); +---------------------+-----------------------------------+ | now() | date_sub(now(), interval 5 month) | +---------------------+-----------------------------------+ | 2018-06-29 00:41:43 | 2018-01-29 00:41:43 | +---------------------+-----------------------------------+ 1 row in set (0.00 sec) 3.3 date_format的用法 mysql> SELECT now(),DATE_FORMAT((select now(6)), '%H:%i:%s'); +---------------------+------------------------------------------+ | now() | DATE_FORMAT((select now(6)), '%H:%i:%s') | +---------------------+------------------------------------------+ | 2018-06-29 00:44:46 | 00:44:46 | +---------------------+------------------------------------------+ 1 row in set (0.00 sec) 3.4 字段更新时间 mysql> create table test_field_update( -> a int(10), -> b timestamp not null default current_timestamp on update current_timestamp -> ); Query OK, 0 rows affected (0.03 sec) mysql> insert into test_field_update values(1, now(6)); Query OK, 1 row affected (0.00 sec) mysql> select * from test_field_update; +------+---------------------+ | a | b | +------+---------------------+ | 1 | 2018-06-29 00:45:46 | +------+---------------------+ 1 row in set (0.00 sec) //更新数据，发现相应的字段的数据也更新了，这个可以拿来用在记录记录的表更上 //当然，如果想更精确，可以使用timestamp，now(6) mysql> update test_field_update set a=100 where a=1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_field_update; +------+---------------------+ | a | b | +------+---------------------+ | 100 | 2018-06-29 00:46:01 | +------+---------------------+ 1 row in set (0.00 sec) 六、JSON类型 5.7版本开始支持 原生json类型用来替代BLOB json数据有效性检查：blob类型无法在数据库层做这样的约束性检查，而json类型可以 查询性能的提升：查询不需要遍历所有的字符串才能找到数据 支持部分属性索引：通过虚拟列的功能可以对json中的部分数据进行索引 1.JSON格式示例(wiki百科) { \"firstName\": \"John\", //Key: Value 格式 \"lastName\": \"Smith\", \"sex\": \"male\", \"age\": 25, \"address\": //Key: Value;其中 Value 也是一个 Key - Value 的结构 { \"streetAddress\": \"21 2nd Street\", \"city\": \"New York\", \"state\": \"NY\", \"postalCode\": \"10021\" }, \"phoneNumber\": [{ \"type\": \"home\", \"number\": \"212 555-1234\" }, { \"type\": \"fax\", \"number\": \"646 555-4567\" } ] } 2. JSON 和 BLOB 的对比 JSON： JSON数据可以做有效性检查; JSON使得查询性能提升; JSON支持部分属性索引，通过虚拟列的功能可以对JSON中的部分数据进行索引; BLOB： BLOB类型无法在数据库层做约束性检查; BLOB进行查询，需要遍历所有字符串; BLOB做只能做指定长度的索引; 5.7之前，只能把JSON当作BLOB进行存储。数据库层面无法对JSON数据做一些操作，只能由应用程序处理。 3. 结构化和非结构化 结构化 二维表结构（行和列） 使用SQL语句进行操作 非结构化 使用Key-Value格式定义数据，无结构定义 Value可以嵌套Key-Value格式的数据 使用JSON进行实现 4. json示例 mysql> create table test_json ( -> uid int auto_increment, -> data json, -> primary key(uid) -> ); Query OK, 0 rows affected (0.02 sec) mysql> mysql> insert into test_json values ( -> null, -- 自增长数据，可以插入null -> '{ '> \"name\":\"nazeebo\", '> \"age\":38, '> \"address\":\"CD\" '> }' -> ); Query OK, 1 row affected (0.00 sec) mysql> insert into test_json values ( -> null, -> '{ '> \"name\":\"lowa\", '> \"age\":37, '> \"mail\":\"lowa@bxbb.com\" '> }' -> ); Query OK, 1 row affected (0.00 sec) // 无法插入，因为是JSON类型 mysql> insert into test_json values ( null, \"今晚打老虎\"); ERROR 3140 (22032): Invalid JSON text: \"Invalid value.\" at position 0 in value for column 'test_json.data'. mysql> mysql> select * from test_json; +-----+------------------------------------------------------+ | uid | data | +-----+------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": \"CD\"} | //这个json中有address字段 | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | //这个json中有mail字段 +-----+------------------------------------------------------+ 2 rows in set (0.00 sec) mysql> 5. json的相关函数 5.1 使用json_extract提取数据 mysql> select json_extract('[10, 20, [30, 40]]', '$[1]'); +--------------------------------------------+ | json_extract('[10, 20, [30, 40]]', '$[1]') | +--------------------------------------------+ | 20 | // 从list中抽取 下标 为1的元素（下标从0开始） +--------------------------------------------+ 1 row in set (0.00 sec) mysql> select -> json_extract(data, '$.name'), -- 提起name字段的数据 -> json_extract(data, '$.address') -- 提取address字段的数据 -> from test_json; +------------------------------+---------------------------------+ | json_extract(data, '$.name') | json_extract(data, '$.address') | +------------------------------+---------------------------------+ | \"nazeebo\" | \"CD\" | | \"lowa\" | NULL | // lowa 没有address字段，填充了NULL +------------------------------+---------------------------------+ 2 rows in set (0.00 sec) 5.2 使用json_object 将list(K-V对)封装成json格式 mysql> select json_object(\"name\", \"lm\", \"email\", \"limin@bxbb.com\", \"age\",99); +----------------------------------------------------------------+ | json_object(\"name\", \"lm\", \"email\", \"limin@bxbb.com\", \"age\",99) | +----------------------------------------------------------------+ | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +----------------------------------------------------------------+ 1 row in set (0.00 sec) mysql> insert into test_json values ( -> null, -> json_object(\"name\", \"lm\", \"email\", \"limin@bxbb.com\", \"age\",99) -- 进行封装 -> ); Query OK, 1 row affected (0.00 sec) mysql> select * from test_json; +-----+------------------------------------------------------+ | uid | data | +-----+------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": \"CD\"} | | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+------------------------------------------------------+ 3 rows in set (0.00 sec) 5.3 使用json_insert 插入数据 mysql> set @j = '{ \"a\": 1, \"b\": [2, 3]}'; Query OK, 0 rows affected (0.00 sec) mysql> select json_insert(@j, '$.a', 10, '$.c', '[true, false]'); +----------------------------------------------------+ | json_insert(@j, '$.a', 10, '$.c', '[true, false]') | +----------------------------------------------------+ | {\"a\": 1, \"b\": [2, 3], \"c\": \"[true, false]\"} | //存在的不受影响，例如a还是=1 +----------------------------------------------------+ //c之前不存在，则插入 1 row in set (0.00 sec) mysql> mysql> select * from test_json; +-----+------------------------------------------------------+ | uid | data | +-----+------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": \"CD\"} | | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+------------------------------------------------------+ 3 rows in set (0.01 sec) // 插入 addres_2 mysql> update test_json set data = json_insert(data, \"$.address_2\", \"BJ\") where uid = 1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_json; +-----+--------------------------------------------------------------------+ | uid | data | +-----+--------------------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": \"CD\", \"address_2\": \"BJ\"} | //对比发现插入了 addres_2 | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+--------------------------------------------------------------------+ 3 rows in set (0.00 sec) 5.4 使用json_merge 合并数据并返回 注意：原数据不受影响 mysql> select json_merge('{\"name\": \"zxx\"}', '{\"id\": 9527}'); +-----------------------------------------------+ | json_merge('{\"name\": \"zxx\"}', '{\"id\": 9527}') | +-----------------------------------------------+ | {\"id\": 9527, \"name\": \"zxx\"} | +-----------------------------------------------+ 1 row in set, 1 warning (0.00 sec) mysql> select -> json_merge( -> json_extract(data, '$.address'), -- json 1 -> json_extract(data, '$.address_2')) -- jons 2 -> from test_json where uid = 1; +----------------------------------------------------------------------------------+ | json_merge( json_extract(data, '$.address'), json_extract(data, '$.address_2')) | +----------------------------------------------------------------------------------+ | [\"CD\", \"BJ\"] | +----------------------------------------------------------------------------------+ 1 row in set, 1 warning (0.00 sec) mysql> show warnings; +---------+------+-----------------------------------------------------------------------------------------------------------------------------+ | Level | Code | Message | +---------+------+-----------------------------------------------------------------------------------------------------------------------------+ | Warning | 1287 | 'JSON_MERGE' is deprecated and will be removed in a future release. Please use JSON_MERGE_PRESERVE/JSON_MERGE_PATCH instead | +---------+------+-----------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql> select -> JSON_MERGE_PRESERVE( -> json_extract(data, '$.address'), -- json 1 -> json_extract(data, '$.address_2')) -- jons 2 -> from test_json where uid = 1; +-------------------------------------------------------------------------------------------+ | JSON_MERGE_PRESERVE( json_extract(data, '$.address'), json_extract(data, '$.address_2')) | +-------------------------------------------------------------------------------------------+ | [\"CD\", \"BJ\"] | +-------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql> 5.5 使用json_array_append 追加数据 mysql> set @j = '[\"a\", [\"b\", \"c\"], \"d\"]'; Query OK, 0 rows affected (0.00 sec) mysql> select json_array_append(@j, '$[1]', 1); +----------------------------------+ | json_array_append(@j, '$[1]', 1) | +----------------------------------+ | [\"a\", [\"b\", \"c\", 1], \"d\"] | //下标为1的值，增加“1” +----------------------------------+ 1 row in set (0.00 sec) mysql> update test_json set data = json_array_append( -> data, -> '$.address', -> json_extract(data, '$.address_2')) -> where uid = 1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_json; +-----+----------------------------------------------------------------------------+ | uid | data | +-----+----------------------------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": [\"CD\", \"BJ\"], \"address_2\": \"BJ\"} | //将address2的值添加到了address中去 | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+----------------------------------------------------------------------------+ 3 rows in set (0.00 sec) 5.6 使用json_remove 从json记录中删除数据 mysql> set @j = '[\"a\", [\"b\", \"c\"], \"d\"]'; Query OK, 0 rows affected (0.00 sec) mysql> select json_remove(@j, '$[1]'); +-------------------------+ | json_remove(@j, '$[1]') | +-------------------------+ | [\"a\", \"d\"] | //删除下标为1的key和value +-------------------------+ 1 row in set (0.00 sec) mysql> update test_json set data = json_remove(data, \"$.address_2\") where uid = 1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_json; +-----+---------------------------------------------------------+ | uid | data | +-----+---------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": [\"CD\", \"BJ\"]} | // address_2 的字段删除了 | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+---------------------------------------------------------+ 3 rows in set (0.00 sec) 6. json 字段创建索引 JSON 类型数据本身 无法直接 创建索引，需要将需要索引的 JSON数据 重新生成虚拟列(Virtual Columns) 之后，对该列进行索引 6.1 新建表的时候创建json索引 1.创建表，建表的语法中抽取data中的name， 生成新的一列，名字为gen_col mysql> create table test_json_index( -> data json, -> gen_col varchar(10) generated always as (json_extract(data, '$.name')), -> index idx (gen_col) -- 将gen_col 作为索引 -> ); Query OK, 0 rows affected (0.03 sec) mysql> show create table test_json_index\\G *************************** 1. row *************************** Table: test_json_index Create Table: CREATE TABLE `test_json_index` ( `data` json DEFAULT NULL, `gen_col` varchar(10) GENERATED ALWAYS AS (json_extract(`data`,'$.name')) VIRTUAL, KEY `idx` (`gen_col`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) 2.插入两条数据 mysql> insert into test_json_index(data) values ('{\"name\":\"lowa\", \"age\":38, \"address\":\"CD\"}'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_json_index(data) values ('{\"name\":\"nazeebo\", \"age\":66, \"address\":\"SZ\"}'); Query OK, 1 row affected (0.00 sec) mysql> select * from test_json_index; +-------------------------------------------------+-----------+ | data | gen_col | +-------------------------------------------------+-----------+ | {\"age\": 38, \"name\": \"lowa\", \"address\": \"CD\"} | \"lowa\" | | {\"age\": 66, \"name\": \"nazeebo\", \"address\": \"SZ\"} | \"nazeebo\" | +-------------------------------------------------+-----------+ 2 rows in set (0.00 sec) 3.查询的时候发现找不到记录 mysql> select json_extract(data,\"$.name\") as username from test_json_index where gen_col=\"lowa\"; Empty set (0.00 sec) 4.原因是因为存储的时候连“”也存储了的 mysql> select hex('\"'); +----------+ | hex('\"') | +----------+ | 22 | +----------+ 1 row in set (0.00 sec) mysql> select hex(gen_col) from test_json_index; +--------------------+ | hex(gen_col) | +--------------------+ | 226C6F776122 | | 226E617A6565626F22 | +--------------------+ 2 rows in set (0.00 sec) 5.所以带上双引号再去查询就可以得到正确的结果集 mysql> select json_extract(data,\"$.name\") as username from test_json_index where gen_col='\"lowa\"'; +----------+ | username | +----------+ | \"lowa\" | +----------+ 1 row in set (0.00 sec) 6.查看执行计划，使用了index的 mysql> explain select json_extract(data,\"$.name\") as username from test_json_index where gen_col='\"lowa\"' \\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_json_index partitions: NULL type: ref possible_keys: idx key: idx key_len: 43 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 7.为了避免出现连双引号一起存储的情况，采用json_unquote函数进行去掉双引号创建新的表test_json_index_2 mysql> create table test_json_index_2 ( -> data json, -> gen_col varchar(10) generated always as ( -> json_unquote( -- 使用json_unquote函数进行去掉双引号 -> json_extract(data, \"$.name\") -> )), -> key idx(gen_col) -> ); Query OK, 0 rows affected (0.02 sec) mysql> show create table test_json_index_2\\G *************************** 1. row *************************** Table: test_json_index_2 Create Table: CREATE TABLE `test_json_index_2` ( `data` json DEFAULT NULL, `gen_col` varchar(10) GENERATED ALWAYS AS (json_unquote(json_extract(`data`,'$.name'))) VIRTUAL, KEY `idx` (`gen_col`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.01 sec) 8.再次插入两条记录 mysql> insert into test_json_index_2(data) values ('{\"name\":\"lowa\", \"age\":38, \"address\":\"CD\"}'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_json_index_2(data) values ('{\"name\":\"nazeebo\", \"age\":66, \"address\":\"SZ\"}'); Query OK, 1 row affected (0.00 sec) 9.再次查询，发现能正确的获取到结果集 mysql> select json_extract(data,\"$.name\") as username from test_json_index_2 where gen_col=\"lowa\"; +----------+ | username | +----------+ | \"lowa\" | +----------+ 1 row in set (0.00 sec) 10.查询执行计划，发现也使用了index mysql> explain select json_extract(data,\"$.name\") as username from test_json_index_2 where gen_col=\"lowa\"\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_json_index_2 partitions: NULL type: ref possible_keys: idx key: idx key_len: 43 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) 6.2 修改已存在的表创建JSON索引 1.拿之前创建好的表test_json来做实验 mysql> show create table test_json\\G *************************** 1. row *************************** Table: test_json Create Table: CREATE TABLE `test_json` ( `uid` int(11) NOT NULL AUTO_INCREMENT, `data` json DEFAULT NULL, PRIMARY KEY (`uid`) ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) mysql> select * from test_json; +-----+---------------------------------------------------------+ | uid | data | +-----+---------------------------------------------------------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": [\"CD\", \"BJ\"]} | | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | +-----+---------------------------------------------------------+ 3 rows in set (0.00 sec) 2.创建虚拟列 **注意：virtual 关键字是不将该列的字段值存储，对应的是stored** mysql> alter table test_json -> add user_name varchar(32) -> generated always as (json_extract(data,\"$.name\")) virtual; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> select * from test_json; +-----+---------------------------------------------------------+-----------+ | uid | data | user_name | +-----+---------------------------------------------------------+-----------+ | 1 | {\"age\": 38, \"name\": \"nazeebo\", \"address\": [\"CD\", \"BJ\"]} | \"nazeebo\" | | 2 | {\"age\": 37, \"mail\": \"lowa@bxbb.com\", \"name\": \"lowa\"} | \"lowa\" | | 3 | {\"age\": 99, \"name\": \"lm\", \"email\": \"limin@bxbb.com\"} | \"lm\" | +-----+---------------------------------------------------------+-----------+ 3 rows in set (0.00 sec) 3.添加索引 mysql> alter table test_json add index idx(user_name); Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 4.查看执行计划 mysql> explain select * from test_json where user_name='\"lowa\"'\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_json partitions: NULL type: ref possible_keys: idx key: idx key_len: 131 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) mysql> show create table test_json\\G *************************** 1. row *************************** Table: test_json Create Table: CREATE TABLE `test_json` ( `uid` int(11) NOT NULL AUTO_INCREMENT, `data` json DEFAULT NULL, `user_name` varchar(32) GENERATED ALWAYS AS (json_extract(`data`,'$.name')) VIRTUAL, PRIMARY KEY (`uid`), KEY `idx` (`user_name`) ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) 七、字符集相关 1. MySQL字符集包括： 字符集(character) --用于定义字符串的存储方式 校对规则(collation) --用于定义比较字符串的方式 常用的字符集： utf8：最常用的字符集，占3个字节 utf8mb4：utf8的超级，占4个字节 gbk ： 占2个字节，通用性没有utf8好 gb18030： 是最新的汉字编码字符集国家标准, 向下兼容 GBK 和 GB2312 标准，编码是一二四字节变长编码 mysql> show character set; +----------+---------------------------------+---------------------+--------+ | Charset | Description | Default collation | Maxlen | +----------+---------------------------------+---------------------+--------+ | big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 | | dec8 | DEC West European | dec8_swedish_ci | 1 | | cp850 | DOS West European | cp850_general_ci | 1 | | hp8 | HP West European | hp8_english_ci | 1 | | koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 | | latin1 | cp1252 West European | latin1_swedish_ci | 1 | | latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 | | swe7 | 7bit Swedish | swe7_swedish_ci | 1 | | ascii | US ASCII | ascii_general_ci | 1 | | ujis | EUC-JP Japanese | ujis_japanese_ci | 3 | | sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 | | hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 | | tis620 | TIS620 Thai | tis620_thai_ci | 1 | | euckr | EUC-KR Korean | euckr_korean_ci | 2 | | koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 | | gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 | | greek | ISO 8859-7 Greek | greek_general_ci | 1 | | cp1250 | Windows Central European | cp1250_general_ci | 1 | | gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 | | latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 | | armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 | | utf8 | UTF-8 Unicode | utf8_general_ci | 3 | | ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 | | cp866 | DOS Russian | cp866_general_ci | 1 | | keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 | | macce | Mac Central European | macce_general_ci | 1 | | macroman | Mac West European | macroman_general_ci | 1 | | cp852 | DOS Central European | cp852_general_ci | 1 | | latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 | | utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 | | cp1251 | Windows Cyrillic | cp1251_general_ci | 1 | | utf16 | UTF-16 Unicode | utf16_general_ci | 4 | | utf16le | UTF-16LE Unicode | utf16le_general_ci | 4 | | cp1256 | Windows Arabic | cp1256_general_ci | 1 | | cp1257 | Windows Baltic | cp1257_general_ci | 1 | | utf32 | UTF-32 Unicode | utf32_general_ci | 4 | | binary | Binary pseudo charset | binary | 1 | | geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 | | cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 | | eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 | | gb18030 | China National Standard GB18030 | gb18030_chinese_ci | 4 | +----------+---------------------------------+---------------------+--------+ 41 rows in set (0.00 sec) 2. collation（排序规则） collation的含义是指排序规则， ci（case insensitive） 结尾的排序集是不区分大小写的 mysql> select 'a' = 'A'; +-----------+ | 'a' = 'A' | +-----------+ | 1 | +-----------+ 1 row in set (0.00 sec) mysql> create table test_ci (a varchar(10), key(a)); Query OK, 0 rows affected (0.03 sec) mysql> insert into test_ci values('a'); Query OK, 1 row affected (0.01 sec) mysql> insert into test_ci values('A'); Query OK, 1 row affected (0.01 sec) mysql> select * from test_ci where a = 'a'; +------+ | a | +------+ | a | | A | +------+ 2 rows in set (0.00 sec) 是不是感觉很神奇！！！a=A 居然是TRUE！ 解释一下为什么会出现以上的情况。 首先，查下默认的排序规则 mysql> show variables like '%coll%'; +----------------------+--------------------+ | Variable_name | Value | +----------------------+--------------------+ | collation_connection | utf8_general_ci | | collation_database | utf8mb4_general_ci | | collation_server | utf8mb4_general_ci | +----------------------+--------------------+ 3 rows in set (0.00 sec) ci（case insensitive） 结尾的排序集是不区分大小写的，所以才有了以上的结果 // 修改当前session的collate，a终于不等于A 了，但是表里面的数据还是 a=A mysql> set names utf8mb4 collate utf8mb4_bin; Query OK, 0 rows affected (0.00 sec) mysql> select 'a' = 'A'; +-----------+ | 'a' = 'A' | +-----------+ | 0 | +-----------+ 1 row in set (0.00 sec) mysql> select * from test_ci where a = 'a'; +------+ | a | +------+ | a | | A | +------+ 2 rows in set (0.00 sec) //修改了session的collate对表数据不起作用，因为表自身也有collate。 //尝试给表修改collate mysql> alter table test_ci collate utf8mb4_bin; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 //发现还是a=A，这是因为只修改collate，对已经存在的数据不起作用 mysql> select * from test_ci where a = 'a'; +------+ | a | +------+ | a | | A | +------+ 2 rows in set (0.00 sec) // 要使得已经存在的数据也修改新的collate，需要用convert命令进行转换 mysql> alter table test_ci convert to character set utf8mb4 collate utf8mb4_bin; Query OK, 2 rows affected (0.07 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> select * from test_ci where a = 'a'; +------+ | a | +------+ | a | +------+ 1 row in set (0.00 sec) mysql> //另外，如果没有数据，可以直接用下面的sql进行修改 mysql> alter table test_ci character set utf8mb4 collate utf8mb4_bin; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 3. 乱码问题 字符集涉及的范围很广，像程序链接、数据库、服务器、表以及表中的字段、结果集，都会涉及到字符集。字符集最容易遇到的问题就是乱码。 mysql> show variables like '%char%'; +--------------------------+----------------------------------------------------------------+ | Variable_name | Value | +--------------------------+----------------------------------------------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/local/mysql-5.7.22-linux-glibc2.12-x86_64/share/charsets/ | +--------------------------+----------------------------------------------------------------+ 8 rows in set (0.00 sec) 如何解决乱码呢？ 答案是：保证三者一致。 三者包括：连接终端的字符集、操作系统的字符集、MySQL数据库的字符集。 如果想要临时的修改数据库字符集，可以在数据库命令行执行set names xxx来实现。 三者统一都是UTF8，就不会出现中文乱码的情况了。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-29 17:51:08 "},"9.createtable.html":{"url":"9.createtable.html","title":"9.表的创建","keywords":"","body":" 一、表的介绍 1. 表的概念 2. 表是数据的集合 二、表的创建 1.临时表 2. 普通表的创建 三、外键 1. 外键示例 2. 外键的级联更新与删除示例 3. 外键的选项及说明 四、表碎片 1. 表碎片产生的现象及原因 2. 碎片计算方法及整理方法 五、表的统计信息 1. 统计信息存放位置 2. 如何查看统计信息 3. 收集统计信息 4. 相关参数说明： 一、表的介绍 1. 表的概念 表是关系数据库的核心 表 = 关系 表是记录的集合 二维表模型易于人的理解 MySQL默认存储引擎都是基于行(记录)存储 每行记录都是基于列进行组织的 2. 表是数据的集合 select * from table_name limit 1; 集合是无序的，上面的SQL语句的意思是 从表(集合)中 随机 选出一条数据，结果是不确定的, 不能简单的认为是取出第一条数据。 select * from table_name order by col_name limit 1; 只有通过 order by 排序之后取出的数据，才是确定的 二、表的创建 1.临时表 临时表主要的作用是给当前登录的用户存储临时数据或者临时结果的。 临时表使用注意事项： 1.临时表是 SESSION 级别的, 当前用户logout或者其他用户登录上来，是无法看到这张表的 2.show tables命令不显示temp table 3.当临时表和普通表同名时，当前用户只能看到同名的临时表 4.创建表时带上 if not exists 进行表的存在性检查；同时建议在临时表的表名前面加上统一的 prefix 5.在MySQL 5.6.X 中没有 innodb_temp_data_file_path 变量 6.MySQL5.7.X 把临时 表结构 放在 tmpdir ，而数据 表数据 放在 datadir 7.MySQL5.6.X 把临时 表结构 和 表数据 都放在 tmpdir 8.不要和SQL优化器在排序过程中内部创建的临时表相混淆。 1.1 查看相关初始化参数 1.查看临时表的默认的存储引擎 mysql> show variables like '%storage%'; +----------------------------------+--------+ | Variable_name | Value | +----------------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_disk_storage_engine | InnoDB | +----------------------------------+--------+ 4 rows in set (0.00 sec)、 2.查看临时表的数据存放位置 mysql> show variables like '%temp_data%'; +----------------------------+-----------------------+ | Variable_name | Value | +----------------------------+-----------------------+ | innodb_temp_data_file_path | ibtmp1:12M:autoextend | +----------------------------+-----------------------+ 1 row in set (0.00 sec) 3.查看临时表的定义的存放目录 mysql> show variables like '%tmp%'; +----------------------------------+----------+ | Variable_name | Value | +----------------------------------+----------+ | default_tmp_storage_engine | InnoDB | | innodb_tmpdir | | | internal_tmp_disk_storage_engine | InnoDB | | max_tmp_tables | 32 | | slave_load_tmpdir | /tmp | | tmp_table_size | 67108864 | | tmpdir | /tmp | +----------------------------------+----------+ 7 rows in set (0.00 sec) 1.2 临时表创建测试 mysql> select version(); +------------+ | version() | +------------+ | 5.7.22-log | +------------+ 1 row in set (0.00 sec) mysql> show create table temp_a\\G *************************** 1. row *************************** Table: temp_a Create Table: CREATE TEMPORARY TABLE `temp_a` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) mysql> insert into test_temp values(123); Query OK, 1 row affected (0.00 sec) mysql> select * from test_temp; +------+ | a | +------+ | 123 | +------+ 1 row in set (0.00 sec) 这个时候另外开一个session，是查看不到这个表的 mysql> show processlist; +-----+------+-----------+------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +-----+------+-----------+------+---------+------+----------+------------------+ | 155 | root | localhost | test | Sleep | 584 | | NULL | | 156 | root | localhost | test | Sleep | 22 | | NULL | | 157 | root | localhost | test | Query | 0 | starting | show processlist | +-----+------+-----------+------+---------+------+----------+------------------+ 3 rows in set (0.00 sec) mysql> select * from test_temp; ERROR 1146 (42S02): Table 'test.test_temp' doesn't exist 临时表的表定义存放位置 mysql> system ls -l /tmp -rw-r----- 1 mysql mysql 8554 Jul 11 14:44 #sql5eef_9c_1.frm drwx------ 3 root root 4096 Jun 13 11:42 systemd-private-9727ba712abb4e158d6af38d2f846420-ntpd.service-5jZaxg 临时表的数据存放位置 mysql> system ls -l /u01/mysql/mysql_data/ibtmp* -rw-r----- 1 mysql mysql 146800640 Jul 11 14:44 /u01/mysql/mysql_data/ibtmp1 1.3 临时表与普通表同名的问题 1.创建一张与test_temp同名的普通表 mysql> show create table test_temp; +-----------+---------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-----------+---------------------------------------------------------------------------------------------------------+ | test_temp | CREATE TEMPORARY TABLE `test_temp` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 | +-----------+---------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) mysql> create table test_temp (a int); Query OK, 0 rows affected (0.02 sec) 2.发现show create table的时候还是显示的临时表的定义 mysql> show create table test_temp; +-----------+---------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-----------+---------------------------------------------------------------------------------------------------------+ | test_temp | CREATE TEMPORARY TABLE `test_temp` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 | +-----------+---------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 3.插入一条记录，并查询，发现显示的是临时表的数据 mysql> insert into test_temp values(456); Query OK, 1 row affected (0.00 sec) mysql> select * from test_temp; +------+ | a | +------+ | 123 | | 456 | +------+ 2 rows in set (0.00 sec) 4.执行删除命令，发现第一次删除的是临时表，第二次才会删除普通表 //第一次删除test_temp表，留下的是普通表，删除的是临时表 mysql> drop table test_temp; Query OK, 0 rows affected (0.00 sec) mysql> show create table test_temp; +-----------+-----------------------------------------------------------------------------------------------+ | Table | Create Table | +-----------+-----------------------------------------------------------------------------------------------+ | test_temp | CREATE TABLE `test_temp` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 | +-----------+-----------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) //第二次删除test_temp表，删除的是普通表 mysql> drop table test_temp; Query OK, 0 rows affected (0.01 sec) mysql> show create table test_temp; ERROR 1146 (42S02): Table 'test.test_temp' doesn't exist mysql> 5.为了避免出现这些问题，建议用if not exists 语法来创建表 mysql> create temporary table if not exists test_temp (a int); Query OK, 0 rows affected (0.00 sec) mysql> show create table test_temp; +-----------+---------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-----------+---------------------------------------------------------------------------------------------------------+ | test_temp | CREATE TEMPORARY TABLE `test_temp` ( `a` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 | +-----------+---------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 2. 普通表的创建 2.1 基本语法 mysql> create table test_table(id int); Query OK, 0 rows affected (0.03 sec) mysql> show create table test_table\\G *************************** 1. row *************************** Table: test_table Create Table: CREATE TABLE `test_table` ( `id` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) 2.2 alter table语法 1.添加列 mysql> alter table test_table add column name varchar(10); Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> show create table test_table \\G *************************** 1. row *************************** Table: test_table Create Table: CREATE TABLE `test_table` ( `id` int(11) DEFAULT NULL, `name` varchar(10) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) 2.删除列 mysql> alter table test_table drop column name ; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> mysql> show create table test_table \\G *************************** 1. row *************************** Table: test_table Create Table: CREATE TABLE `test_table` ( `id` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) 注意： 当表记录很大的时候， alter table 会很耗时，影响性能 ONLINE DDL 5.6以后对在线DDL操作进行了优化，以提高性能。 三、外键 1. 外键示例 mysql> CREATE TABLE product ( -- 商品表 -> category INT NOT NULL, -- 商品种类 -> id INT NOT NULL, -- 商品id -> price DECIMAL, -> PRIMARY KEY(category, id) -- 主键是 (category, id) -> ) ENGINE=INNODB; Query OK, 0 rows affected (0.03 sec) mysql> CREATE TABLE customer ( -- 客户表 -> id INT NOT NULL, -- 客户id -> PRIMARY KEY (id) -- 主键是 id -> ) ENGINE=INNODB; Query OK, 0 rows affected (0.02 sec) mysql> CREATE TABLE product_order ( -- 订单表 -> no INT NOT NULL AUTO_INCREMENT, -- number，自增长 -> product_category INT NOT NULL, -- 商品种类 -> product_id INT NOT NULL, -- 商品id -> customer_id INT NOT NULL, -- 客户id -> PRIMARY KEY(no), -- 主键是 no -> INDEX (product_category, product_id), -- 对 (product_category, product_id) 做索引 -> INDEX (customer_id), -- 对 customer_id 做索引 -> FOREIGN KEY (product_category, product_id) -- 两个外键约束 -> REFERENCES product(category, id) -- 字段 product_category 引用自 product表的category -> -- 字段 product_id 引用自 product表的id -> ON UPDATE CASCADE ON DELETE RESTRICT, -- 级联跟新 和 严格模式删除 -> FOREIGN KEY (customer_id) -> REFERENCES customer(id) -> ) ENGINE=INNODB; Query OK, 0 rows affected (0.03 sec) 2. 外键的级联更新与删除示例 1.创建一张父表与子表，让子表的外键关联父表的主键id mysql> create table parent ( -> id int not null, -> primary key (id) -> ); Query OK, 0 rows affected (0.03 sec) mysql> mysql> create table child ( -> id int, -> parent_id INT, -> index par_ind (parent_id), -> foreign key (parent_id) -> references parent(id) -> on delete cascade on update cascade -- 比官网例子增加 update cascade -> ); Query OK, 0 rows affected (0.02 sec) 2.插入一条数据，id=1，parent_id=1，直接报错 ，因为此时parent表中没有任何记录 mysql> insert into child values(1,1); ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`test`.`child`, CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) 3.先在parent中插入记录，然后在child中插入记录，且parent_id是在parent中存在的，正常插入。 mysql> insert into parent values(1); Query OK, 1 row affected (0.01 sec) mysql> insert into child values(1,1); Query OK, 1 row affected (0.01 sec) 4.插入parent_id=2的记录，报错。因为此时parent_id=2的记录不存在 mysql> insert into child values(1,2); ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`test`.`child`, CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) mysql> select * from child; +------+-----------+ | id | parent_id | +------+-----------+ | 1 | 1 | +------+-----------+ 1 row in set (0.00 sec) mysql> select * from parent; +----+ | id | +----+ | 1 | //根据表结构的定义（Foreign_key），这个值就是 child表中的parent_id +----+ 1 row in set (0.00 sec) 5.更新parent表的id，可以看到child表的相关记录也被级联更新了 mysql> update parent set id=100 where id=1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from parent; +-----+ | id | +-----+ | 100 | +-----+ 1 row in set (0.00 sec) mysql> select * from child; +------+-----------+ | id | parent_id | +------+-----------+ | 1 | 100 | //自动变化，这是on update cascade的作用，联级更新，parent更新，child也跟着更新 +------+-----------+ 1 row in set (0.00 sec) 6.删除parent id=100这条记录，发现child的这条记录也想要的被删除了 mysql> delete from parent where id=100; Query OK, 1 row affected (0.01 sec) mysql> select * from parent; Empty set (0.00 sec) -- id=1，parent_id=100的记录跟着被删除了，这是on delete cascade的作用 mysql> select * from child; Empty set (0.00 sec) 7. 删除 之前的外键，新增加一个使用严格模式的外键 mysql> alter table child drop foreign key child_ibfk_1; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> alter table child add foreign key(parent_id) -> references parent(id) on update cascade on delete restrict; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> insert into parent values(50); Query OK, 1 row affected (0.01 sec) mysql> insert into child values(3,50); Query OK, 1 row affected (0.01 sec) 8.插入会和之前一样会提示错误 mysql> insert into child values(3,51); ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`test`.`child`, CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON UPDATE CASCADE) 9.删除parent表的记录报错了，因为这个时候child的外键使用的是严格模式，如果要删除parent这条记录，必须要先把child的相应记录删除了才行 mysql> delete from parent where id=50; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`test`.`child`, CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON UPDATE CASCADE) mysql> delete from child where parent_id=50; Query OK, 1 row affected (0.01 sec) mysql> delete from parent where id=50; Query OK, 1 row affected (0.00 sec) 3. 外键的选项及说明 ALTER TABLE tbl_name ADD [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name, ...) REFERENCES tbl_name (index_col_name,...) [ON DELETE reference_option] [ON UPDATE reference_option] 其中reference_option的选项有以下四种： CASCADE 在父表上update/delete记录时，同步update/delete掉子表的匹配记录 SET NULL 在父表上update/delete记录时，将子表上匹配记录的列设为null (要注意子表的外键列不能为not null) NO ACTION （updatedelete 后面说明都不写表示 no action == restrict） 如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作 RESTRICT 同no action, 都是立即检查外键约束 使用说明： CASCADE 删除：删除主表时自动删除从表。删除从表，主表不变 更新：更新主表时自动更新从表。更新从表，主表不变 SET NULL 删除：删除主表时自动更新从表值为NULL。删除从表，主表不变 更新：更新主表时自动更新从表值为NULL。更新从表，主表不变 RESTRICT、NO ACTION 删除：从表记录不存在时，主表才可以删除。删除从表，主表不变 更新：从表记录不存在时，主表才可以更新。更新从表，主表不变 注意： 外键约束，可以让数据进行一致性更新，但是会有一定的 性能损耗 ，线上业务使用不多。 通常上述级联更新和删除都是由应用层业务逻辑进行判断并实现。 trigger不会受外键cascade行为的影响,即不会触发trigger。 四、表碎片 1. 表碎片产生的现象及原因 现象： 有时候在表中删除了大量的无用数据，但是发现文件的大小没有发生变化，这是因为在删除数据后，遗留了大量的数据碎片所导致的。 原因： 在MySQL中delete删除数据的操作，并不会把数据文件真实删除，只是将数据文件的标识位删除，也没有整理数据文件，所以不会彻底的释放空间。当大量数据删除的时候，被删除数据的空间就会越来越大，当有新数据写入的时候会去占用这片空间，但又不是彻底占用。这就是所谓的碎片空间。这种存储空间在读取效率方面比正常占用的空间的效率要低很多！所以我们需要对这种表碎片进行整理。 2. 碎片计算方法及整理方法 mysql> show table status like 'employees'\\G *************************** 1. row *************************** Name: employees Engine: InnoDB Version: 10 Row_format: Dynamic Rows: 298124 Avg_row_length: 51 Data_length: 15245312 Max_data_length: 0 Index_length: 4726784 Data_free: 2097152 Auto_increment: NULL Create_time: 2018-07-11 16:29:36 Update_time: NULL Check_time: NULL Collation: utf8mb4_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) 2.1 计算方法： 碎片大小=数据总大小-实际表空间文件大小 数据总大小=Data_length + Index_length=15245312+4726784=19972096 实际表空间文件大小=RowsAvg_row_length=29812451=15204324 碎片大小=数据总大小 - 实际表空间文件大小 = (19972096 - 15204324)/1024/1024≈4.55M 2.2 整理方法： 1.alter table table_name engine=innodb; 2.备份数据表，删除删掉，再重新导入 3.使用percona公司提供的pt-online-schema-change工具 ./pt-online-schema-change --user=root --password=123456 --host=localhost --alter=\"engine=innodb\" d=employees , t=employees --excute 4.在MySQL5.7开始，直接支持online ddl 五、表的统计信息 1. 统计信息存放位置 统计信息的数据字典：information_schema.tables中 2. 如何查看统计信息 Show index from table 或查看 information_schema.statistics表 Show table status 或查看 information_schema.tables表 3. 收集统计信息 3.1 手动收集： Analyze table table_name； 适用于innodb和mysiam存储引擎。除非执行计划不准确，否则不要轻易执行该操作，如果是很大的表该操作会影响表的性能。 3.2 自动收集： 以下行为会自动触发统计信息的收集 第一次打开表的时候 表修改的行超过1/6或者20亿条时 当有新的记录插入时 执行show index from tablename或者执行show table、查询information_schema.tables\\statistics 时 3.3 开启参数innodb_stats_on_metadata触发收集 当开启参数innodb_stats_on_metadata后访问以下表也会触发统计信息的收集 在访问以下表时，innodb表的统计信息可自动收集 information_schema.TABLES information_schema.STATISTICS information_schema.PARTITIONS information_schema.KEY_COLUMN_USAGE information_schema.TABLE_CONSTRAINTS information_schema.REFERENTIAL_CONSTRAINTS information_schema.table_constraints 4. 相关参数说明： mysql> show variables like '%innodb_stats%'; +--------------------------------------+-------------+ | Variable_name | Value | +--------------------------------------+-------------+ | innodb_stats_auto_recalc | ON | | innodb_stats_include_delete_marked | OFF | | innodb_stats_method | nulls_equal | | innodb_stats_on_metadata | OFF | | innodb_stats_persistent | ON | | innodb_stats_persistent_sample_pages | 20 | | innodb_stats_sample_pages | 8 | | innodb_stats_transient_sample_pages | 8 | +--------------------------------------+-------------+ 8 rows in set (0.00 sec) Innodb_stats_sample_pages：每次收集统计信息时采样的页数，默认为20。 innodb_stats_persistent：默认on，将analyze table产生的统计信息保存于磁盘，直至下次analyze table为止，这样避免了统计信息动态更新，保证了执行计划的稳定，对于大表也节省了收集统计信息的所需资源。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:35:02 "},"10.sqlselect.html":{"url":"10.sqlselect.html","title":"10.SQL之select","keywords":"","body":" SELECT语法树： limit 和 order by where 示例 JOIN SQL89的语法 SQL92语法 OUTER JOIN LEFT JOIN RIGHT JOIN 连接的总结 条件位置的区别 范例： GROUP BY 子查询 子查询的使用 子查询的分类 子查询的优化 包含null 值的 in 和 not in in 可以改为 exists ; not in 不一定可以改成 not exists 显示行号 终于到SQL语句了！ SELECT语法树： SELECT -- -------------------------不推荐使用-------------------------- [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [MAX_STATEMENT_TIME = N] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] -- ------------------------------------------------------------- select_expr [, select_expr ...] [FROM table_references [PARTITION partition_list] [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [PROCEDURE procedure_name(argument_list)] [INTO OUTFILE 'file_name' [CHARACTER SET charset_name] export_options | INTO DUMPFILE 'file_name' | INTO var_name [, var_name]] [FOR UPDATE | LOCK IN SHARE MODE]] limit 和 order by 从employees中 随机 取出一条数据，结果是不确定的 mysql> use employees; Database changed mysql> select * from employees limit 1; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | +--------+------------+------------+-----------+--------+------------+ 1 row in set (0.00 sec) 使用order by col_name asc进行升序排序 mysql> select * from employees order by emp_no asc limit 1; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | +--------+------------+------------+-----------+--------+------------+ 1 row in set (0.00 sec) 默认就是升序的 mysql> select * from employees order by emp_no limit 1; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | +--------+------------+------------+-----------+--------+------------+ 1 row in set (0.00 sec) desc表示降序 通过order by排序后 limit 1 才是确定的 在这里，emp_no 是主键，order by 主键 不会创建临时表的，主键(索引)本身有序 mysql> select * from employees order by emp_no desc limit 1; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 499999 | 1958-05-01 | Sachin | Tsukuda | M | 1997-11-30 | +--------+------------+------------+-----------+--------+------------+ 1 row in set (0.00 sec) mysql> show create table employees\\G *************************** 1. row *************************** Table: employees Create Table: CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` enum('M','F') NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`), //注意：emp_no 是主键，order by 主键 不会创建临时表的，主键(索引)本身有序 KEY `idx_emp_2` (`hire_date`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) limit的语法 limit start, offset --从第5条开始取，取5条出来 mysql> select * from employees order by emp_no asc limit 5,5; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10006 | 1953-04-20 | Anneke | Preusig | F | 1989-06-02 | | 10007 | 1957-05-23 | Tzvetan | Zielinski | F | 1989-02-10 | | 10008 | 1958-02-19 | Saniya | Kalloufi | M | 1994-09-15 | | 10009 | 1952-04-19 | Sumant | Peac | F | 1985-02-18 | | 10010 | 1963-06-01 | Duangkaew | Piveteau | F | 1989-08-24 | +--------+------------+------------+-----------+--------+------------+ 5 rows in set (0.00 sec) 以上这个语法有一种分页的效果，但是会随着start的增加，性能会下降，因为会扫描表(从 1 到 start) 相对比较推荐的方法 mysql> select * from employees where emp_no > 20000 order by emp_no limit 5; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 20001 | 1962-05-16 | Atreye | Eppinger | M | 1990-04-18 | | 20002 | 1955-12-25 | Jaber | Brender | M | 1988-01-26 | | 20003 | 1953-04-11 | Munehiko | Coors | F | 1991-02-07 | | 20004 | 1952-03-07 | Radoslaw | Pfau | M | 1995-11-24 | | 20005 | 1956-02-20 | Licheng | Przulj | M | 1992-07-17 | +--------+------------+------------+-----------+--------+------------+ 5 rows in set (0.05 sec) where WHERE 是将查询出来的结果，通过 WHERE 后面的条件(condition)，对结果进行过滤 示例 不加order by的limit是不确定的SQL mysql> select * from employees limit 4; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | | 10002 | 1964-06-02 | Bezalel | Simmel | F | 1985-11-21 | | 10003 | 1959-12-03 | Parto | Bamford | M | 1986-08-28 | | 10004 | 1954-05-01 | Chirstian | Koblick | M | 1986-12-01 | +--------+------------+------------+-----------+--------+------------+ 4 rows in set (0.00 sec) 对emp_no进行过滤 mysql> select * from employees where emp_no > 30000 limit 4; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 30001 | 1953-03-27 | Izaskun | Morton | M | 1988-05-21 | | 30002 | 1960-08-23 | Branimir | Snedden | M | 1998-09-24 | | 30003 | 1952-11-25 | Takahito | Vilarrasa | M | 1990-08-22 | | 30004 | 1957-11-26 | Lucian | Penttonen | F | 1992-10-08 | +--------+------------+------------+-----------+--------+------------+ 4 rows in set (0.00 sec) mysql> select * from employees where emp_no > 40000 order by emp_no limit 4; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 40001 | 1956-03-28 | Akemi | Maliniak | F | 1987-08-06 | | 40002 | 1960-03-15 | Nakhoon | Badr | M | 1990-02-13 | | 40003 | 1960-01-26 | Jacopo | Marshall | F | 1991-09-30 | | 40004 | 1955-09-09 | Anneke | Stiles | F | 1986-03-05 | +--------+------------+------------+-----------+--------+------------+ 4 rows in set (0.01 sec) 可以用 and 进行 逻辑与 mysql> select * from employees -> where emp_no > 40000 -> and hire_date > '1991-01-01' -> order by emp_no limit 4; +--------+------------+------------+------------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+------------+--------+------------+ | 40003 | 1960-01-26 | Jacopo | Marshall | F | 1991-09-30 | | 40005 | 1961-02-27 | Zsolt | Fairtlough | F | 1991-07-08 | | 40012 | 1955-02-07 | Chinhyun | Ozeri | F | 1995-08-12 | | 40015 | 1964-10-08 | Ioana | Lemarechal | M | 1997-08-07 | +--------+------------+------------+------------+--------+------------+ 4 rows in set (0.00 sec) 使用()明确条件的逻辑规则,可以使用 or 做 逻辑或 mysql> select * from employees -> where (emp_no > 40000 and birth_date > '1961-01-01') -- 使用()明确条件的逻辑规则 -> or (emp_no > 40000 and hire_date > '1991-01-01') -- 可以使用 or 做 逻辑或 -> order by emp_no limit 5; +--------+------------+------------+------------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+------------+--------+------------+ | 40003 | 1960-01-26 | Jacopo | Marshall | F | 1991-09-30 | | 40005 | 1961-02-27 | Zsolt | Fairtlough | F | 1991-07-08 | | 40006 | 1962-11-07 | Basim | Panienski | F | 1986-12-27 | | 40012 | 1955-02-07 | Chinhyun | Ozeri | F | 1995-08-12 | | 40015 | 1964-10-08 | Ioana | Lemarechal | M | 1997-08-07 | +--------+------------+------------+------------+--------+------------+ 5 rows in set (0.00 sec) JOIN 相关的employees库的ER图 SQL89的语法 关联employees表和titles表，要求 employees的emp_no 等于 titles的emp_no mysql> select * from employees,titles where employees.emp_no = titles.emp_no limit 5; +--------+------------+------------+-----------+--------+------------+--------+-----------------+------------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | emp_no | title | from_date | to_date | +--------+------------+------------+-----------+--------+------------+--------+-----------------+------------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | 10001 | Senior Engineer | 1986-06-26 | 9999-01-01 | | 10002 | 1964-06-02 | Bezalel | Simmel | F | 1985-11-21 | 10002 | Staff | 1996-08-03 | 9999-01-01 | | 10003 | 1959-12-03 | Parto | Bamford | M | 1986-08-28 | 10003 | Senior Engineer | 1995-12-03 | 9999-01-01 | | 10004 | 1954-05-01 | Chirstian | Koblick | M | 1986-12-01 | 10004 | Engineer | 1986-12-01 | 1995-12-01 | | 10004 | 1954-05-01 | Chirstian | Koblick | M | 1986-12-01 | 10004 | Senior Engineer | 1995-12-01 | 9999-01-01 | +--------+------------+------------+-----------+--------+------------+--------+-----------------+------------+------------+ 5 rows in set (0.04 sec) 在上面的基础上只显示emp_no，名字，性别和职位名称 mysql> select emp_no, concat(last_name,' ', first_name), gender, title -> from employees,titles -> where employees.emp_no = titles.emp_no limit 5; ERROR 1052 (23000): Column 'emp_no' in field list is ambiguous 发现上面报错了，原因是因为emp_no在两个表中都有，在select后面需要指定取的是哪个表的emp_no mysql> select employees.emp_no, concat(last_name,' ', first_name), gender, title -> from employees,titles -> where employees.emp_no = titles.emp_no limit 5; +--------+-----------------------------------+--------+-----------------+ | emp_no | concat(last_name,' ', first_name) | gender | title | +--------+-----------------------------------+--------+-----------------+ | 10001 | Facello Georgi | M | Senior Engineer | | 10002 | Simmel Bezalel | F | Staff | | 10003 | Bamford Parto | M | Senior Engineer | | 10004 | Koblick Chirstian | M | Engineer | | 10004 | Koblick Chirstian | M | Senior Engineer | +--------+-----------------------------------+--------+-----------------+ 5 rows in set (0.00 sec) 别名的使用，可以对列，对表取别名 对列使用别名 mysql> select employees.emp_no, -> concat(last_name,' ', first_name) as emp_name, gender, title -- 对名字的列取一个别名叫emp_name -> from employees,titles -> where employees.emp_no = titles.emp_no limit 5; +--------+-------------------+--------+-----------------+ | emp_no | emp_name | gender | title | +--------+-------------------+--------+-----------------+ | 10001 | Facello Georgi | M | Senior Engineer | | 10002 | Simmel Bezalel | F | Staff | | 10003 | Bamford Parto | M | Senior Engineer | | 10004 | Koblick Chirstian | M | Engineer | | 10004 | Koblick Chirstian | M | Senior Engineer | +--------+-------------------+--------+-----------------+ 5 rows in set (0.00 sec) 对表名使用别名。 在后面的where条件中，可以直接使用别名 mysql> select e.emp_no, -- 使用表的别名 -> concat(last_name,' ', first_name) as emp_name, gender, title -> from employees as e,titles as t -- 对表做别名 -> where e.emp_no = t.emp_no limit 5; -- 使用报表的别名 +--------+-------------------+--------+-----------------+ | emp_no | emp_name | gender | title | +--------+-------------------+--------+-----------------+ | 10001 | Facello Georgi | M | Senior Engineer | | 10002 | Simmel Bezalel | F | Staff | | 10003 | Bamford Parto | M | Senior Engineer | | 10004 | Koblick Chirstian | M | Engineer | | 10004 | Koblick Chirstian | M | Senior Engineer | +--------+-------------------+--------+-----------------+ 5 rows in set (0.00 sec) SQL92语法 inner join ... on ...语法 mysql> select e.emp_no, -> concat(last_name,' ', first_name) as emp_name, gender, title -> from employees as e inner join titles as t -- inner join 可以省略inner关键字 -> on e.emp_no = t.emp_no limit 5; -- 配合join使用on +--------+-------------------+--------+-----------------+ | emp_no | emp_name | gender | title | +--------+-------------------+--------+-----------------+ | 10001 | Facello Georgi | M | Senior Engineer | | 10002 | Simmel Bezalel | F | Staff | | 10003 | Bamford Parto | M | Senior Engineer | | 10004 | Koblick Chirstian | M | Engineer | | 10004 | Koblick Chirstian | M | Senior Engineer | +--------+-------------------+--------+-----------------+ 5 rows in set (0.00 sec) SQL89 和 SQL02 两者效率其实是一样的，只是写法不一样，可以看执行计划即可得到这个结论 mysql> explain -> select e.emp_no, -- 使用表的别名 -> concat(last_name,' ', first_name) as emp_name, gender, title -> from employees as e,titles as t -- 对表做别名 -> where e.emp_no = t.emp_no limit 5; -- 使用报表的别名 +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ | 1 | SIMPLE | e | NULL | ALL | PRIMARY | NULL | NULL | NULL | 298124 | 100.00 | NULL | | 1 | SIMPLE | t | NULL | ref | PRIMARY | PRIMARY | 4 | employees.e.emp_no | 1 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec) mysql> explain -> select e.emp_no, -> concat(last_name,' ', first_name) as emp_name, gender, title -> from employees as e inner join titles as t -- inner join 可以省略inner关键字 -> on e.emp_no = t.emp_no limit 5; -- 配合join使用on +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ | 1 | SIMPLE | e | NULL | ALL | PRIMARY | NULL | NULL | NULL | 298124 | 100.00 | NULL | | 1 | SIMPLE | t | NULL | ref | PRIMARY | PRIMARY | 4 | employees.e.emp_no | 1 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+---------+---------+--------------------+--------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec) 通过上面的对比，可以看到两者的执行计划是完全一致的。 OUTER JOIN 环境准备 mysql> create table test_join_1(a int); Query OK, 0 rows affected (0.03 sec) mysql> create table test_join_2(b int); Query OK, 0 rows affected (0.03 sec) mysql> insert into test_join_2 values (1); Query OK, 1 row affected (0.01 sec) mysql> insert into test_join_1 values (1); Query OK, 1 row affected (0.00 sec) mysql> insert into test_join_1 values (2); Query OK, 1 row affected (0.00 sec) mysql> select * from test_join_1; +------+ | a | +------+ | 1 | | 2 | +------+ 2 rows in set (0.00 sec) mysql> select * from test_join_2; +------+ | b | +------+ | 1 | +------+ 1 row in set (0.00 sec) LEFT JOIN left join ： 左表 left join 右表 on 条件； 左表全部显示，右表是匹配表， 如果右表的某条记录满足 [on 条件]匹配，则该记录显示 如果右表的某条记录 不 满足 匹配，则该记录显示NULL mysql> select * from -> test_join_1 as t1 -> left join -- 使用left join -> test_join_2 as t2 -> on t1.a = t2.b; +------+------+ | a | b | +------+------+ | 1 | 1 | | 2 | NULL | +------+------+ 2 rows in set (0.00 sec) RIGHT JOIN right join ： 左表 right join 右表 on 条件 右表全部显示，左边是匹配表 同样和left join一样，满足则显示，不满足且右表中有值，则填充NULL 1.t2 中再增加一条记录 mysql> insert into test_join_2 values (3); Query OK, 1 row affected (0.01 sec) 2.右表存在，左表没有，用NULL填充 mysql> select * from -> test_join_1 as t1 -> right join -> test_join_2 as t2 -> on t1.a = t2.b; +------+------+ | a | b | +------+------+ | 1 | 1 | | NULL | 3 | +------+------+ 2 rows in set (0.00 sec) 查找在t1表，而不在t2表的数据 mysql> select * from -> test_join_1 as t1 -> left join -> test_join_2 as t2 -> on t1.a = t2.b where t2.b is null; +------+------+ | a | b | +------+------+ | 2 | NULL | +------+------+ 1 row in set (0.00 sec) 连接的总结 left join ： left outer join , outer关键字可以省略 right join： right outer join , outer 关键字可以省略 join无论inner还是outer，列名不需要一样，甚至列的类型也可以不一样，会进行转换。 一般情况下，表设计合理，需要关联的字段类型应该是一样的 条件位置的区别 在 inner join中，过滤条件放在where或者on中都是可以的 在 outer join中 条件放在where和on中是不一样的 ON 参与 OUTER JOIN 的结果的生成，而 WHERE 只是对结果的一个过滤 mysql> select * from -> test_join_1 as t1 -> left join -> test_join_2 as t2 -> on t1.a = t2.b -> where t2.b is null; +------+------+ | a | b | +------+------+ | 2 | NULL | +------+------+ 1 row in set (0.00 sec) mysql> select * from -> test_join_1 as t1 -> left join -> test_join_2 as t2 -> on t1.a = t2.b -> and t2.b is null; +------+------+ | a | b | +------+------+ | 1 | NULL | | 2 | NULL | +------+------+ 2 rows in set (0.00 sec) 范例： 查找哪些员工不是经理 mysql> select e.emp_no, -> concat(last_name,' ', first_name) as emp_name, gender, d.dept_no -> from employees as e left join dept_manager as d -> on e.emp_no = d.emp_no -> where d.emp_no is null limit 5; +--------+-------------------+--------+---------+ | emp_no | emp_name | gender | dept_no | +--------+-------------------+--------+---------+ | 10001 | Facello Georgi | M | NULL | | 10002 | Simmel Bezalel | F | NULL | | 10003 | Bamford Parto | M | NULL | | 10004 | Koblick Chirstian | M | NULL | | 10005 | Maliniak Kyoichi | M | NULL | +--------+-------------------+--------+---------+ 5 rows in set (0.02 sec) GROUP BY GROUP BY 子句中列出的每一列都必须是检索列或有效的表达式（但不能是聚集函数）。 如果在SELECT中使用表达式，则必须在 GROUP BY 子句中指定相同的表达式，而不能使用别名。 除聚集计算语句外， SELECT语句中的每一列都必须在GROUP BY子句中给出 。 找出同一个部门的员工数量 mysql> select dept_no, count(dept_no) -- count是得到数量，这里就是分组函数 -> from dept_emp -> group by dept_no; -- 通过 dept_no 分组 +---------+----------------+ | dept_no | count(dept_no) | +---------+----------------+ | d001 | 20211 | | d002 | 17346 | | d003 | 17786 | | d004 | 73485 | | d005 | 85707 | | d006 | 20117 | | d007 | 52245 | | d008 | 21126 | | d009 | 23580 | +---------+----------------+ 9 rows in set (0.68 sec) 选出部门人数 > 50000 对分组的聚合函数做过滤，使用having，用where报语法错误 mysql> select dept_no, count(dept_no) -> from dept_emp -> group by dept_no -> having count(dept_no) > 50000; +---------+----------------+ | dept_no | count(dept_no) | +---------+----------------+ | d004 | 73485 | | d005 | 85707 | | d007 | 52245 | +---------+----------------+ 3 rows in set (0.10 sec) 子查询 子查询就是指在一个select语句中嵌套另一个select语句。同时，子查询必须包含括号。 在MySQL5.6.x版本之前，MySQL的子查询性能较差，但是从5.6开始，性能上有了较大的提升 select a from t1 where a > any(select a from t2); select a from t1是外部查询(out query) (select a from t2)是子查询 一般说来，子查询嵌套于外部查询中，可以将两个或两个以上的子查询进行嵌 子查询的使用 any/some（任何满足一个就返回记录） 如果外部查询的列的结果和子查询的列的结果比较得到为True的话，则返回比较值为True的（外查询）的记录 环境准备 mysql> create table t1 (a int); Query OK, 0 rows affected (0.02 sec) mysql> create table t2 (a int); Query OK, 0 rows affected (0.03 sec) mysql> insert into t1 values(10),(4); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> insert into t2 values(12),(13),(5); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select a from t1; +------+ | a | +------+ | 10 | | 4 | +------+ 2 rows in set (0.00 sec) mysql> select a from t2; +------+ | a | +------+ | 12 | | 13 | | 5 | +------+ 3 rows in set (0.00 sec) any/some示例 mysql> select a from t1 -> where a > any -> (select a from t2); +------+ | a | +------+ | 10 | +------+ 1 row in set (0.00 sec) t1中a列的值，只要大于(12,13,5)中任意一值，即t1.a > t2.a为True，则返回对应的t1.a。 对于t1.a来说，10满足大于5；4不满足任何>条件，所以最终返回的结果集为10。 这个查询可以解释为，t1表内a列的值 大于 t2表中a列的任意(any)一个值（t1.a > any(t2.a) == true）,则返回t1.a的记录。 ANY关键词必须与一个比较操作符一起使用：=,>,=,(这个是!=的意思) 子查询中SOME和ANY是同一个意思 IN n是ANY的一种特殊情况：\"in\" 等同于 \"=any\" 1.向t1中插入一个t2中存在的值 5 mysql> insert into t1 values(5); Query OK, 1 row affected (0.01 sec) mysql> select * from t1; +------+ | a | +------+ | 10 | | 4 | | 5 | +------+ 3 rows in set (0.00 sec) mysql> select * from t2; +------+ | a | +------+ | 12 | | 13 | | 5 | +------+ 3 rows in set (0.01 sec) 2. t1.a==t2.a 的只有5 mysql> select a from t1 where a = any(select a from t2); +------+ | a | +------+ | 5 | +------+ 1 row in set (0.00 sec) 3. in的结果等同于 =any 的结果 mysql> select a from t1 where a in (select a from t2); +------+ | a | +------+ | 5 | +------+ 1 row in set (0.00 sec) ALL (全部满足才会返回记录) 如果外部查询的列的结果和子查询的列的所有结果比较得到为True的话，则返回比较值为True的（外查询）的记录 mysql> truncate t1; Query OK, 0 rows affected (0.04 sec) mysql> truncate t2; Query OK, 0 rows affected (0.01 sec) mysql> insert into t1 values(10),(4); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> insert into t1 values(10),(4);^C mysql> insert into t2 value(5),(4),(3); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 // (10 > 5, 4, 3 为 True) 而 (4 >5, 4, 3 为 False) mysql> select a from t1 where a > all(select a from t2); +------+ | a | +------+ | 10 | +------+ 1 row in set (0.00 sec) ALL关键词必须与一个比较操作符一起使用 NOT IN 等同于<>ALL 子查询的分类 独立子查询 不依赖外部查询而运行的子查询 mysql> select a from t1 where a in (1,2,3,4,5); +------+ | a | +------+ | 4 | +------+ 1 row in set (0.00 sec) 相关子查询 引用了外部查询列的子查 mysql> select a from t1 where a in (select * from t2 where t1.a = t2.a); +------+ | a | +------+ | 4 | +------+ 1 row in set (0.00 sec) 子查询的优化 在5.6之前，优化器会把子查询重写为exists的形式 1.这个是一条独立的子查询，时间复杂度 O(M+N) mysql> select a from t1 where a in (select a from t2); +------+ | a | +------+ | 4 | +------+ 1 row in set (0.00 sec) 2.经过优化器重写后 这是相关子查询，复杂度O(M*N + M) mysql> select a from t1 where exists (select 1 from t2 where t1.a = t2.a); +------+ | a | +------+ | 4 | +------+ 1 row in set (0.00 sec) 3.部分的子查询需要重写成join的形式 mysql> select t1.a from t1 join t2 on t1.a = t2.a; +------+ | a | +------+ | 4 | +------+ 1 row in set (0.00 sec) 在5.6之后，优化器不会将子查询重写成exists的形式，而是自动优化，性能有了大幅提 可以通过查看执行计划来查看子查询优化的结果。(explain extended) 包含null 值的 in 和 not in MySQL 数据库的比较操作，除了返回1(True),0(False)之外，还会返回NULL NULL和NULL的比较，返回的还是NULL mysql> select null in ('a', 'b', null); +--------------------------+ | null in ('a', 'b', null) | +--------------------------+ | NULL | +--------------------------+ 1 row in set (0.00 sec) null不在('a', 'b', null)中，返回的还是null，因为有null和null的比较 mysql> select null not in ('a', 'b', null); +------------------------------+ | null not in ('a', 'b', null) | +------------------------------+ | NULL | +------------------------------+ 1 row in set (0.00 sec) a 不在 ('a', 'b', null)中，返回0,即False mysql> select 'a' not in ('a', 'b', null); +-----------------------------+ | 'a' not in ('a', 'b', null) | +-----------------------------+ | 0 | +-----------------------------+ 1 row in set (0.00 sec) 'c'不在('a', 'b')中，返回1，即为True mysql> select 'c' not in ('a', 'b'); +-----------------------+ | 'c' not in ('a', 'b') | +-----------------------+ | 1 | +-----------------------+ 1 row in set (0.00 sec) 理论上应该是返回1，即True的。但是包含了null值。则返回null mysql> select 'c' not in ('a', 'b', null); +-----------------------------+ | 'c' not in ('a', 'b', null) | +-----------------------------+ | NULL | +-----------------------------+ 1 row in set (0.00 sec) 对于包含了NULL值的两种操作: IN操作，返回True或者NULL NOT IN操作，返回NOT True(False)或者NOT NULL(NULL) 和 null比较，使用is和is not， 而不是 = 和 <> mysql> select null = null; +-------------+ | null = null | +-------------+ | NULL | +-------------+ 1 row in set (0.00 sec) mysql> select null <> null; +--------------+ | null <> null | +--------------+ | NULL | +--------------+ 1 row in set (0.00 sec) mysql> select null is null; +--------------+ | null is null | +--------------+ | 1 | +--------------+ 1 row in set (0.00 sec) mysql> select null is not null; +------------------+ | null is not null | +------------------+ | 0 | +------------------+ 1 row in set (0.00 sec) in 可以改为 exists ; not in 不一定可以改成 not exists 当结果集合中没有NULL值时，下面两条SQL语句查询的结果是一致的 select customerid, companyname from customers as A where country = 'Spain' and not exists ( select * from orders as B where A.customerid = B.customerid ); select customerid, companyname from customers as A where country = 'Spain' and customerid not in (select customerid from orders); 插入一个NULL值 insert into orders(orderid) values (null); SQL语句1 : 返回和之前一致 SQL语句2 : 返回为空表，因为子查询返回的结果集中存在NULL值。not in null 永远返回False或者NULL 此时 where (country = 'Spain' and (False or NULL)) 为 False OR NULL，条件永远不匹配 SQL语句2 应该改写为以下，两者才一致： select customerid, companyname from customers as A where country = 'Spain' and customerid not in (select customerid from orders where customerid is not null); -- 增加这个过滤条件，使用is not，而不是<> EXISTS不管返回值是什么，而是看是否有行返回，所以EXISTS中子查询都是select *、select 1等，因为只关心返回是否有行（结果集） 显示行号 mysql> set @rn:=0; --可以设置也可以不设置 Query OK, 0 rows affected (0.00 sec) mysql> select @rn:=@rn+1 as rownumber, emp_no, gender from employees limit 10; +-----------+--------+--------+ | rownumber | emp_no | gender | +-----------+--------+--------+ | 1 | 10001 | M | | 2 | 10002 | F | | 3 | 10003 | M | | 4 | 10004 | M | | 5 | 10005 | M | | 6 | 10006 | F | | 7 | 10007 | F | | 8 | 10008 | M | | 9 | 10009 | F | | 10 | 10010 | F | +-----------+--------+--------+ 10 rows in set (0.00 sec) mysql> select @rn:=@rn+1 as rownumber, emp_no, gender from employees limit 10; +-----------+--------+--------+ | rownumber | emp_no | gender | +-----------+--------+--------+ | 11 | 10001 | M | | 12 | 10002 | F | | 13 | 10003 | M | | 14 | 10004 | M | | 15 | 10005 | M | | 16 | 10006 | F | | 17 | 10007 | F | | 18 | 10008 | M | | 19 | 10009 | F | | 20 | 10010 | F | +-----------+--------+--------+ 10 rows in set (0.00 sec) 推荐下面这种 原理是：把 employees 和 (select @rn1:=0)做了笛卡尔积，然后使用@rn1:=@rn + 1，根据每行进行累加 mysql> select @rn1:=@rn1+1 as rownumber, emp_no, gender from employees, (select @rn1:=0) as a limit 10; +-----------+--------+--------+ | rownumber | emp_no | gender | +-----------+--------+--------+ | 1 | 10001 | M | | 2 | 10002 | F | | 3 | 10003 | M | | 4 | 10004 | M | | 5 | 10005 | M | | 6 | 10006 | F | | 7 | 10007 | F | | 8 | 10008 | M | | 9 | 10009 | F | | 10 | 10010 | F | +-----------+--------+--------+ 10 rows in set (0.00 sec) mysql> select @rn1:=@rn1+1 as rownumber, emp_no, gender from employees, (select @rn1:=0) as a limit 10; +-----------+--------+--------+ | rownumber | emp_no | gender | +-----------+--------+--------+ | 1 | 10001 | M | | 2 | 10002 | F | | 3 | 10003 | M | | 4 | 10004 | M | | 5 | 10005 | M | | 6 | 10006 | F | | 7 | 10007 | F | | 8 | 10008 | M | | 9 | 10009 | F | | 10 | 10010 | F | +-----------+--------+--------+ 10 rows in set (0.00 sec) mysql> select @rn1:=@rn1+1 as rownumber, emp_no, gender from employees, (select @rn1:=0) as a limit 10; +-----------+--------+--------+ | rownumber | emp_no | gender | +-----------+--------+--------+ | 1 | 10001 | M | | 2 | 10002 | F | | 3 | 10003 | M | | 4 | 10004 | M | | 5 | 10005 | M | | 6 | 10006 | F | | 7 | 10007 | F | | 8 | 10008 | M | | 9 | 10009 | F | | 10 | 10010 | F | +-----------+--------+--------+ 10 rows in set (0.00 sec) mysql> select @rn1:=0; +---------+ | @rn1:=0 | +---------+ | 0 | +---------+ 1 row in set (0.00 sec) 使用子查询实现（但是该子查询的效率较低。不推荐使用。）： SELECT (SELECT COUNT(1) FROM employees b WHERE b.emp_no 思路： 假设当前在第N行记录，通过主键emp_no遍历有多少行的记录 小于等于 当前行,即为当前行的行数 但是该子查询的效率较低。不推荐使用。 推荐上面的第二种 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 08:43:05 "},"11.sqldml.html":{"url":"11.sqldml.html","title":"11.SQL之增删改","keywords":"","body":" 一、INSERT 二、DELETE 三、UPDATE 1.单表更新 2.级联更新 四、REPLACE 一、INSERT mysql> truncate table t1; Query OK, 0 rows affected (0.02 sec) mysql> insert into t1 values(1); Query OK, 1 row affected (0.00 sec) mysql> insert into t1 values(2),(3),(-1); //插入多个值，MySQL独有 Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> insert into t1 select 8; Query OK, 1 row affected (0.01 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql> create table t3 (a int, b int); Query OK, 0 rows affected (0.02 sec) mysql> insert into t3 select 8; //没有指定列，报错 ERROR 1136 (21S01): Column count doesn't match value count at row 1 mysql> insert into t3(a) select 8; //指定列，正常插入 Query OK, 1 row affected (0.01 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql> select * from t3; +------+------+ | a | b | +------+------+ | 8 | NULL | +------+------+ 1 row in set (0.00 sec) mysql> insert into t3 select 8, 9; //不指定列，但是插入值匹配列的个数和类型 Query OK, 1 row affected (0.01 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql> select * from t3; +------+------+ | a | b | +------+------+ | 8 | NULL | | 8 | 9 | +------+------+ 2 rows in set (0.00 sec) mysql> insert into t3(b) select a from t2; //从t2表中查询数据并插入到t3(a)中，注意指定列 Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from t3; +------+------+ | a | b | +------+------+ | 8 | NULL | | 8 | 9 | | NULL | 5 | | NULL | 4 | | NULL | 3 | +------+------+ 5 rows in set (0.00 sec) 二、DELETE 没啥好说的。。 三、UPDATE 1.单表更新 mysql> truncate table t3; Query OK, 0 rows affected (0.01 sec) mysql> insert into t3 select 1,2; Query OK, 1 row affected (0.01 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql> select * from t3; +------+------+ | a | b | +------+------+ | 1 | 2 | +------+------+ 1 row in set (0.00 sec) mysql> update t3 set a=10 where a=1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from t3; +------+------+ | a | b | +------+------+ | 10 | 2 | +------+------+ 1 row in set (0.00 sec) 2.级联更新 mysql> select * from t1; +------+ | a | +------+ | 1 | | 2 | | 3 | | -1 | | 8 | +------+ 5 rows in set (0.00 sec) mysql> select * from t2; +------+ | a | +------+ | 5 | | 4 | | 3 | +------+ 3 rows in set (0.00 sec) mysql> select * from t1 join t2 on t1.a = t2.a ; +------+------+ | a | a | +------+------+ | 3 | 3 | +------+------+ 1 row in set (0.00 sec) 级联更新 先得到t1.a=t2.a的结果集，然后将结果集中的t1.a设置为100 mysql> update t1 join t2 on t1.a = t2.a set t1.a=100; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from t1; +------+ | a | +------+ | 1 | | 2 | | 100 | //该行被update为100 | -1 | | 8 | +------+ 5 rows in set (0.00 sec) 四、REPLACE replace的原理是：先delete，在insert mysql> create table t4(a int primary key auto_increment, b int); Query OK, 0 rows affected (0.03 sec) mysql> insert into t4 values(NULL, 10); Query OK, 1 row affected (0.01 sec) mysql> insert into t4 values(NULL, 11); Query OK, 1 row affected (0.01 sec) mysql> insert into t4 values(NULL, 12); Query OK, 1 row affected (0.00 sec) mysql> select * from t4; +---+------+ | a | b | +---+------+ | 1 | 10 | | 2 | 11 | | 3 | 12 | +---+------+ 3 rows in set (0.00 sec) //报错，说存在重复的主键记录 \"1\" mysql> insert into t4 values(1, 100); ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY' //使用replace成功！替换该主键对应的值，两行记录受到影响 mysql> replace into t4 values(1, 100); Query OK, 2 rows affected (0.01 sec) mysql> select * from t4; +---+------+ | a | b | +---+------+ | 1 | 100 | //replace的原理是：先delete，在insert | 2 | 11 | | 3 | 12 | +---+------+ 3 rows in set (0.00 sec) //没有替换对象时，类似插入效果 mysql> replace into t4 values(5, 50); Query OK, 1 row affected (0.00 sec) mysql> select * from t4; +---+------+ | a | b | +---+------+ | 1 | 100 | | 2 | 11 | | 3 | 12 | | 5 | 50 | +---+------+ 4 rows in set (0.00 sec) 测试示例2 mysql> create table t6 (a int primary key, -> b int auto_increment, // b是auto_increment的int型数据 -> c int, key(b)); Query OK, 0 rows affected (0.03 sec) mysql> insert into t6 values(10, NULL, 100),(20,NULL,200); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> SELECT * FROM t6; +----+---+------+ | a | b | c | +----+---+------+ | 10 | 1 | 100 | | 20 | 2 | 200 | +----+---+------+ 2 rows in set (0.00 sec) //替换后b从1变成了3，说明是先删除，再插入 mysql> replace into t6 values(10,NULL,150); Query OK, 2 rows affected (0.01 sec) mysql> SELECT * FROM t6; +----+---+------+ | a | b | c | +----+---+------+ | 10 | 3 | 150 | | 20 | 2 | 200 | +----+---+------+ 2 rows in set (0.00 sec) Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:56 "},"12.sqlextra.html":{"url":"12.sqlextra.html","title":"12.SQL其他补充","keywords":"","body":" 一、case when 二、视图 1.视图的作用 2.示例 3.视图的算法 三、UNION 与 UNION ALL 一、case when case when [condition_1] then [do_something_1] when [condition_2] then [do_something_2] end 语法： 如果 condition_1条件满足，则执行 do_something_1 然后就跳出,不会执行condition_2; 如果 condition_1条件不满足，则继续执行到 condition_2。以此类推 示例： mysql> create table test_rank(id int, score int); Query OK, 0 rows affected (0.02 sec) mysql> insert into test_rank values(1, 10), (2, 20), (3, 30), (4, 30), (5, 40), (6, 40); Query OK, 6 rows affected (0.00 sec) Records: 6 Duplicates: 0 Warnings: 0 mysql> select * from test_rank; +------+-------+ | id | score | +------+-------+ | 1 | 10 | | 2 | 20 | | 3 | 30 | | 4 | 30 | | 5 | 40 | | 6 | 40 | +------+-------+ 6 rows in set (0.00 sec) mysql> select id, score, -> case -> when @prev_value = score then @rank_count -> when @prev_value := score then @rank_count := @rank_count + 1 -> end as rank_column -- case 开始的，end结尾 -> from test_rank -> order by score desc; +------+-------+-------------+ | id | score | rank_column | +------+-------+-------------+ | 5 | 40 | NULL | | 6 | 40 | NULL | | 3 | 30 | NULL | | 4 | 30 | NULL | | 2 | 20 | NULL | | 1 | 10 | NULL | +------+-------+-------------+ 6 rows in set (0.00 sec) mysql> 同时，上述示例也是一个rank的示例 给出不同的用户的分数，然后根据分数计算排名 case --相等则prev_value不变， 并返回rank_count（第一次为NULL，不会相等，所以跳转到下一个when语句） when @prev_value = score then @rank_count --不等，则第N行的score赋值(:=)给prev_value。且rank_count增加1 when @prev_value := score then @rank_count := @rank_count + 1 end as rank_column -- case 开始的，end结尾 二、视图 1.视图的作用 视图的作用是，可以对开发人员透明，可以隐藏部分关键的列 视图在MySQL中是虚拟表。根据视图的定义，还是取执行定义中的select语句。 2.示例 对上面的test_rank创建一个视图。也可以通过where进行过滤再创建。 mysql> create view view_rank as select * from test_rank; Query OK, 0 rows affected (0.01 sec) //真正的表通过 show table 得到的是表结构 mysql> show create table test_rank \\G *************************** 1. row *************************** Table: test_rank Create Table: CREATE TABLE `test_rank` ( `id` int(11) DEFAULT NULL, `score` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 1 row in set (0.00 sec) //而视图通过 show table 得到的是视图的定义，不会得到表结构 mysql> show create table view_rank \\G *************************** 1. row *************************** View: view_rank Create View: CREATE ALGORITHM=UNDEFINED DEFINER=`root`@`localhost` SQL SECURITY DEFINER VIEW `view_rank` AS select `test_rank`.`id` AS `id`,`test_rank`.`score` AS `score` from `test_rank` character_set_client: utf8 collation_connection: utf8_general_ci 1 row in set (0.00 sec) 可以正确查询到结果集 mysql> select * from view_rank; +------+-------+ | id | score | +------+-------+ | 1 | 10 | | 2 | 20 | | 3 | 30 | | 4 | 30 | | 5 | 40 | | 6 | 40 | +------+-------+ 6 rows in set (0.00 sec) 只展示部分列 mysql> create view view_rank_1 as select id from test_rank; Query OK, 0 rows affected (0.01 sec) mysql> select * from view_rank_1; +------+ | id | +------+ | 1 | | 2 | | 3 | | 4 | | 5 | | 6 | +------+ 6 rows in set (0.00 sec) 创建视图最好是对每个列进行明确列举，因为即使使用seect * from去创建视图，MySQL也会逐个去解析成列。 而当原来的表结构发生变化时，视图的表结构是不会发生变化的，视图在创建的瞬间，便确定了结构。 例如，当alter原来的表 增加列(add columns)时,再去查询该视图,新增加的列是不存在的。 //增加一列名字为c，默认值为0 mysql> alter table test_rank add column c int default 0; Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 //查询原表，新的列c出现了 mysql> select * from test_rank; +------+-------+------+ | id | score | c | +------+-------+------+ | 1 | 10 | 0 | | 2 | 20 | 0 | | 3 | 30 | 0 | | 4 | 30 | 0 | | 5 | 40 | 0 | | 6 | 40 | 0 | +------+-------+------+ 6 rows in set (0.00 sec) //尽管view_rank用select * 创建，但当时没有列c，所以无法得到c列的值 mysql> select * from view_rank; +------+-------+ | id | score | +------+-------+ | 1 | 10 | | 2 | 20 | | 3 | 30 | | 4 | 30 | | 5 | 40 | | 6 | 40 | +------+-------+ 6 rows in set (0.00 sec) 注意： mysql中的视图都是虚拟表。Oracle中的视图也类似，而Oracle提供了物化视图，可以将视图变为真实存在的表。 每次查询视图，实际上还是去查询的原来的表，只是查询的规则是在视图创建时经过定义的。 3.视图的算法 视图的算法( ALGORITHM )有三种： UNDEFINED ：默认方式，让MySQL来判断使用下面的哪种算法 MERGE ： 每次通过物理表 查询得到结果，把结果merge(合并)起来返回 TEMPTABLE ： 产生一张临时表，把数据放入临时表后，客户端再去临时表取数据（不会缓存） TEMPTABLE 特点 ：即使访问条件一样，第二次查询还是会去读取物理表中的内容，并重新生成一张临时表,并不会取缓存之前的表。 （临时表是 Memory 存储引擎，默认放内存，超过配置大小放磁盘） 当查询有一个较大的结果集时，使用 TEMPTABLE 可以快速的结束对该物理表的访问，从而可以快速释放这张物理表上占用的资源。然后客户端可以对临时表上的数据做一些耗时的操作，而不影响原来的物理表。 一般我们使用 UNDEFINED ，由MySQL自己去判断。 三、UNION 与 UNION ALL UNION 的作用是将两个查询的结果集进行合并。 UNION必须由两条或两条以上 的SELECT语句组成，语句之间用关键字 UNION 分隔。 UNION中的每个查询必须包含相同的列（ 类型相同或可以隐式转换 ）、表达式或聚集函数。 如果知道数据本身具有唯一性，没有重复，建议使用 UNION ALL，因为 UNION 会做去重操作，性能会比 UNION ALL要低 mysql> create table test_union_1(a int, b int); Query OK, 0 rows affected (0.02 sec) mysql> create table test_union_2(a int, c int); Query OK, 0 rows affected (0.03 sec) mysql> insert into test_union_1 values(1, 2), (3, 4), (5, 6), (10, 20); Query OK, 4 rows affected (0.01 sec) Records: 4 Duplicates: 0 Warnings: 0 mysql> insert into test_union_2 values(10, 20), (30, 40), (50, 60); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from test_union_1; +------+------+ | a | b | +------+------+ | 1 | 2 | | 3 | 4 | | 5 | 6 | | 10 | 20 | +------+------+ 4 rows in set (0.00 sec) mysql> select * from test_union_2; +------+------+ | a | c | +------+------+ | 10 | 20 | | 30 | 40 | | 50 | 60 | +------+------+ 3 rows in set (0.00 sec) mysql> select a, b from test_union_1 union select * from test_union_2; +------+------+ | a | b | +------+------+ | 1 | 2 | | 3 | 4 | | 5 | 6 | | 10 | 20 | | 30 | 40 | | 50 | 60 | +------+------+ 6 rows in set (0.00 sec) mysql> select a, b from test_union_1 -> union all -> select * from test_union_2; +------+------+ | a | b | +------+------+ | 1 | 2 | | 3 | 4 | | 5 | 6 | | 10 | 20 | | 10 | 20 | | 30 | 40 | | 50 | 60 | +------+------+ 7 rows in set (0.00 sec) mysql> select a, b from test_union_1 where a > 2 -> union -> select * from test_union_2 where c > 50; +------+------+ | a | b | +------+------+ | 3 | 4 | | 5 | 6 | | 10 | 20 | | 50 | 60 | +------+------+ 4 rows in set (0.00 sec) Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:54 "},"13.cfqandccgc.html":{"url":"13.cfqandccgc.html","title":"13.触发器存储过程函数","keywords":"","body":" 一、触发器 1.触发器的定义和类型 2.触发器的创建 3.触发器总结 4.用触发器模拟物化视图 二、存储过程 1.存储过程介绍 2.存储过程中的流程控制 三、自定义函数 一、触发器 1.触发器的定义和类型 定义 触发器的对象是 表 ，当表上出现 特定的事件 时 触发 该程序的执行 触发器的类型 UPDATE：update操作 DELETE delete 操作 replace 操作 注意：drop，truncate等DDL操作 不会触发 DELETE INSERT insert 操作 load data 操作 replace 操作 注意： replace 操作会 触发两次 ，一次是 UPDATE 类型的触发器，一次是 INSERT 类型的触发器 MySQL 5.6版本同一个类型的触发器只能有一个( 针对一个表 ) MySQL 5.7允许多个同一类型的触发器 触发器只触发DML(Data Manipulation Language)操作，不会触发DDL(Data Definition Language)操作 （ create,drop 等操作） 2.触发器的创建 CREATE [DEFINER = { user | CURRENT_USER }] TRIGGER trigger_name -- 触发器名字 trigger_time trigger_event -- 触发时间和事件 ON tbl_name FOR EACH ROW [trigger_order] trigger_body 其中： trigger_time: { BEFORE | AFTER } -- 事件之前还是之后触发 trigger_event: { INSERT | UPDATE | DELETE } -- 三个类型 trigger_order: { FOLLOWS | PRECEDES } other_trigger_name mysql> create table test_trigger_1 ( -> name varchar(10), -> score int(10), -> primary key (name)); Query OK, 0 rows affected (0.03 sec) mysql> delimiter // -- 将语句分隔符定义成 // （原来是';'） mysql> create trigger trg_upd_score -- 定义触发器名字 -> before update on test_trigger_1 -- 作用在test_trigger_1 更新(update)之前(before) -> for each row -- 每行 -> begin -- 开始定义 -> if new.score set new.score=0; -- 则设置成0 -> elseif new.score > 100 then -- 如果新值大于100 -> set new.score = 100; -- 则设置成100 -> end if; -- begin对应的 结束 -> end;// -- 结束，使用新定义的 '//' 结尾 Query OK, 0 rows affected (0.01 sec) mysql> delimiter ; -- 恢复 ';' 结束符 注意： -- new.col : 表示更新以后的值 -- old.col : 表示更新以前的值(只读) --插入新值 mysql> insert into test_trigger_1 values (\"sure\", 1000); Query OK, 1 row affected (0.00 sec) mysql> select * from test_trigger_1; +------+-------+ | name | score | +------+-------+ | sure | 1000 | -- 没改成100，因为定义的是update，而执行的是insert +------+-------+ 1 row in set (0.00 sec) --通过触发器的设置，大于100的值被修改成100 mysql> update test_trigger_1 set score=500 where name ='sure'; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql> select * from test_trigger_1; +------+-------+ | name | score | +------+-------+ | sure | 100 | +------+-------+ 1 row in set (0.00 sec) 3.触发器总结 触发器对性能有损耗，应当非常慎重使用； 对于事务表，触发器执行失败则整个语句回滚 Row格式主从复制， 触发器不会在从库上执行 因为从库复制的肯定是主库已经提交的数据，既然已经提交了说明触发器已经被触发辟了，所以从库不会执行。 使用触发器时应防止递归执行； delimiter // create trigger trg_test before update on 'test_trigger' for each row begin update test_trigger set score=20 where name = old.name; -- 又触发了update操作，循环触发了 end;// 4.用触发器模拟物化视图 物化视图： 不是基于基表的虚表 根据基表实际存在的实表 预先计算并保存耗时较多的SQL操作结果（如多表迹接(join)或者group by等） 物化视图的更新方式有很多种： 从不更新（只在开始更新，只用于静态数据） 根据需要（比如每天，比如每夜） 即时（每次数据修改之后） 一般使用的更新方法： 全部更新（速度慢，完全从无到有） 延时的（速度快，使用log表） 通过在日志表中存储变更信息，通常会产生简单的“快照”或者延时状况： 及时更新 完全更新 示例： --创建order表 mysql> create table Orders -> (order_id int unsigned not null auto_increment, -> product_name varchar(30) not null, -> price decimal(8,2) not null, -> amount smallint not null, -> primary key(order_id)); Query OK, 0 rows affected (0.06 sec) --插入记录 mysql> insert into Orders values -> (null, 'cpu', 135.5 ,1), -> (null, 'memory', 48.2, 3), -> (null, 'cpu', 125.6, 3), -> (null, 'cpu', 105.3, 4); Query OK, 4 rows affected (0.01 sec) Records: 4 Duplicates: 0 Warnings: 0 mysql> select * from Orders; +----------+--------------+--------+--------+ | order_id | product_name | price | amount | +----------+--------------+--------+--------+ | 1 | cpu | 135.50 | 1 | | 2 | memory | 48.20 | 3 | | 3 | cpu | 125.60 | 3 | | 4 | cpu | 105.30 | 4 | +----------+--------------+--------+--------+ 4 rows in set (0.00 sec) --创建模拟的mv mysql> create table Orders_MV -> ( product_name varchar(30) not null, -> price_sum decimal(8,2) not null, -> amount_sum int not null, -> price_avg float not null, -> orders_cnt int not null, -> unique index (product_name)); Query OK, 0 rows affected (0.02 sec) --将mv进行初始化记录 mysql> insert into Orders_MV -> select product_name, sum(price), -> sum(amount), avg(price), count(*) -> from Orders group by product_name; Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> select * from Orders_MV; +--------------+-----------+------------+-----------+------------+ | product_name | price_sum | amount_sum | price_avg | orders_cnt | +--------------+-----------+------------+-----------+------------+ | cpu | 366.40 | 8 | 122.133 | 3 | | memory | 48.20 | 3 | 48.2 | 1 | +--------------+-----------+------------+-----------+------------+ 2 rows in set (0.00 sec) --建立触发器 mysql> delimiter // mysql> CREATE TRIGGER tgr_Orders_insert -- 创建触发器为tgr_Orders_insert -> AFTER INSERT ON Orders -- 触发器是INSERT类型的，且作用于Orders表 -> FOR EACH ROW -> BEGIN -> SET @old_price_sum := 0; -- 设置临时存放Orders_MV表(模拟物化视图)的字段的变量 -> SET @old_amount_sum := 0; -> SET @old_price_avg := 0; -> SET @old_orders_cnt := 0; -> SELECT -- select ... into ... 在更新Orders_MV之前，将Orders_MV中对应某个产品的信息写入临时变量 -> IFNULL(price_sum, 0), -> IFNULL(amount_sum, 0), -> IFNULL(price_avg, 0), -> IFNULL(orders_cnt, 0) -> FROM -> Orders_MV -> WHERE -> product_name = NEW.product_name INTO @old_price_sum , @old_amount_sum , @old_price_avg , @old_orders_cnt; -> SET @new_price_sum = @old_price_sum + NEW.price; -- 累加新的值 -> SET @new_amount_sum = @old_amount_sum + NEW.amount; -> SET @new_orders_cnt = @old_orders_cnt + 1; -> SET @new_price_avg = @new_price_sum / @new_orders_cnt ; -> REPLACE INTO Orders_MV -> VALUES(NEW.product_name, @new_price_sum, -> @new_amount_sum, @new_price_avg, @new_orders_cnt ); -> -- REPLACE 将对应的物品（唯一索引）的字段值替换new_xxx的值 -> END;// Query OK, 0 rows affected (0.01 sec) mysql> delimiter ; --插入新的记录 mysql> insert into Orders values (null, 'ssd', 299, 3); Query OK, 1 row affected (0.00 sec) mysql> insert into Orders values (null, 'memory', 47.9, 5); Query OK, 1 row affected (0.01 sec) --查询order_mv，发现相应的值也做了变化 mysql> select * from Orders_MV; +--------------+-----------+------------+-----------+------------+ | product_name | price_sum | amount_sum | price_avg | orders_cnt | +--------------+-----------+------------+-----------+------------+ | cpu | 366.40 | 8 | 122.133 | 3 | | memory | 96.10 | 8 | 48.05 | 2 | | ssd | 299.00 | 3 | 299 | 1 | +--------------+-----------+------------+-----------+------------+ 3 rows in set (0.00 sec) 二、存储过程 1.存储过程介绍 存储在数据库端的一组SQL语句逸； 用户可以通过存储过程名和传参多次调用的程序模块； 存储辟程的特点： 使用灵活，可以使用流控语句、自定义变量等完成复杂的业务逻辑； 提高数据安全性，屏蔽应用程序直接对表的操作，易于进行审计； 减少网络传输； 提高代码维护的复杂度，实际使用需要结合业务评估； CREATE [DEFINER = { user | CURRENT_USER }] PROCEDURE sp_name ([proc_parameter[,...]]) [characteristic ...] routine_body proc_parameter: -- 注意，只有procedure才有in(传入),out(传出),inout(传入传出)参数，自定义函数（只有）默认就是 in。 [ IN | OUT | INOUT ] param_name type characteristic: COMMENT 'string' | LANGUAGE SQL | [NOT] DETERMINISTIC | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } routine_body: Valid SQL routine statement 2.存储过程中的流程控制 if 语句 IF search_condition THEN statement_list [ELSEIF search_condition THEN statement_list] ... [ELSE statement_list] END IF 示例 创建存储过程 mysql> delimiter // mysql> create procedure pcd_test_1 (in param_a int) -- 创建一个 -> begin -> declare a int; -- delcare声明了该变量的作用域在该procedure中 -> if param_a > 10 then set a:=11; -> elseif param_a = 10 then set a:=10; -> else set a:=9; -> end if; -> select a; -> end;// Query OK, 0 rows affected (0.00 sec) mysql> delimiter ; 调用存储过程 --传入值为1，根据存储过程的逻辑，a=9 mysql> call pcd_test_1(1); +------+ | a | +------+ | 9 | +------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) --传入值为10，根据存储过程的逻辑，a=10 mysql> call pcd_test_1(10); +------+ | a | +------+ | 10 | +------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) --传入值为20，根据存储过程的逻辑，a=11 mysql> call pcd_test_1(20); +------+ | a | +------+ | 11 | +------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) --a的赋值范围仅限于存储过程中，所以这个地方的值为null mysql> select @a; +------+ | @a | +------+ | NULL | +------+ 1 row in set (0.00 sec) 3.CASE WHEN 语句 CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list] ... [ELSE statement_list] END CASE -- 或者是 CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list] ... [ELSE statement_list] END CASE 示例 mysql> delimiter // mysql> create procedure pcd_test_2(in param_1 int) -> begin -> case param_1 -> -- 当case后面有value时，该value会和when中的when_value进行\"=\"判断 -> -- 相等则执行then后面的语句，然后跳出；否则就进行下一次when的匹配 -> when 2 then select 200; -> when 3 then select 300; -> else -> begin -> -- 当没有匹配时，且else中没有要执行的语句 -> -- 则给一个begin/end的空语句； -> -- 或者不写else语句；或者写个其他的提示性语句； -> select \"not found!\"; -> end; -> end case; -> end;// Query OK, 0 rows affected (0.00 sec) mysql> delimiter ; mysql> call pcd_test_2(1); +------------+ | not found! | +------------+ | not found! | +------------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) mysql> call pcd_test_2(2); +-----+ | 200 | +-----+ | 200 | +-----+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) mysql> call pcd_test_2(3); +-----+ | 300 | +-----+ | 300 | +-----+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) 4.WHILE 语句 [begin_label:] WHILE search_condition DO statement_list END WHILE [end_label] 示例： mysql> delimiter // mysql> create procedure pcd_test_3(in param_1 int) -> begin -> declare a int default 1; -> while param_1 > 10 do -> set param_1 = param_1 - 1; -> set a = a + 1; -> end while; -> select a; -> end;// Query OK, 0 rows affected (0.00 sec) mysql> delimiter ; --15 - 10 = 5；需要5次循环 mysql> call pcd_test_3(15); +------+ | a | +------+ | 6 | --a=a+1=5+1=6 +------+ 1 row in set (0.00 sec) Query OK, 0 rows affected (0.00 sec) 5.REPEAT语句 [begin_label:] REPEAT statement_list UNTIL search_condition END REPEAT [end_label] 示例： mysql> delimiter // mysql> create procedure pcd_test_4(in param_1 int) -> begin -> SET @x = 0; -- 没有使用declare，所以x是会话级别的 -> REPEAT -> SET @x = @x + 1; -> UNTIL @x > param_1 END REPEAT; -> end;// Query OK, 0 rows affected (0.00 sec) mysql> delimiter ; mysql> call pcd_test_4(10); Query OK, 0 rows affected (0.00 sec) mysql> select @x; +------+ | @x | +------+ | 11 | +------+ 1 row in set (0.00 sec) 6.loop语句 [begin_label:] LOOP statement_list END LOOP [end_label] -- ITERATE 和label相结合，表示继续从label处执行 -- LEAVE 和label相结合，表示从label 标记的代码段离开 示例： mysql> delimiter // mysql> create procedure pcd_test_5(in param_1 int) -> begin -> test_label: loop -> set param_1 := param_1 + 1; -- 参数累加 -> if param_1 iterate test_label; -- 继续执行 标签 test_label -> end if; -> leave test_label; -- 如果>=10则离开这个test_label(loop) -> end loop test_label; -> set @x = param_1; -- 设置会话级别的变量 -> end;// Query OK, 0 rows affected (0.01 sec) mysql> delimiter ; -- 5=10为true，离开循环 mysql> call pcd_test_5(5); Query OK, 0 rows affected (0.00 sec) mysql> select @x; +------+ | @x | +------+ | 10 | +------+ 1 row in set (0.00 sec) 三、自定义函数 自定义函数和存储过程很类似，但是必需要有返回值； 与内置的函数(sum(), max()等)使用方法类似 select fun(val); select * from t where col= fun(val); 自定义函数可能在遍历每条记录中使用； CREATE [DEFINER = { user | CURRENT_USER }] FUNCTION sp_name ([func_parameter[,...]]) RETURNS type -- 必须有返回值 [characteristic ...] routine_body func_parameter: param_name type type: Any valid MySQL data type characteristic: COMMENT 'string' | LANGUAGE SQL | [NOT] DETERMINISTIC | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA } | SQL SECURITY { DEFINER | INVOKER } routine_body: Valid SQL routine statement 示例： 计算一个阶乘 --创建一个存放记录的表 mysql> create table test_proc_1(a int, b int); Query OK, 0 rows affected (0.02 sec) --定义函数 mysql> delimiter // mysql> create function fun_test_1(total int) -> returns int -> begin -> declare i int; -> declare res int; -> set i := 1; -> set res := 1; -> if total set total := 1; -> end if; -> while i set res := res * i; -> set i := i + 1; -> end while; -> return res; -> end;// ERROR 1418 (HY000): This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable) 上面的定义报错了，原因是因为函数的声明中没有\"DETERMINISTIC, NO SQL, or READS SQL DATA\"等关键字 ，需要使用打开参数 log_bin_trust_function_creators，或者 增加 上述相应功能的关键字 使用 deterministic 关键字 mysql> create function fun_test_1(total int) -> returns int deterministic -- 这个只是告诉MySQL这个函数是否会改变数据 -> -- 即使下面使用了insert，update等DML语句，MySQL不会检查 -> -- 函数是否会改变数据，完全依赖创建函数的用户去指定的关键字 -> -- 而非真的是否有修改数据。仅仅只是声明，而非约束 -> begin -> declare i int; -> declare res int; -> set i := 1; -> set res := 1; -> if total set total := 1; -> end if; -> while i set res := res * i; -> insert into test_proc_1 values(i, res); -- 在自定义函数中，同样可以使用sql并且该SQL是insert，其实和deterministic违背。 -> set i := i + 1; -> end while; -> return res; -> end;// Query OK, 0 rows affected (0.00 sec) mysql> delimiter ; --测试调用 mysql> select fun_test_1(6); +---------------+ | fun_test_1(6) | +---------------+ | 720 | +---------------+ 1 row in set (0.00 sec) mysql> select * from test_proc_1; +------+------+ | a | b | +------+------+ | 1 | 1 | | 2 | 2 | | 3 | 6 | | 4 | 24 | | 5 | 120 | | 6 | 720 | +------+------+ 6 rows in set (0.00 sec) 关键字简单说明： DETERMINISTIC ： 当给定相同的输入，产生确定的结果 NOT DETERMINISTIC ： 默认值，认为产生的结果是不确定的 READS SQL DATA ： 只是读取SQL数据 MODIFIES SQL DATA ： 会修改数据 NO SQL ： 没有SQL遇见 CONTAINS SQL ： 包含SQL语句，但是没有读写语句，理论有select now()等 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:52 "},"14.backrecover.html":{"url":"14.backrecover.html","title":"14.备份与恢复","keywords":"","body":" 概览 1.冷备 2.热备 2.1 mysqldump 2.2 mysqlpump 2.3 mydumper 2.4 xtrabackup 概览 1.冷备 很简单：关数据，物理copy。基本不会用到这种方式。 2.热备 从以下维度选择备份方式： 备份速度 恢复速度 备份大小 对业务影响 表，包含表结构，约束（主键，唯一键，外键等），当然索引这东西实际上不需要备份，也无法备份。 视图 存储过程 存储函数 触发器 事件 以上对象在全库备份时一个都不能少，否则全库备份就失去意义。 默认情况下，mysqldump仅仅备份表，视图和触发器。 -E，指定导出事件（events）。 -R，指定导出存储程序（函数和过程）。 mysqlpump工具，默认导出所有的六类对象。 但是mysqlpump没有 --lock-all-tables 和 --lock-tables 参数。虽然有 --single-transaction 参数，但默认也off。 所以很明显，导出的备份不是数据一致性快照。 如果我们需要使用mysqlpump备份，并且需要数据一致性快照的话，那么我们必须在pump之前手工使用 FLUSH TABLES WITH READ LOCK 锁住数据库。 特别注意： FTWRL(flush tables with read lock)，全局禁止读写。为了获取一致性位点，都强依赖于FTWRL。这个锁杀伤力非常大，因为持有锁的这段时间，整个数据库实质上不能对外提供写服务的。此外，由于FTWRL需要关闭表，如有大查询，会导致FTWRL等待，进而导致DML堵塞的时间变长。即使是备库，也有SQL线程在复制来源于主库的更新，上全局锁时，会导致主备库延迟。从前面的分析来看，FTWRL这把锁持有的时间主要与非innodb表的数据量有关，如果非innodb表数据量很大，备份很慢，那么持有锁的时间就会很长。即使全部是innodb表，也会因为有mysql库系统表存在，导致会锁一定的时间。 2.1 mysqldump mysqldump [OPTIONS] --single-transaction database [tables] # 备份某个数据库下的表 mysqldump [OPTIONS] --single-transaction --databases [OPTIONS] DB1 [DB2 DB3...] # 备份指定数据库 mysqldump [OPTIONS] --single-transaction --all-databases [OPTIONS] # 备份所有数据库 For more options, use mysqldump --help 需要注意single-transaction ： 在一个事务中导出，确保产生一致性的备份 ，当前只对innodb支持 2.1.1 mysqldump参数说明 参数说明 --all-databases , -A 导出全部数据库 eg: mysqldump -uroot -p123456 --all-databases --all-tablespaces , -Y 导出全部表空间 eg: mysqldump -uroot -p123456 --all-databases --all-tablespaces --no-tablespaces , -y 不导出任何表空间信息 eg: mysqldump -uroot -p123456 --all-databases --no-tablespaces --add-drop-database 每个数据库创建之前添加drop数据库语句 eg: mysqldump -uroot -p123456 --all-databases --add-drop-database --add-drop-table 每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用--skip-add-drop-table取消选项) eg: mysqldump -uroot -p123456 --all-databases (默认添加drop语句) eg: mysqldump -uroot -p123456 --all-databases –skip-add-drop-table (取消drop语句) --add-locks 在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(默认为打开状态，使用--skip-add-locks取消选项) eg: mysqldump -uroot -p123456 --all-databases (默认添加LOCK语句) eg: mysqldump -uroot -p123456 --all-databases –skip-add-locks (取消LOCK语句) --allow-keywords 允许创建是关键词的列名字 eg: mysqldump -uroot -p123456 --all-databases --allow-keywords --apply-slave-statements 在'CHANGE MASTER'前添加'STOP SLAVE'，并且在导出的最后添加'START SLAVE'。 eg: mysqldump -uroot -p123456 --all-databases --apply-slave-statements --character-sets-dir 字符集文件的目录 eg: mysqldump -uroot -p123456 --all-databases --character-sets-dir=/usr/local/mysql/share/mysql/charsets --comments 附加注释信息。默认为打开，可以用--skip-comments取消 eg: mysqldump -uroot -p123456 --all-databases (默认记录注释) eg: mysqldump -uroot -p123456 --all-databases --skip-comments (取消注释) --compatible 导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等，要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。 eg: mysqldump -uroot -p123456 --all-databases --compatible=ansi --compact 导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：--skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys eg: mysqldump -uroot -p123456 --all-databases --compact --complete-insert, -c 使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。 eg: mysqldump -uroot -p123456 --all-databases --complete-insert --compress, -C 在客户端和服务器之间启用压缩传递所有信息 eg: mysqldump -uroot -p123456 --all-databases --compress --create-options, -a 在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态) eg: mysqldump -uroot -p123456 --all-databases --databases, -B 导出几个数据库。参数后面所有名字参量都被看作数据库名。 eg: mysqldump -uroot -p123456 --databases test mysql --debug 输出debug信息，用于调试。默认值为：d:t:o , /tmp/mysqldump.trace eg: mysqldump -uroot -p123456 --all-databases --debug eg: mysqldump -uroot -p123456 --all-databases --debug=\"d:t:o,/tmp/debug.trace\" --debug-check 检查内存和打开文件使用说明并退出。 eg: mysqldump -uroot -p123456 --all-databases --debug-check --debug-info 输出调试信息并退出 eg: mysqldump -uroot -p123456 --all-databases --debug-info --default-character-set 设置默认字符集，默认值为utf8 eg: mysqldump -uroot -p123456 --all-databases --default-character-set=latin1 --delayed-insert 采用延时插入方式（INSERT DELAYED）导出数据 eg: mysqldump -uroot -p123456 --all-databases --delayed-insert --delete-master-logs master备份后删除日志. 这个参数将自动激活--master-data eg: mysqldump -uroot -p123456 --all-databases --delete-master-logs --disable-keys 对于每个表，用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。 eg: mysqldump -uroot -p123456 --all-databases --dump-slave 该选项将导致主的binlog位置和文件名追加到导出数据的文件中。设置为1时，将会以CHANGE MASTER命令输出到数据文件；设置为2时，在命令前增加说明信息。该选项将会打开--lock-all-tables，除非--single-transaction被指定。该选项会自动关闭--lock-tables选项。默认值为0。 eg: mysqldump -uroot -p123456 --all-databases --dump-slave=1 eg: mysqldump -uroot -p123456 --all-databases --dump-slave=2 --events, -E 导出事件。 eg: mysqldump -uroot -p123456 --all-databases --events --extended-insert, -e 使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项。 eg: mysqldump -uroot -p123456 --all-databases eg: mysqldump -uroot -p123456 --all-databases--skip-extended-insert (取消选项) --fields-terminated-by 导出文件中忽略给定字段。与--tab选项一起使用，不能用于--databases和--all-databases选项 eg: mysqldump -uroot -p123456 test test --tab=”/home/mysql” --fields-terminated-by=”#” --fields-enclosed-by 输出文件中的各个字段用给定字符包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项 eg: mysqldump -uroot -p123456 test test --tab=”/home/mysql” --fields-enclosed-by=”#” --fields-optionally-enclosed-by 输出文件中的各个字段用给定字符选择性包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项 eg: mysqldump -uroot -p123456 test test --tab=”/home/mysql” --fields-enclosed-by=”#” --fields-optionally-enclosed-by =”#” --fields-escaped-by 输出文件中的各个字段忽略给定字符。与--tab选项一起使用，不能用于--databases和--all-databases选项 eg: mysqldump -uroot -p123456 mysql user --tab=”/home/mysql” --fields-escaped-by=”#” --flush-logs 开始导出之前刷新日志。 注意：假如一次导出多个数据库(使用选项--databases或者--all-databases)，将会逐个数据库刷新日志。除使用--lock-all-tables或者--master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用--lock-all-tables 或者--master-data 和--flush-logs。 eg: mysqldump -uroot -p123456 --all-databases --flush-logs --flush-p123456rivileges 在导出mysql数据库之后，发出一条FLUSH PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。 eg: mysqldump -uroot -p123456 --all-databases --flush-p123456rivileges --force 在导出过程中忽略出现的SQL错误。 eg: mysqldump -uroot -p123456 --all-databases --force --help 显示帮助信息并退出。 eg: mysqldump --help --hex-blob 使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。 eg: mysqldump -uroot -p123456 --all-databases --hex-blob --host, -h 需要导出的主机信息 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --ignore-table 不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table=database.table1 --ignore-table=database.table2 …… eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --ignore-table=mysql.user --include-master-host-p123456ort 在--dump-slave产生的'CHANGE MASTER TO..'语句中增加'MASTER_HOST=，MASTER_PORT=' eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --include-master-host-p123456ort --insert-ignore 在插入行时使用INSERT IGNORE语句 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --insert-ignore --lines-terminated-by 输出文件的每行用给定字符串划分。与--tab选项一起使用，不能用于--databases和--all-databases选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock test test --tab=”/tmp/mysql” --lines-terminated-by=”##” --lock-all-tables, -x 提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭--single-transaction 和--lock-tables 选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --lock-all-tables --lock-tables, -l 开始导出前，锁定所有表。用READ LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，--single-transaction是一个更好的选择，因为它根本不需要锁定表。 注意当导出多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --lock-tables --log-error 附加警告和错误信息到给定文件 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --log-error=/tmp/mysqldump_error_log.err --master-data 该选项将binlog的位置和文件名追加到输出文件中。如果为1，将会输出CHANGE MASTER 命令；如果为2，输出的CHANGE MASTER命令前添加注释信息。该选项将打开--lock-all-tables 选项，除非--single-transaction也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的--single-transaction选项）。该选项自动关闭--lock-tables选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --master-data=1; eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --master-data=2; --max_allowed_packet 服务器发送和接受的最大包长度。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --max_allowed_packet=10240 --net_buffer_length TCP/IP和socket连接的缓存大小。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --net_buffer_length=1024 --no-autocommit 使用autocommit/commit 语句包裹表。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --no-autocommit --no-create-db, -n 只导出数据，而不添加CREATE DATABASE 语句。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --no-create-db --no-create-info, -t 只导出数据，而不添加CREATE TABLE 语句。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --no-create-info --no-data, -d 不导出任何数据，只导出数据库表结构。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --no-data --no-set-names, -N 等同于--skip-set-charset eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --no-set-names --opt 等同于--add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys 该选项默认开启, 可以用--skip-opt禁用. eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --opt --order-by-p123456rimary 如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --order-by-p123456rimary --p123456ipe(windows系统可用) 使用命名管道连接mysql eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --p123456ipe --p123456ort, -p123456 连接数据库端口号 --p123456rotocol 使用的连接协议，包括：tcp, socket, pipe, memory. eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --p123456rotocol=tcp --quick, -q 不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-quick --quote-names,-Q 使用（`）引起表和列名。默认为打开状态，使用--skip-quote-names取消该选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-quote-names --replace 使用REPLACE INTO 取代INSERT INTO. eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --replace --result-file, -r 直接输出到指定文件中。该选项应该用在使用回车换行对（\\\\r\\\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --result-file=/tmp/mysqldump_result_file.txt --routines, -R 导出存储过程以及自定义函数。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --routines --set-charset 添加'SET NAMES default_character_set'到输出文件。默认为打开状态，使用--skip-set-charset关闭选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-set-charset --single-transaction 该选项在导出数据之前提交一个BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅InnoDB。本选项和--lock-tables 选项是互斥的，因为LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用--quick 选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --single-transaction --dump-date 将导出时间添加到输出文件中。默认为打开状态，使用--skip-dump-date关闭选项。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-dump-date --skip-opt 禁用–opt选项. eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-opt --socket,-S 指定连接mysql的socket文件位置，默认路径/tmp/mysql.sock eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --socket=/tmp/mysqld.sock --tab,-T 为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock test test --tab=\"/home/mysql\" --tables 覆盖--databases (-B)参数，指定需要导出的表名。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --databases test --tables test --triggers 导出触发器。该选项默认启用，用--skip-triggers禁用它。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --triggers --tz-utc 在导出顶部设置时区TIME_ZONE='+00:00' ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --tz-utc --user, -u 指定连接的用户名。 --verbose, --v 输出多种平台信息。 --version, -V 输出mysqldump版本信息并退出 --where, -w 只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --where=” user=’root’” --xml, -X 导出XML格式. eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --xml --p123456lugin_dir 客户端插件的目录，用于兼容不同的插件版本。 eg: mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --p123456lugin_dir=”/usr/local/lib/plugin” --default_auth 客户端插件默认使用权限。 2.1.2 重要参数介绍 以上是根据 --help得到的参数 下面将重点列举几个生产环境中常用的参数 single-transaction 当开始备份的时候，备份的是备份点（备份开始的时刻） 时的数据（即使在备份过程中，表中的数据发生了改变） 实现方式：在开启事物前，先设置为 RR 隔离级别（ 事物隔离级别是会话级别，由 mysqldump 自己设置 ），因为RR级别 解决 了 不可重复读 和 幻读 问题，所以在备份的时刻开启一个事务后，读取的数据是能保证一致性的 mysql> show variables like '%socket%'; +-----------------------------------------+-----------------+ | Variable_name | Value | +-----------------------------------------+-----------------+ | performance_schema_max_socket_classes | 10 | | performance_schema_max_socket_instances | -1 | | socket | /tmp/mysql.sock | +-----------------------------------------+-----------------+ 3 rows in set (0.00 sec) mysql> exit Bye [root@nazeebo ~]# mysqldump -uroot -p --single-transaction --databases employees -S /tmp/mysql.sock > employees_bak.sql Enter password: Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don't want to restore GTIDs, pass --set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events. [root@nazeebo ~]# ll total 164432 -rw-r--r-- 1 root root 168376235 Jul 17 11:41 employees_bak.sql master-data 备份的时候dump出 CHANGE MASTER 信息（file 和 pos），可供 主从复制的时候使用， 默认值为1 。 当值设置为 2 的时候，也会dump出信息，但是会被 注释 掉 [root@nazeebo ~]# mysqldump -uroot -p --single-transaction --master-data=1 --databases test -S /tmp/mysql.sock > test_bak_1.sql Enter password: Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don't want to restore GTIDs, pass --set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events. [root@nazeebo ~]# mysqldump -uroot -p --single-transaction --master-data=2 --databases test -S /tmp/mysql.sock > test_bak_2.sql Enter password: Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don't want to restore GTIDs, pass --set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events. [root@nazeebo ~]# [root@nazeebo ~]# diff test_bak_1.sql test_bak_2.sql 30c30 -- CHANGE MASTER TO MASTER_LOG_FILE='bin.000006', MASTER_LOG_POS=21135; 1024c1024 -- Dump completed on 2018-07-17 11:45:02 CHANGE MASTER 信息表示，这个mysqldump出来的文件，是在这个 MASTER_LOG_FILE 文件的 MASTER_LOG_POS 位置备份出来的，是一个 起始位置 信息 dump-slave 该选项将导致主的binlog位置和文件名追加到导出数据的文件中。 设置为1时，将会以CHANGE MASTER命令输出到数据文件； 设置为2时，在命令前增加说明信息。 该选项将会打开--lock-all-tables，除非--single-transaction被指定。该选项会自动关闭--lock-tables选项。默认值为0。 mysqldump -uroot -p123456 --all-databases --dump-slave=1 -S /tmp/mysql.sock > full_bak.sql mysqldump -uroot -p123456 --all-databases --dump-slave=2 -S /tmp/mysql.sock > full_bak.sql no-data 不导出任何数据，只导出数据库表结构。 [root@nazeebo ~]# mysqldump -uroot -p123456 --no-data --databases test -S /tmp/mysql.sock > test_bak_3.sql no-create-info 与no-data相反，这个参数只导出数据不包含创建表的表结构 quick 不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项 mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --skip-quick default-character-set 设置默认字符集，默认值为utf8, ，要与备份出的表的字符集保持一致 mysqldump -uroot -p123456 --all-databases --default-character-set=latin1 complete-insert 使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。 mysqldump -uroot -p123456 --all-databases --complete-insert -S /tmp/mysql.sock > test_bak.sql all-databases 导出全部数据库 mysqldump -uroot -p123456 --all-databases -S /tmp/mysql.sock > test_bak.sql databases 导出几个数据库。参数后面所有名字参量都被看作数据库名。 mysqldump -uroot -p123456 --databases test mysql -S /tmp/mysql.sock > somedb_bak.sql 2.1.3 flush-logs 注意：假如一次导出多个数据库(使用选项--databases或者--all-databases)，将会逐个数据库刷新日志。除使用--lock-all-tables或者--master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用--lock-all-tables 或者--master-data 和--flush-logs。 mysqldump -uroot -p123456 --all-databases --flush-logs 另外，这个参数要重点提一句： 从mysqldump备份文件恢复数据会丢失掉从备份点开始的更新数据，所以还需要结合mysqlbinlog二进制日志增量备份。确保my.cnf中包含下面的配置以启用二进制日志，或者mysqld ---log-bin： mysqldump命令必须带上--flush-logs 以便生成新的二进制日志文件：这样生成的增量二进制日志文件比如为mysql-bin.00000X，那么恢复数据时如下： --先进行全备恢复 mysql -uroot -p123456 此外，mysqlbinlog还可以指定--start-date、--stop-date、--start-position和--stop-position参数，用于精确恢复数据到某个时刻之前或者跳过中间某个出问题时间段恢复数据。 可以参考MySQL_FAQ一章中的《恢复被误删的表》 where 只转储给定的WHERE条件选择的记录。 请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。 mysqldump -uroot -p123456 -S /tmp/mysql.sock --all-databases --where=” user='root'” set-gtid-purged 以上的备份操作，如果数据库开启了gtid的选项，但备份过程中又不想带gtid的信息，那么可以使用 --set-gtid-purged=off参数来达到效果 2.1.4 恢复操作 备份与恢复是匹配的，恢复操作更简单一些 直接利用mysql -uroot -p 来进行恢复即可 恢复全库 备份全库： mysqldump -uroot -p123456 --single-transaction -S /tmp/mysql.sock > all_bak.sql 恢复全库： mysql -uroot -p123456 -S /tmp/mysql.sock 恢复单库 备份库employee： mysqldump --single-transaction -S /tmp/mysql.sock -uroot -p123456 employee > employee_bak.sql 恢复employee库： mysql -uroot -p123456 employee -S /tmp/mysql.sock 恢复单表 备份表 employee.dept： mysqldump --single-transaction -S /tmp/mysql.sock -uroot -p123456 employee dept > employee_dept_bak.sql 恢复表employee.dept： mysql -uroot -p123456 employee -S /tmp/mysql.sock 2.1.5 使用mysqldump注意事项 备份包括六大件： 表，包含表结构，约束（主键，唯一键，外键等），当然索引这东西实际上不需要备份，也无法备份。 视图 存储过程 存储函数 触发器 事件 以上对象在全库备份时一个都不能少，否则全库备份就失去意义。 默认情况下，mysqldump仅仅 备份表，视图和触发器。 如果需要备份事件和存储过程，需要使用下面两个参数 -E，指定导出事件（events） -R，指定导出存储程序（函数和过程） 另外，在备份过程中，可能会出现性能的抖动，出现性能急剧下降的现象。原因是因为mysqldump是先从buffer里面找想要的内容，如果buffer中找不到，则需要去访问磁盘中的数据文件，然后把数据调回内存中，再形成备份文件。而在这个过程中，有可能会被热点数据从buffer中刷走，故影响了性能。 在MySQL5.7，新增了一个参数innodb_buffer_pool_dump_pct，用这个参数来控制每个innodb buffer中转储活跃使用的innodb buffer pages的比例，只有当数据在1秒内再次被访问时，才能放到热区域中，这样避免了热数据被冲走的情况 2.2 mysqlpump 在 MySQL5.7 版本推出了 mysqlpump工具 。 可以理解它是mysqldump的加强版，几大提升： 并行备份数据库和数据库中的对象的，加快备份过程。 更好的控制数据库和数据库对象（表，存储过程，用户帐户）的备份，默认导出所有的六类对象。 备份用户账号作为帐户管理语句（CREATE USER，GRANT），而不是直接插入到MySQL的系统数据库。 备份出来直接生成压缩后的备份文件。 备份进度指示（估计值）。 重新加载（还原）备份文件，先建表后插入数据最后建立索引，减少了索引维护开销，加快了还原速度。 备份可以排除或则指定数据库。 需要注意的是： 要确保使用mysqlpump的版本在5.7.11及以上（在5.7.11以前，mysqlpump和并行参数是有冲突的，在这个版本之后做了修复） mysqlpump没有 --lock-all-tables 和 --lock-tables 参数。虽然有 --single-transaction 参数，但默认也off。所以很明显，导出的备份不是数据一致性快照。如果我们需要使用mysqlpump备份，并且需要数据一致性快照的话，那么我们必须在pump之前手工使用 FLUSH TABLES WITH READ LOCK 锁住数据库。 mysqlpump 是多线的，但是只能到 表级别 ，对于 一张表 来说，还是 单线程的 mysqlpump 有默认的队列（default），队列下面可以有N个线程去备份数据库/数据库下的表 mysqlpump 可以开多个队列（对应不同的库/表），然后每个队列设置不同的线程数，进行并发备份 mysqlpump 会先插入数据，在建立索引 ；而mysqldump在建立表的时候就把索引加上了，所以mysqlpump在导入数据的时候也比mysqldump要快 mysqlpump 目前 导入 的时候是 单线程 的 2.2.1 mysqlpump重要参数 mysqlpump参数常甠参数同mysqldump类似，以下参数和并发相关的 --default-parallelism=4 #线程数，默认开 2 个线程进行并发备份 --parallel-schemas=name #哪些数据库进行并发备份 --compress-output #mysqlpump 支持压缩 功能，支持 LZ4 和 ZLIB 。ZLIB 压缩比例对较高，但是速度较慢 2.2.2 mysqlpump示例 mysqlpump --single-transaction --databases employees -S /tmp/mysql.sock > employees_pump_1.sql mysqlpump -S /tmp/mysql.sock --single-transaction --parallel-schemas=2:employees --parallel-schemas=4:dbt3 --databases employees dbt3 > backup.sql --parallel-schemas=2:employees 表示备份employees库使用2个线程 --parallel-schemas=4:dbt3 表示备份dbt3库使用4个线程 --databases employees dbt3 表示指定备份 employees 和 dbt3 这两个库 2.2.3 mysqlpump恢复 恢复没有被压缩的库 mysql 恢复压缩的库，需要先将压缩的库解压lz4_decompress backup.sql.lz4 backup.sql，再进行恢复 mysql 2.3 mydumper mydumper是一个针对MySQL的高性能多线程的备份工具，也属于逻辑备份，恢复的时候使用myloader工具进行恢复。 2.3.1 mydumper特点： 支持多线程导出数据，速度比mysqldump快。 支持一致性备份，使用FTWRL(FLUSH TABLES WITH READ LOCK)会阻塞DML语句,保证备份数据的一致性。 支持将导出文件压缩，节约空间。 支持多线程恢复。 支持以守护进程模式工作，定时快照和连续二进制日志 支持按照指定大小将备份文件切割。 数据与建表语句分离。 2.3.2 mydumper的主要工作步骤： 主线程 FLUSH TABLES WITH READ LOCK, 施加全局只读锁，以阻止DML语句写入，保证数据的一致性 读取当前时间点的二进制日志文件名和日志写入的位置并记录在metadata文件中，以供即使点恢复使用 START TRANSACTION WITH CONSISTENT SNAPSHOT; 开启读一致事务 启用N个（线程数可以指定，默认是4）dump线程导出表和表结构 备份非事务类型的表 主线程 UNLOCK TABLES，备份完成非事务类型的表之后，释放全局只读锁 dump InnoDB tables, 基于事物导出InnoDB表 事物结束 2.3.3 参数说明 mydumper 的常用参数 -B, --database 要导出的dbname -T, --tables-list 需要导出的表名,导出多个表需要逗号分隔，t1[,t2,t3 ....] -o, --outputdir 导出数据文件存放的目录，mydumper会自动创建 -s, --statement-size 生成插入语句的字节数, 默认1000000字节 -r, --rows Try to split tables into chunks of this many rows. This option turns off --chunk-filesize -F, --chunk-filesize 切割表文件的大小，默认单位是 MB ，如果表大于 -c, --compress 压缩导出的文件 -e, --build-empty-files 即使是空表也为表创建文件 -x, --regex 使用正则表达式匹配 db.table -i, --ignore-engines 忽略的存储引擎，多个值使用逗号分隔 -m, --no-schemas 只导出数据，不导出建库建表语句 -d, --no-data 仅仅导出建表结构，创建db的语句 -G, --triggers 导出触发器 -E, --events 导出events -R, --routines 导出存储过程和函数 -k, --no-locks 不执行临时的只读锁，会导致备份不一致 。WARNING: This will cause inconsistent backups --less-locking 最小化在innodb表上的锁表时间 --butai -l, --long-query-guard 设置长时间执行的sql 的时间标准 -K, --kill-long-queries 将长时间执行的sql kill -D, --daemon 以守护进程的方式执行 -I, --snapshot-interval 创建导出快照的时间间隔，默认是 60s ，该参数只有在守护进程执行的时候有用。 -L, --logfile 指定mydumper输出的日志文件，默认使用控制台输出。 --tz-utc SET TIME_ZONE='+00:00' at top of dump to allow dumping of TIMESTAMP data when a server has data in different time zones or data is being moved between servers with different time zones, defaults to on use --skip-tz-utc to disable. --skip-tz-utc --use-savepoints 使用savepoints 减少MDL 锁事件 需要 SUPER 权限 --success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn myloader使用参数 -d, --directory 备份文件的文件夹 -q, --queries-per-transaction 每次事物执行的查询数量，默认是1000 -o, --overwrite-tables 如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构 -B, --database 需要还原的数据库 -e, --enable-binlog 启用还原数据的二进制日志 -h, --host The host to connect to -u, --user Username with privileges to run the dump -p, --password User password -P, --port TCP/IP port to connect to -S, --socket UNIX domain socket file to use for connection -t, --threads 还原所使用的线程数，默认是4 -C, --compress-protocol 压缩协议 -V, --version 显示版本 -v, --verbose 输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为2 注意：mydumper没有—where参数，部分场景不适用 2.3.4 mydumper使用示例 导出整个库 mydumper -u root -S /tmp/mysql.sock -B employee -o /bak/employee 导出platform的ddl语句不包含数据到指定的目录 /bak/employee mydumper -u root -S /tmp/mysql.sock -B employee -m -o /bak/employee 以压缩的方式导出的文件 mydumper -u root -S /tmp/mysql.sock -B employee -c -o /bak/employee 使用正则表达式 ,--regex=order.* 导出所有order 开头的表 mydumper -u root -S /tmp/mysql.sock --regex='^(?!(mysql|test))' -o /bak/bktest20180717 mydumper 导出的文件分为: metadata :包含导出时刻的binlog 位点信息 ，如果启用gtid ，则记录gtid信息。 db.table.sql :数据文件，insert语句 db.table-schema.sql :包含建表语句 db-schema.sql :包含建库语句 2.4 xtrabackup 内容较多，单独写一章 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 08:44:58 "},"15.backuprecoverpxb.html":{"url":"15.backuprecoverpxb.html","title":"15.备份恢复-pxb","keywords":"","body":" 一、Xtrabackup 1. xtrabackup备份的原理 1.1 全量备份 1.2 增量备份 1.3 恢复过程 1.4 xb在对于FTWRL上做的改进： 2. 下载及安装 2.1 参数选项： 3. 全量备份与恢复示例 3.1 全备过程 3.2 恢复过程 4. 增量备份与恢复示例 4.1 增量备份 4.2 再恢复之前可以先看下相关的备份信息 4.3 恢复的过程及注意事项 4.4 恢复示例 5. xtrabackup备份的压缩 一、Xtrabackup xtrabackup 只能备份innodb存储引擎表 innobackupex 可以备份内其他存储引擎（含innodb） innobackupex 在 xtrabackup 的基础上做了包装，以兼容其他存储引擎 平时在 备份/恢复 操作过程中， 使用innobackupex 备份时，默认读取MySQL配置文件（读取datadir） 1. xtrabackup备份的原理 xtrabackup备份的是 备份结束点 的数据（ 而 mysqldump 是备份开始时的数据 ） 1.1 全量备份 网上找了一个备份的过程图: innobackupex 在启动后，会先 fork 一个进程，启动 xtrabackup进程，然后就等待 xtrabackup 备份完 ibd 数据文件； xtrabackup 在备份 InnoDB 相关数据时，是有2种线程的，1种是 redo 拷贝线程，负责拷贝 redo 文件，1种是 ibd 拷贝线程，负责拷贝 ibd 文件；redo 拷贝线程只有一个，在 ibd 拷贝线程之前启动，在 ibd 线程结束后结束。xtrabackup 进程开始执行后，先启动 redo 拷贝线程，从最新的 checkpoint 点开始顺序拷贝 redo 日志；然后再启动 ibd 数据拷贝线程，在 xtrabackup 拷贝 ibd 过程中，innobackupex 进程一直处于等待状态（等待文件被创建）。 xtrabackup 拷贝完成idb后，通知 innobackupex（通过创建文件），同时自己进入等待（redo 线程仍然继续拷贝）; innobackupex 收到 xtrabackup 通知后，执行FLUSH TABLES WITH READ LOCK (FTWRL)，取得一致性位点，然后开始备份非 InnoDB 文件（包括 frm、MYD、MYI、CSV、opt、par等）。拷贝非 InnoDB 文件过程中，因为数据库处于全局只读状态，如果在业务的主库备份的话，要特别小心，非 InnoDB 表（主要是MyISAM）比较多的话整库只读时间就会比较长，这个影响一定要评估到。 当 innobackupex 拷贝完所有非 InnoDB 表文件后，通知 xtrabackup（通过删文件） ，同时自己进入等待（等待另一个文件被创建）； xtrabackup 收到 innobackupex 备份完非 InnoDB 通知后，就停止 redo 拷贝线程，然后通知 innobackupex redo log 拷贝完成（通过创建文件）； innobackupex 收到 redo 备份完成通知后，就开始解锁，执行 UNLOCK TABLES； 最后 innobackupex 和 xtrabackup 进程各自完成收尾工作，如资源的释放、写备份元数据信息等，innobackupex 等待 xtrabackup 子进程结束后退出。 在上面描述的文件拷贝，都是备份进程直接通过操作系统读取数据文件的，只在执行 SQL 命令时和数据库有交互，基本不影响数据库的运行，在备份非 InnoDB 时会有一段时间只读（如果没有MyISAM表的话，只读时间在几秒左右），在备份 InnoDB 数据文件时，对数据库完全没有影响，是真正的热备。 InnoDB 和非 InnoDB 文件的备份都是通过拷贝文件来做的，但是实现的方式不同，前者是以page为粒度做的(xtrabackup)，后者是 cp 或者 tar 命令(innobackupex)，xtrabackup 在读取每个page时会校验 checksum 值，保证数据块是一致的，而 innobackupex 在 cp MyISAM 文件时已经做了flush（FTWRL），磁盘上的文件也是完整的，所以最终备份集里的数据文件都是写入完整的。 1.2 增量备份 XB 是支持增量备份的，但是只能对 InnoDB 做增量，InnoDB 每个 page 有个 LSN 号，LSN 是全局递增的，page 被更改时会记录当前的 LSN 号，page中的 LSN 越大，说明当前page越新（最近被更新）。每次备份会记录当前备份到的LSN（xtrabackup_checkpoints 文件中），增量备份就是只拷贝LSN大于上次备份的page，比上次备份小的跳过，每个ibd文件最终备份出来的是增量 delta 文件。 MyISAM 是没有增量的机制的，每次增量备份都是全部拷贝的。 增量备份过程和全量备份一样，只是在 ibd 文件拷贝上有不同。 1.3 恢复过程 如果看恢复备份集的日志，会发现和 mysqld 启动时非常相似，其实备份集的恢复就是类似 mysqld crash后，做一次 crash recover。 恢复的目的是把备份集中的数据恢复到一个一致性位点，所谓一致就是指原数据库某一时间点各引擎数据的状态，比如 MyISAM 中的数据对应的是 15:00 时间点的，InnoDB 中的数据对应的是 15:20 的，这种状态的数据就是不一致的。XB 备份集对应的一致点，就是备份时FTWRL的时间点，恢复出来的数据，就对应原数据库FTWRL时的状态。 因为备份时 FTWRL 后，数据库是处于只读的，非 InnoDB 数据是在持有全局读锁情况下拷贝的，所以非 InnoDB 数据本身就对应 FTWRL 时间点；InnoDB 的 ibd 文件拷贝是在 FTWRL 前做的，拷贝出来的不同 ibd 文件最后更新时间点是不一样的，这种状态的 ibd 文件是不能直接用的，但是 redo log 是从备份开始一直持续拷贝的，最后的 redo 日志点是在持有 FTWRL 后取得的，所以最终通过 redo 应用后的 ibd 数据时间点也是和 FTWRL 一致的。 所以恢复过程只涉及 InnoDB 文件的恢复，非 InnoDB 数据是不动的。备份恢复完成后，就可以把数据文件拷贝到对应的目录，然后通过mysqld来启动了。 1.4 xb在对于FTWRL上做的改进： 为了解决这个FTWRL的问题，Percona公司对Mysql的Server层做了改进，引入了BACKUP LOCK，具体而言，通过\"LOCK TABLES FOR BACKUP\"命令来备份非innodb表数据；通过\"LOCK BINLOG FOR BACKUP\"来获取一致性位点，尽量减少因为数据库备份带来的服务受损。这两个锁与FTWRL的区别： LOCK TABLES FOR BACKUP 作用：备份数据 1.禁止非innodb表更新 2.禁止所有表的ddl 优化点： 1.不会被大查询堵塞(关闭表) 2.不会堵塞innodb表的读取和更新，这点非常重要，对于业务表全部是innodb的情况，则备份过程中DML完全不受损 3.UNLOCK TABLES LOCK BINLOG FOR BACKUP 作用：获取一致性位点。 1.禁止对位点更新的操作 优化点： 1.允许DDl和更新，直到写binlog为止。 2.UNLOCK BINLOG 2. 下载及安装 下载页面 https://www.percona.com/downloads/XtraBackup/LATEST/ 具体下载版本: https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.9/binary/tarball/percona-xtrabackup-2.4.9-Linux-x86_64.tar.gz 选择的是2.4.9的版本，10以上的版本带有libgcrypt的版本，搞不懂。 选择编译好的版本，解压，做个链接，即可使用 [root@nazeebo percona-xtrabackup-2.4.9-Linux-x86_64]# tree bin bin ├── innobackupex -> xtrabackup ├── xbcloud ├── xbcloud_osenv ├── xbcrypt ├── xbstream └── xtrabackup 0 directories, 6 files [root@nazeebo softdb]# mv percona-xtrabackup-2.4.9-Linux-x86_64 /usr/local/xtrabackup [root@nazeebo softdb]# ln -sf /usr/local/xtrabackup/bin/* /usr/bin/ 2.1 参数选项： 1) innobackupex 参数选项 --defaults-file=[MY.CNF] //指定配置文件：只能从给定的文件中读取默认选项。 且必须作为命令行上的第一个选项；必须是一个真实的文件，它不能是一个符号链接。 --databases=# //指定备份的数据库和表，格式为：--database=\"db1[.tb1] db2[.tb2]\" 多个库之间以空格隔开，如果此选项不被指定，将会备份所有的数据库。 --include=REGEXP //用正则表达式的方式指定要备份的数据库和表，格式为 --include=‘^mydb[.]mytb’ ，对每个库中的每个表逐一匹配，因此会创建所有的库，不过是空的目录。--include 传递给 xtrabackup --tables。 --tables-file=FILE //此选项的参数需要是一个文件名，此文件中每行包含一个要备份的表的完整名称，格式为databasename.tablename。该选项传递给 xtrabackup --tables-file，与--tables选项不同，只有要备份的表的库才会被创建。 注意：部分备份（--include、--tables-file、--database）需要开启 innodb_file_per_table 。 --compact //创建紧凑型备份，忽略所有辅助索引页，只备份data page；通过--apply-log中重建索引--rebuild-indexs。 --compress //此选项指示xtrabackup压缩备份的InnoDB数据文件，会生成 *.qp 文件。 --decompress //解压缩qp文件，为了解压缩，必须安装 qpress 工具。 Percona XtraBackup不会自动删除压缩文件，为了清理备份目录，用户应手动删除 * .qp文件：find /data/backup -name \"*.qp\" | xargs rm。 --no-timestamp //指定了这个选项备份将会直接存储在 BACKUP-DIR 目录，不再创建时间戳文件夹。 --apply-log //应用 BACKUP-DIR 中的 xtrabackup_logfile 事务日志文件。一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处于不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件使得数据文件处于一致性状态。 --use-memory=# //此选项接受一个字符参数（1M/1MB,1G/1GB，默认100M），仅与--apply-log一起使用，该选项指定prepare时用于崩溃恢复（crash-recovery）的内存。 --copy-back //拷贝先前备份所有文件到它们的原始路径。但原路径下不能有任何文件或目录，除非指定 --force-non-empty-directories 选项。 --force-non-empty-directories //恢复时指定此选项，可使 --copy-back 和 --move-back 复制文件到非空目录，即原data目录下可以有其他文件，但是不能有与恢复文件中同名的文件，否则恢复失败。 --rsync //此选项可优化本地文件（非InnoDB）的传输。rsync工具一次性拷贝所有非InnoDB文件，而不是为每个文件单独创建cp，在备份恢复很多数据库和表时非常高效。此选项不能和 --stream 一起使用。 --incremental //这个选项告诉 xtrabackup 创建一个增量备份，而不是完全备份。它传递到 xtrabackup 子进程。当指定这个选项，可以设置 --incremental-lsn 或 --incremental-basedir。如果这2个选项都没有被指定，--incremental-basedir 传递给 xtrabackup 默认值，默认值为：基础备份目录的第一个时间戳备份目录。 --incremental-basedir=DIRECTORY //该选项接受一个字符串参数，该参数指定作为增量备份的基本数据集的完整备份目录。它与 --incremental 一起使用。 --incremental-dir=DIRECTORY //该选项接受一个字符串参数，该参数指定了增量备份将与完整备份相结合的目录，以便进行新的完整备份。它与 --incremental 选项一起使用。 --redo-only //在“准备基本完整备份” 和 “合并所有的增量备份(除了最后一个增备)”时使用此选项。它直接传递给xtrabackup的 xtrabackup --apply-log-only 选项，使xtrabackup跳过\"undo\"阶段，只做\"redo\"操作。如果后面还有增量备份应用到这个全备,这是必要的。有关详细信息,请参阅xtrabackup文档。 --parallel=NUMBER-OF-THREADS //此选项接受一个整数参数，指定xtrabackup子进程应用于同时备份文件的线程数。请注意，此选项仅适用于文件级别，也就是说，如果您有多个.ibd文件，则它们将被并行复制； 如果您的表一起存储在一个表空间文件中，它将不起作用。 2) xtrabackup 参数选项 --apply-log-only //这个选项使在准备备份(prepare)时，只执行重做(redo)阶段，这对于增量备份非常重要。 3. 全量备份与恢复示例 3.1 全备过程 3.1.1 创建备份的目录 mkdir -p /bakdir 3.1.2 创建备份用户 mysql> CREATE USER 'bkadmin'@'%' IDENTIFIED BY '123456'; mysql> GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT,process ON *.* TO 'bkadmin'@'%'; mysql> FLUSH PRIVILEGES; 注意，上面必须要有一个权限是 process [root@nazeebo softdb]# innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host 127.0.0.1 /bakdir 180718 13:32:07 innobackupex: Starting the backup operation IMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\". Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693. BEGIN failed--compilation aborted at - line 693. 180718 13:32:07 Connecting to MySQL server host: 127.0.0.1, user: bkadmin, password: set, port: not set, socket: not set Using server version 5.7.22-log Error: failed to execute query SHOW ENGINE INNODB STATUS: Access denied; you need (at least one of) the PROCESS privilege(s) for this operation [root@nazeebo softdb]# mysql -ubkadmin -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 59 Server version: 5.7.22-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> SHOW ENGINE INNODB STATUS; ERROR 1227 (42000): Access denied; you need (at least one of) the PROCESS privilege(s) for this operation 3.1.3 执行全备 [root@nazeebo ~]# innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host 127.0.0.1 /bakdir 180718 13:56:20 innobackupex: Starting the backup operation IMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\". Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693. BEGIN failed--compilation aborted at - line 693. 180718 13:56:20 Connecting to MySQL server host: 127.0.0.1, user: bkadmin, password: set, port: not set, socket: not set Using server version 5.7.22-log innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) xtrabackup: uses posix_fadvise(). xtrabackup: cd to /u01/mysql/mysql_data/ xtrabackup: open files limit requested 0, set to 65535 xtrabackup: using the following InnoDB configuration: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ xtrabackup: innodb_log_files_in_group = 2 xtrabackup: innodb_log_file_size = 1073741824 xtrabackup: using O_DIRECT InnoDB: Number of pools: 1 180718 13:56:20 >> log scanned up to (291395853) InnoDB: Opened 3 undo tablespaces InnoDB: 0 undo tablespaces made active xtrabackup: Generating a list of tablespaces InnoDB: Allocated tablespace ID 33 for employees/titles, old maximum was 3 180718 13:56:20 [01] Copying ./ibdata1 to /bakdir/2018-07-18_13-56-20/ibdata1 180718 13:56:21 [01] ...done 180718 13:56:21 [01] Copying /u01/mysql/mysql_undolog//undo001 to /bakdir/2018-07-18_13-56-20/undo001 180718 13:56:21 [01] ...done 180718 13:56:21 >> log scanned up to (291395853) 180718 13:56:21 [01] Copying /u01/mysql/mysql_undolog//undo002 to /bakdir/2018-07-18_13-56-20/undo002 180718 13:56:21 [01] ...done 180718 13:56:21 [01] Copying /u01/mysql/mysql_undolog//undo003 to /bakdir/2018-07-18_13-56-20/undo003 180718 13:56:21 [01] ...done 180718 13:56:21 [01] Copying ./employees/titles.ibd to /bakdir/2018-07-18_13-56-20/employees/titles.ibd 180718 13:56:22 >> log scanned up to (291395853) 180718 13:56:22 [01] ...done 180718 13:56:22 [01] Copying ./employees/salaries.ibd to /bakdir/2018-07-18_13-56-20/employees/salaries.ibd 180718 13:56:23 >> log scanned up to (291395853) 180718 13:56:24 >> log scanned up to (291395853) 180718 13:56:25 >> log scanned up to (291395853) 180718 13:56:25 [01] ...done 180718 13:56:25 [01] Copying ./employees/dept_emp.ibd to /bakdir/2018-07-18_13-56-20/employees/dept_emp.ibd ... ... 省略部分输出 ... ... 180718 13:56:28 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /bakdir/2018-07-18_13-56-20/performance_schema/events_waits_summary_global_by_event_name.frm 180718 13:56:28 [01] ...done 180718 13:56:28 Finished backing up non-InnoDB tables and files 180718 13:56:28 [00] Writing /bakdir/2018-07-18_13-56-20/xtrabackup_binlog_info 180718 13:56:28 [00] ...done 180718 13:56:28 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS... xtrabackup: The latest check point (for incremental): '291395844' xtrabackup: Stopping log copying thread. .180718 13:56:28 >> log scanned up to (291395853) 180718 13:56:28 Executing UNLOCK TABLES 180718 13:56:28 All tables unlocked 180718 13:56:28 [00] Copying ib_buffer_pool to /bakdir/2018-07-18_13-56-20/ib_buffer_pool 180718 13:56:28 [00] ...done 180718 13:56:28 Backup created in directory '/bakdir/2018-07-18_13-56-20/' MySQL binlog position: filename 'bin.000006', position '23108', GTID of the last change '873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-444' 180718 13:56:28 [00] Writing /bakdir/2018-07-18_13-56-20/backup-my.cnf 180718 13:56:28 [00] ...done 180718 13:56:28 [00] Writing /bakdir/2018-07-18_13-56-20/xtrabackup_info 180718 13:56:28 [00] ...done xtrabackup: Transaction log of lsn (291395844) to (291395853) was copied. 180718 13:56:29 completed OK! 3.1.4 查看备份出来的目录 [root@nazeebo 2018-07-18_13-56-20]# ll total 33940 -rw-r----- 1 root root 449 Jul 18 13:56 backup-my.cnf --备份的my.cnf drwxr-x--- 2 root root 4096 Jul 18 13:56 employees -rw-r----- 1 root root 99624 Jul 18 13:56 ib_buffer_pool -rw-r----- 1 root root 12582912 Jul 18 13:56 ibdata1 drwxr-x--- 2 root root 4096 Jul 18 13:56 mysql drwxr-x--- 2 root root 4096 Jul 18 13:56 performance_schema drwxr-x--- 2 root root 12288 Jul 18 13:56 sys drwxr-x--- 2 root root 4096 Jul 18 13:56 test -rw-r----- 1 root root 7340032 Jul 18 13:56 undo001 -rw-r----- 1 root root 7340032 Jul 18 13:56 undo002 -rw-r----- 1 root root 7340032 Jul 18 13:56 undo003 -rw-r----- 1 root root 60 Jul 18 13:56 xtrabackup_binlog_info -rw-r----- 1 root root 117 Jul 18 13:56 xtrabackup_checkpoints -rw-r----- 1 root root 579 Jul 18 13:56 xtrabackup_info -rw-r----- 1 root root 2560 Jul 18 13:56 xtrabackup_logfile xtrabackup除了备份指定的库，还要备份共享表空间，undo表空间等等。 并且生成对应的4个文件 xtrabackup_binlog_info – 包含了binlog的文件名和position xtrabackup_checkpoints – 包含了备份过程中的checkpoint、LSN信息 xtrabackup_info – 包含了备份过程中的整体信息 xtrabackup_logfile – 持续备份的日志文件（redo） [root@nazeebo 2018-07-18_13-56-20]# cat xtrabackup_binlog_info bin.000006 23108 873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-444 [root@nazeebo 2018-07-18_13-56-20]# cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 291395844 last_lsn = 291395853 compact = 0 recover_binlog_info = 0 [root@nazeebo 2018-07-18_13-56-20]# cat xtrabackup_info uuid = 504fb2eb-8a4f-11e8-ae89-00163e0463a7 name = tool_name = innobackupex tool_command = --defaults-file=/etc/my.cnf --user=bkadmin --password=... --host 127.0.0.1 /bakdir tool_version = 2.4.9 ibbackup_version = 2.4.9 server_version = 5.7.22-log start_time = 2018-07-18 13:56:20 end_time = 2018-07-18 13:56:28 lock_time = 0 binlog_pos = filename 'bin.000006', position '23108', GTID of the last change '873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-444' innodb_from_lsn = 0 innodb_to_lsn = 291395844 partial = N incremental = N format = file compact = N compressed = N encrypted = N 3.2 恢复过程 3.2.1 删除一个库作测试 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | +--------------------+ 6 rows in set (0.00 sec) mysql> drop database employees; Query OK, 8 rows affected (0.67 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) 3.2.2 恢复 恢复步骤分为三步： apply-log copy-back 修改权限 启动实例 3.2.2.1 apply-log [root@nazeebo bakdir]# innobackupex --defaults-file=/etc/my.cnf --apply-log /bakdir/2018-07-18_13-56-20/ 180718 23:34:03 innobackupex: Starting the apply-log operation IMPORTANT: Please check that the apply-log run completes successfully. At the end of a successful apply-log run innobackupex prints \"completed OK!\". innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) xtrabackup: cd to /bakdir/2018-07-18_13-56-20/ xtrabackup: This target seems to be not prepared yet. InnoDB: Number of pools: 1 xtrabackup: xtrabackup_logfile detected: size=8388608, start_lsn=(291395844) xtrabackup: using the following InnoDB configuration for recovery: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = . xtrabackup: innodb_log_files_in_group = 1 xtrabackup: innodb_log_file_size = 8388608 xtrabackup: using the following InnoDB configuration for recovery: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = . xtrabackup: innodb_log_files_in_group = 1 xtrabackup: innodb_log_file_size = 8388608 xtrabackup: Starting InnoDB instance for recovery. xtrabackup: Using 104857600 bytes for buffer pool (set by --use-memory parameter) InnoDB: PUNCH HOLE support available InnoDB: Mutexes and rw_locks use GCC atomic builtins InnoDB: Uses event mutexes InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier InnoDB: Compressed tables use zlib 1.2.7 InnoDB: Number of pools: 1 InnoDB: Using CPU crc32 instructions InnoDB: Initializing buffer pool, total size = 100M, instances = 1, chunk size = 100M InnoDB: Completed initialization of buffer pool InnoDB: page_cleaner coordinator priority: -20 InnoDB: Opened 3 undo tablespaces InnoDB: 3 undo tablespaces made active InnoDB: Highest supported file format is Barracuda. InnoDB: Log scan progressed past the checkpoint lsn 291395844 InnoDB: Doing recovery: scanned up to log sequence number 291395853 (0%) InnoDB: Doing recovery: scanned up to log sequence number 291395853 (0%) InnoDB: Database was not shutdown normally! InnoDB: Starting crash recovery. InnoDB: xtrabackup: Last MySQL binlog file position 21135, file name bin.000006 InnoDB: Creating shared tablespace for temporary tables InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... InnoDB: File './ibtmp1' size is now 12 MB. InnoDB: 96 redo rollback segment(s) found. 1 redo rollback segment(s) are active. InnoDB: 32 non-redo rollback segment(s) are active. InnoDB: 5.7.13 started; log sequence number 291395853 InnoDB: xtrabackup: Last MySQL binlog file position 21135, file name bin.000006 xtrabackup: starting shutdown with innodb_fast_shutdown = 1 InnoDB: FTS optimize thread exiting. InnoDB: Starting shutdown... InnoDB: Shutdown completed; log sequence number 291395872 InnoDB: Number of pools: 1 xtrabackup: using the following InnoDB configuration for recovery: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = . xtrabackup: innodb_log_files_in_group = 2 xtrabackup: innodb_log_file_size = 1073741824 InnoDB: PUNCH HOLE support available InnoDB: Mutexes and rw_locks use GCC atomic builtins InnoDB: Uses event mutexes InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier InnoDB: Compressed tables use zlib 1.2.7 InnoDB: Number of pools: 1 InnoDB: Using CPU crc32 instructions InnoDB: Initializing buffer pool, total size = 100M, instances = 1, chunk size = 100M InnoDB: Completed initialization of buffer pool InnoDB: page_cleaner coordinator priority: -20 InnoDB: Setting log file ./ib_logfile101 size to 1024 MB InnoDB: Progress in MB: 100 200 300 400 500 600 700 800 900 1000 InnoDB: Setting log file ./ib_logfile1 size to 1024 MB InnoDB: Progress in MB: 100 200 300 400 500 600 700 800 900 1000 InnoDB: Renaming log file ./ib_logfile101 to ./ib_logfile0 InnoDB: New log files created, LSN=291395872 InnoDB: Opened 3 undo tablespaces InnoDB: 3 undo tablespaces made active InnoDB: Highest supported file format is Barracuda. InnoDB: Log scan progressed past the checkpoint lsn 291396108 InnoDB: Doing recovery: scanned up to log sequence number 291396117 (0%) InnoDB: Doing recovery: scanned up to log sequence number 291396117 (0%) InnoDB: Database was not shutdown normally! InnoDB: Starting crash recovery. InnoDB: xtrabackup: Last MySQL binlog file position 21135, file name bin.000006 InnoDB: Removed temporary tablespace data file: \"ibtmp1\" InnoDB: Creating shared tablespace for temporary tables InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... InnoDB: File './ibtmp1' size is now 12 MB. InnoDB: 96 redo rollback segment(s) found. 1 redo rollback segment(s) are active. InnoDB: 32 non-redo rollback segment(s) are active. InnoDB: page_cleaner: 1000ms intended loop took 38564ms. The settings might not be optimal. (flushed=0 and evicted=0, during the time.) InnoDB: 5.7.13 started; log sequence number 291396117 xtrabackup: starting shutdown with innodb_fast_shutdown = 1 InnoDB: FTS optimize thread exiting. InnoDB: Starting shutdown... InnoDB: Shutdown completed; log sequence number 291396136 180718 23:34:45 completed OK! 3.2.2.2 copy-back [root@nazeebo bakdir]# innobackupex --defaults-file=/etc/my.cnf --copy-back 2018-07-18_13-56-20 180718 23:37:57 innobackupex: Starting the copy-back operation IMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \"completed OK!\". innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) 180718 23:37:57 [01] Copying undo001 to /u01/mysql/mysql_undolog/undo001 180718 23:37:57 [01] ...done 180718 23:37:57 [01] Copying undo002 to /u01/mysql/mysql_undolog/undo002 180718 23:37:57 [01] ...done 180718 23:37:57 [01] Copying undo003 to /u01/mysql/mysql_undolog/undo003 180718 23:37:57 [01] ...done 180718 23:37:57 [01] Copying ib_logfile0 to /u01/mysql/mysql_redolog/ib_logfile0 180718 23:38:15 [01] ...done ... 省略一些copy的输出 ... 180718 23:38:41 [01] Copying ./xtrabackup_info to /u01/mysql/mysql_data/xtrabackup_info 180718 23:38:41 [01] ...done 180718 23:38:41 [01] Copying ./ib_buffer_pool to /u01/mysql/mysql_data/ib_buffer_pool 180718 23:38:41 [01] ...done 180718 23:38:41 completed OK! 需要注意的是：在copy-back的时候要保证在my.cnf里面对应的数据文件、undo、redo的目录为空，否则会报错，如下： --datafile的报错 [root@nazeebo bakdir]# innobackupex --defaults-file=/etc/my.cnf --copy-back 2018-07-18_13-56-20/ 180718 23:36:03 innobackupex: Starting the copy-back operation IMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \"completed OK!\". innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) Original data directory /u01/mysql/mysql_data/ is not empty! --undo的报错 innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) innobackupex: Can't create/write to file '/u01/mysql/mysql_undolog/undo001' (Errcode: 17 - File exists) [01] error: cannot open the destination stream for undo001 [01] Error: copy_file() failed. --redo的报错 innobackupex: Can't create/write to file '/u01/mysql/mysql_redolog/ib_logfile0' (Errcode: 17 - File exists) [01] error: cannot open the destination stream for ib_logfile0 [01] Error: copy_file() failed. 3.2.2.3 修改目录的权限 chown -R mysql.mysql /u01/mysql/mysql_* 3.2.2.4 启动mysql服务 service mysql start service mysql status 3.2.2.5 验证 注意： --apply-log 与 --copy-back 步骤可以调换，可以先拷贝到 datadir 后，再做 redo 日志重放（apply-log） 4. 增量备份与恢复示例 增量备份可以是链式的，每次增量备份都要基于上一次的备份的LSN信息 也可以每一次增量备份都是基于上一次全量备份 --先做一个全备，得到一个全备的目录，比如第一次全备后的目录叫做/bakdir/full/年月日 innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host 127.0.0.1 /bakdir/full --再做增量备份 innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host 127.0.0.1 --incremental /bakdir/inc --incremental-basedir=/bakdir/full/年月日 --incremental – 指定进行增量备份 --incremental-basedir – 指定之前 完整备份/上一次增量备份的文件夹 4.1 增量备份 4.1.1 先做一个全备 [root@nazeebo bakdir]# innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host 127.0.0.1 /bakdir/full 180719 00:24:18 innobackupex: Starting the backup operation IMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\". Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693. BEGIN failed--compilation aborted at - line 693. 180719 00:24:18 Connecting to MySQL server host: 127.0.0.1, user: bkadmin, password: set, port: not set, socket: not set Using server version 5.7.22-log innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) xtrabackup: uses posix_fadvise(). xtrabackup: cd to /u01/mysql/mysql_data/ xtrabackup: open files limit requested 0, set to 65535 xtrabackup: using the following InnoDB configuration: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ xtrabackup: innodb_log_files_in_group = 2 xtrabackup: innodb_log_file_size = 1073741824 xtrabackup: using O_DIRECT InnoDB: Number of pools: 1 180719 00:24:18 >> log scanned up to (291396136) InnoDB: Opened 3 undo tablespaces InnoDB: 0 undo tablespaces made active xtrabackup: Generating a list of tablespaces InnoDB: Allocated tablespace ID 33 for employees/titles, old maximum was 3 180719 00:24:18 [01] Copying ./ibdata1 to /bakdir/full/2018-07-19_00-24-18/ibdata1 180719 00:24:18 [01] ...done 180719 00:24:19 [01] Copying /u01/mysql/mysql_undolog//undo001 to /bakdir/full/2018-07-19_00-24-18/undo001 180719 00:24:19 [01] ...done 180719 00:24:19 [01] Copying /u01/mysql/mysql_undolog//undo002 to /bakdir/full/2018-07-19_00-24-18/undo002 180719 00:24:19 [01] ...done 180719 00:24:19 >> log scanned up to (291396136) 180719 00:24:19 [01] Copying /u01/mysql/mysql_undolog//undo003 to /bakdir/full/2018-07-19_00-24-18/undo003 180719 00:24:19 [01] ...done ... 省略一些copy的过程 ... 180719 00:24:25 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /bakdir/full/2018-07-19_00-24-18/performance_schema/events_waits_summary_global_by_event_name.frm 180719 00:24:25 >> log scanned up to (291396136) 180719 00:24:25 [01] ...done 180719 00:24:25 Finished backing up non-InnoDB tables and files 180719 00:24:25 [00] Writing /bakdir/full/2018-07-19_00-24-18/xtrabackup_binlog_info 180719 00:24:25 [00] ...done 180719 00:24:25 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS... xtrabackup: The latest check point (for incremental): '291396136' xtrabackup: Stopping log copying thread. .180719 00:24:25 >> log scanned up to (291396136) 180719 00:24:25 Executing UNLOCK TABLES 180719 00:24:25 All tables unlocked 180719 00:24:25 [00] Copying ib_buffer_pool to /bakdir/full/2018-07-19_00-24-18/ib_buffer_pool 180719 00:24:25 [00] ...done 180719 00:24:25 Backup created in directory '/bakdir/full/2018-07-19_00-24-18/' MySQL binlog position: filename 'bin.000006', position '23442', GTID of the last change '873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-446' 180719 00:24:25 [00] Writing /bakdir/full/2018-07-19_00-24-18/backup-my.cnf 180719 00:24:25 [00] ...done 180719 00:24:25 [00] Writing /bakdir/full/2018-07-19_00-24-18/xtrabackup_info 180719 00:24:25 [00] ...done xtrabackup: Transaction log of lsn (291396136) to (291396136) was copied. 180719 00:24:25 completed OK! [root@nazeebo bakdir]# cd full/ [root@nazeebo full]# ls 2018-07-19_00-24-18 4.1.2 新增加一个库一个表，然后做一个增量备份 mysql> create database test_lowa; Query OK, 1 row affected (0.01 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | | test_lowa | +--------------------+ 7 rows in set (0.00 sec) mysql> use test_lowa; Database changed mysql> create table t1 (id bigint); Query OK, 0 rows affected (0.02 sec) mysql> show tables; +---------------------+ | Tables_in_test_lowa | +---------------------+ | t1 | +---------------------+ 1 row in set (0.00 sec) 做第一次增量备份 [root@nazeebo full]# innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host=127.0.0.1 --incremental /bakdir/inc --incremental-basedir=/bakdir/full/2018-07-19_00-24-18/ 180719 00:28:42 innobackupex: Starting the backup operation IMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\". Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693. BEGIN failed--compilation aborted at - line 693. 180719 00:28:42 Connecting to MySQL server host: 127.0.0.1, user: bkadmin, password: set, port: not set, socket: not set Using server version 5.7.22-log innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) incremental backup from 291396136 is enabled. xtrabackup: uses posix_fadvise(). xtrabackup: cd to /u01/mysql/mysql_data/ xtrabackup: open files limit requested 0, set to 65535 xtrabackup: using the following InnoDB configuration: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ xtrabackup: innodb_log_files_in_group = 2 xtrabackup: innodb_log_file_size = 1073741824 xtrabackup: using O_DIRECT InnoDB: Number of pools: 1 180719 00:28:42 >> log scanned up to (291396136) InnoDB: Opened 3 undo tablespaces InnoDB: 0 undo tablespaces made active xtrabackup: Generating a list of tablespaces InnoDB: Allocated tablespace ID 33 for employees/titles, old maximum was 3 180719 00:28:42 [01] Copying ./ibdata1 to /bakdir/inc/2018-07-19_00-28-42/ibdata1.delta 180719 00:28:42 [01] ...done 180719 00:28:42 [01] Copying /u01/mysql/mysql_undolog//undo001 to /bakdir/inc/2018-07-19_00-28-42/undo001.delta 180719 00:28:42 [01] ...done 180719 00:28:42 [01] Copying /u01/mysql/mysql_undolog//undo002 to /bakdir/inc/2018-07-19_00-28-42/undo002.delta 180719 00:28:42 [01] ...done 180719 00:28:42 [01] Copying /u01/mysql/mysql_undolog//undo003 to /bakdir/inc/2018-07-19_00-28-42/undo003.delta 180719 00:28:42 [01] ...done 180719 00:28:42 [01] Copying ./employees/titles.ibd to /bakdir/inc/2018-07-19_00-28-42/employees/titles.ibd.delta 180719 00:28:42 [01] ...done ... 省略一些copy的步骤 ... 180719 00:28:44 [01] ...done 180719 00:28:44 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /bakdir/inc/2018-07-19_00-28-42/performance_schema/events_waits_summary_global_by_event_name.frm 180719 00:28:44 [01] ...done 180719 00:28:44 Finished backing up non-InnoDB tables and files 180719 00:28:44 [00] Writing /bakdir/inc/2018-07-19_00-28-42/xtrabackup_binlog_info 180719 00:28:44 [00] ...done 180719 00:28:44 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS... xtrabackup: The latest check point (for incremental): '291396136' xtrabackup: Stopping log copying thread. .180719 00:28:44 >> log scanned up to (291396136) 180719 00:28:44 Executing UNLOCK TABLES 180719 00:28:44 All tables unlocked 180719 00:28:44 [00] Copying ib_buffer_pool to /bakdir/inc/2018-07-19_00-28-42/ib_buffer_pool 180719 00:28:44 [00] ...done 180719 00:28:44 Backup created in directory '/bakdir/inc/2018-07-19_00-28-42/' MySQL binlog position: filename 'bin.000006', position '23792', GTID of the last change '873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-448' 180719 00:28:44 [00] Writing /bakdir/inc/2018-07-19_00-28-42/backup-my.cnf 180719 00:28:44 [00] ...done 180719 00:28:44 [00] Writing /bakdir/inc/2018-07-19_00-28-42/xtrabackup_info 180719 00:28:44 [00] ...done xtrabackup: Transaction log of lsn (291396136) to (291396136) was copied. 180719 00:28:44 completed OK! [root@nazeebo full]# cd ../inc/ [root@nazeebo inc]# ls 2018-07-19_00-28-42 4.1.3 再增加一张表，做第二次增量备份 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | | test_lowa | +--------------------+ 7 rows in set (0.00 sec) mysql> use test_lowa Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> create table t2(id bigint); Query OK, 0 rows affected (0.03 sec) mysql> show tables; +---------------------+ | Tables_in_test_lowa | +---------------------+ | t1 | | t2 | +---------------------+ 2 rows in set (0.00 sec) 做第二次增量备份 [root@nazeebo inc]# innobackupex --defaults-file=/etc/my.cnf --user=bkadmin --password=123456 --host=127.0.0.1 --incremental /bakdir/inc --incremental-basedir=/bakdir/inc/2018-07-19_00-28-42/ 180719 00:32:56 innobackupex: Starting the backup operation IMPORTANT: Please check that the backup run completes successfully. At the end of a successful backup run innobackupex prints \"completed OK!\". Can't locate Digest/MD5.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at - line 693. BEGIN failed--compilation aborted at - line 693. 180719 00:32:56 Connecting to MySQL server host: 127.0.0.1, user: bkadmin, password: set, port: not set, socket: not set Using server version 5.7.22-log innobackupex version 2.4.9 based on MySQL server 5.7.13 Linux (x86_64) (revision id: a467167cdd4) incremental backup from 291396136 is enabled. xtrabackup: uses posix_fadvise(). xtrabackup: cd to /u01/mysql/mysql_data/ xtrabackup: open files limit requested 0, set to 65535 xtrabackup: using the following InnoDB configuration: xtrabackup: innodb_data_home_dir = . xtrabackup: innodb_data_file_path = ibdata1:12M:autoextend xtrabackup: innodb_log_group_home_dir = /u01/mysql/mysql_redolog/ xtrabackup: innodb_log_files_in_group = 2 xtrabackup: innodb_log_file_size = 1073741824 xtrabackup: using O_DIRECT InnoDB: Number of pools: 1 180719 00:32:56 >> log scanned up to (291396136) InnoDB: Opened 3 undo tablespaces InnoDB: 0 undo tablespaces made active xtrabackup: Generating a list of tablespaces InnoDB: Allocated tablespace ID 33 for employees/titles, old maximum was 3 180719 00:32:56 [01] Copying ./ibdata1 to /bakdir/inc/2018-07-19_00-32-56/ibdata1.delta 180719 00:32:56 [01] ...done 180719 00:32:56 [01] Copying /u01/mysql/mysql_undolog//undo001 to /bakdir/inc/2018-07-19_00-32-56/undo001.delta 180719 00:32:56 [01] ...done 180719 00:32:56 [01] Copying /u01/mysql/mysql_undolog//undo002 to /bakdir/inc/2018-07-19_00-32-56/undo002.delta 180719 00:32:56 [01] ...done 180719 00:32:56 [01] Copying /u01/mysql/mysql_undolog//undo003 to /bakdir/inc/2018-07-19_00-32-56/undo003.delta 180719 00:32:56 [01] ...done 180719 00:32:56 [01] Copying ./employees/titles.ibd to /bakdir/inc/2018-07-19_00-32-56/employees/titles.ibd.delta 180719 00:32:56 [01] ...done ... 省略一些copy的过程 ... 180719 00:32:58 [01] Copying ./performance_schema/events_waits_summary_global_by_event_name.frm to /bakdir/inc/2018-07-19_00-32-56/performance_schema/events_waits_summary_global_by_event_name.frm 180719 00:32:58 [01] ...done 180719 00:32:58 Finished backing up non-InnoDB tables and files 180719 00:32:58 [00] Writing /bakdir/inc/2018-07-19_00-32-56/xtrabackup_binlog_info 180719 00:32:58 [00] ...done 180719 00:32:58 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS... xtrabackup: The latest check point (for incremental): '291396136' xtrabackup: Stopping log copying thread. .180719 00:32:58 >> log scanned up to (291396136) 180719 00:32:58 Executing UNLOCK TABLES 180719 00:32:58 All tables unlocked 180719 00:32:58 [00] Copying ib_buffer_pool to /bakdir/inc/2018-07-19_00-32-56/ib_buffer_pool 180719 00:32:58 [00] ...done 180719 00:32:58 Backup created in directory '/bakdir/inc/2018-07-19_00-32-56/' MySQL binlog position: filename 'bin.000006', position '23967', GTID of the last change '873d6f4e-6ed2-11e8-b02d-00163e0463a7:1-449' 180719 00:32:58 [00] Writing /bakdir/inc/2018-07-19_00-32-56/backup-my.cnf 180719 00:32:58 [00] ...done 180719 00:32:58 [00] Writing /bakdir/inc/2018-07-19_00-32-56/xtrabackup_info 180719 00:32:58 [00] ...done xtrabackup: Transaction log of lsn (291396136) to (291396136) was copied. 180719 00:32:58 completed OK! [root@nazeebo inc]# 4.2 再恢复之前可以先看下相关的备份信息 --全备 [root@nazeebo 2018-07-19_00-24-18]# more xtrabackup_checkpoints backup_type = full-backuped --备份类型为全备 from_lsn = 0 to_lsn = 291396136 last_lsn = 291396136 compact = 0 recover_binlog_info = 0 --第一次增量备份 [root@nazeebo 2018-07-19_00-28-42]# more xtrabackup_checkpoints backup_type = incremental --备份类型为增量备份 from_lsn = 291396136 --从全备的结束开始 to_lsn = 291491125 last_lsn = 291491125 compact = 0 recover_binlog_info = 0 --第二次增量备份 [root@nazeebo 2018-07-19_00-32-56]# more xtrabackup_checkpoints backup_type = incremental --备份类型为增量备份 from_lsn = 291491125 --从第一次增量备份的结束开始 to_lsn = 292396157 last_lsn = 292396157 compact = 0 recover_binlog_info = 0 4.3 恢复的过程及注意事项 增量恢复的过程： 如果有多个增量备份，增量恢复的步骤相对较多 innobackupex --apply-log --redo-only BASE-DIR BASE-DIR 指完整的全部备份目录 innobackupex --apply-log --redo-only BASE-DIR --incremental-dir=INCREMENTAL-DIR-1 INCREMENTAL-DIR-1 指第一次增量备份的目录 innobackupex --apply-log BASE-DIR --incremental-dir=INCREMENTAL-DIR-2 INCREMENTAL-DIR-2 第二档增量备份的目录 如果此时是 最后一个增量备份 ，就不要使用--redo-only选项 innobackupex --apply-log BASE-DIR （可选） 原文：Once you merge the base with all the increments, you can prepare it to roll back the uncommitted transactions 官方建议做一档，来回滚掉没有提交的事物 即使不做这个一步，数据库在启动的时候也会回滚掉未提交的事物（ 启动会变慢 ） innobackupex --copy-back BASE-DIR 再通过 全量的copy-back 进行还原 增量备份还原就是，把 增量目录 下的数据， 整合 到 全备份目录 下，然后在进行 全量数据的还原 在应用 最后一次 apply-log之前，都需要增加 --redo-only 参数 这里的 BASE-DIR 和 --incremental-dir 保持绝对路径 ，不然可能会提示 找不到xtrabackup_logfile ( 主要是 --incremental-dir 这个参数需要绝对路径，因为 innobackupex 会先 cd 到 BASE-DIR 目录中去 4.4 恢复示例 4.4.1 先搞个破坏，删掉装有新建2个表的数据库test_lowa mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | | test_lowa | +--------------------+ 7 rows in set (0.00 sec) mysql> drop database test_lowa; Query OK, 2 rows affected (0.06 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | +--------------------+ 6 rows in set (0.00 sec) 4.4.2 先完整应用全备 [root@nazeebo mysql_data]# innobackupex --defaults-file=/etc/my.cnf --apply-log --redo-only /bakdir/full/2018-07-19_00-24-18/ 4.4.3 应用第一次增量备份 使用绝对路径! [root@nazeebo mysql_data]# innobackupex --defaults-file=/etc/my.cnf --apply-log --redo-only /bakdir/full/2018-07-19_00-24-18 --incremental-dir=/bakdir/inc/2018-07-19_00-28-42/ 4.4.4 应用第二次增量备份 使用绝对路径! 不要使用 --redo-only 选项 [root@nazeebo mysql_data]# innobackupex --defaults-file=/etc/my.cnf --apply-log /bakdir/full/2018-07-19_00-24-18 --incremental-dir=/bakdir/inc/2018-07-19_00-32-56/ 4.4.5 建议再做一次apply-log来回滚事务 innobackupex --defaults-file=/etc/my.cnf --apply-log /bakdir/full/2018-07-19_00-24-18 至此，之前 全量备份 的目录中的数据 是 两次增量备份整合的数据 4.4.6 清空相关数据目录里面的文件 [root@nazeebo mysql]# tree . ├── log │ ├── mysql_error.log │ └── mysql_slow_query.log ├── mysql_data ├── mysql_redolog └── mysql_undolog 4 directories, 2 files 4.4.7 还原数据库copy-file innobackupex --defaults-file=/etc/my.cnf --copy-back /bakdir/full/2018-07-19_00-24-18/ 4.4.8 修改权限，重启服务，验证 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | | test_lowa | +--------------------+ 7 rows in set (0.00 sec) mysql> use test_lowa Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> show tables; +---------------------+ | Tables_in_test_lowa | +---------------------+ | t1 | | t2 | +---------------------+ 2 rows in set (0.00 sec) 5. xtrabackup备份的压缩 innobackupex 可以通过 stream 的方式（流的方式），然后通过 管道 进行压缩，或者直接使用 --compress 进行自动压缩 innobackupex --compress --compress-threads=8 --stream=xbstream --parallel=4 ./ > backup.xbstream --parallel 表示有多少个线程拷贝表空间文件 --compress-threads 表示有多少个线程进行压缩 压缩的东西还有点多，后面有时间再慢慢补上。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 07:15:09 "},"16.basetest.html":{"url":"16.basetest.html","title":"16.基准测试","keywords":"","body":" 一、一些基本的概念 1.基准测试： 2.基准测试的作用 3.常见数据库的基准测试指标包括： 4.基准测试的分类 5.MySQL的相关tps/qps计算方法 5.1 MySQL的QPS计算 5.2 MySQL的TPS计算 6.磁盘的IOPS计算 6.1 传统机械硬盘的IOPS值计算 6.2 iostat 命令 6.3 iotop 7.提升IOPS性能的手段 二、sysbench 1.基本介绍 2.sysbench测试框架 3.sysbench的安装 3.1 下载sysbench 3.2 进入目录，生成相关的配置文件 3.3 关联mysql的头文件和库 3.4 常规性的make && make install 3.5 配置环境变量，查看版本 4.sysbench的使用 4.1 sysbench选项说明 4.2 cpu性能测试 4.3 线程测试 4.4 磁盘IO性能测试 4.5 内存测试 4.6 OLTP测试 一、一些基本的概念 1.基准测试： 数据库的基准测试是对数据库的性能指标进行定量的、可复现的、可对比的测试。 基准测试可以理解为针对系统的一种压力测试。但基准测试不关心业务逻辑，更加简单、直接、易于测试，数据可以由工具生成，不要求真实；而压力测试一般考虑业务逻辑(如购物车业务)，要求真实的数据。 总结一下，为什么要有基准测试： 验证假设 重现异常 测试系统 预测扩展性瓶颈 规划未来的业务增长，评估所需资源 测试应用适应可变环境的能力 测试不同的硬件、软件和操作系统配置 证明设备是否配置正确 2.基准测试的作用 对于多数Web应用，整个系统的瓶颈在于数据库；原因很简单：Web应用中的其他因素，例如网络带宽、负载均衡节点、应用服务器（包括CPU、内存、硬盘灯、连接数等）、缓存，都很容易通过水平的扩展（俗称加机器）来实现性能的提高。而对于MySQL，由于数据一致性的要求，无法通过增加机器来分散向数据库写数据带来的压力；虽然可以通过前置缓存（Redis等）、读写分离、分库分表来减轻压力，但是与系统其它组件的水平扩展相比，受到了太多的限制。 而对数据库的基准测试的作用，就是分析在当前的配置下（包括硬件配置、OS、数据库设置等），数据库的性能表现，从而找出MySQL的性能阈值，并根据实际系统的要求调整配置。 3.常见数据库的基准测试指标包括： 1.处理能力 数据吞吐量(Throughput)，指单位时间内可以成功传输的数据数量。对于大量顺序读写的应用，如VOD(Video On Demand)，则更关注吞吐量指标。 每秒事务数(TPS) ：这是一个系统的处理能力的，最直接指标，一般的基准测试，都会重点测试这个指标。个业务场景中的事物标准是不一样的。 --用于衡量吞吐量 QPS 每秒处理的查询数 --用于衡量吞吐量 TPM 每分钟事务数 IOPS，每秒磁盘进行的I/O操作次数。随机读写频繁的应用，如OLTP，IOPS是关键衡量指标。 2.响应时间或延迟 任务所需的整体时间 常用测试指标： 平均响应时间 最小响应时间 最大响应时间 时间百分比 其中时间百分比参考意义较大，如前95%的请求的最大响应时间 3.并发量：同时处理的查询请求的数量。 为了测试应用在不同并发下的性能 4.可扩展性 给系统增加一倍的工作，在理想情况下获得两倍的结果(吞吐量) 4.基准测试的分类 对MySQL的基准测试，有如下两种思路： 针对整个系统的基准测试：通过http请求进行测试，如通过浏览器、APP或postman等测试工具。该方案的优点是能够更好的针对整个系统，测试结果更加准确；缺点是设计复杂实现困难。 只针对MySQL的基准测试：优点和缺点与针对整个系统的测试恰好相反。 在针对MySQL进行基准测试时，一般使用专门的工具进行，例如mysqlslap、sysbench等。其中，sysbench比mysqlslap更通用、更强大，且更适合Innodb（因为模拟了许多Innodb的IO特性），后面也将介绍使用sysbench进行基准测试的方法。 5.MySQL的相关tps/qps计算方法 5.1 MySQL的QPS计算 show global status where Variable_name in('com_select','com_insert','com_delete','com_update'); 等待10秒 show global status where Variable_name in('com_select','com_insert','com_delete','com_update'); 计算差值 5.2 MySQL的TPS计算 show global status where Variable_name in('com_insert','com_delete','com_update'); 等待10秒 show global status where Variable_name in('com_insert','com_delete','com_update'); 计算差值 6.磁盘的IOPS计算 IOPS 是指单位时间内系统能处理的I/O请求数量，一般以每秒处理的I/O请求数量为单位，I/O请求通常为读或写数据操作请求。 6.1 传统机械硬盘的IOPS值计算 磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。 寻道时间Tseek 是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3－15ms。 旋转延迟Trotation 是指盘片旋转将请求数据所在扇区移至读写磁头下方所需要的时间。旋转延迟取决于磁盘转速，通常使用磁盘旋转一周所需时间的1/2表示。比如，7200 rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000 rpm的磁盘其平均旋转延迟约为2ms。 数据传输时间Ttransfer 是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。 目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分时间。 因此，理论上可以计算出磁盘的平均最大IOPS，即IOPS = 1000 ms/ (Tseek + Troatation)，忽略数据传输时间。假设磁盘平均物理寻道时间为3ms, 磁盘转速为7200,10K,15K rpm，则磁盘IOPS理论最大值分别为， IOPS = 1000 / (3 + 60000/7200/2) = 140 IOPS = 1000 / (3 + 60000/10000/2) = 167 IOPS = 1000 / (3 + 60000/15000/2) = 200 6.2 iostat 命令 [root@nazeebo ~]# iostat -xm 2 --x表示显示扩展统计信息，m表示以兆为单位显示，2表示每隔2秒显示 Linux 3.10.0-693.2.2.el7.x86_64 (nazeebo) 07/24/2018 _x86_64_ (2 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.08 0.00 0.07 0.01 0.00 99.84 Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.07 0.03 0.26 0.00 0.01 70.07 0.02 58.27 41.96 60.14 0.87 0.03 avg-cpu: %user %nice %system %iowait %steal %idle 0.00 0.00 0.25 0.00 0.00 99.75 Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 avg-cpu: %user %nice %system %iowait %steal %idle 0.25 0.00 0.00 0.00 0.00 99.75 Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 6.2.1 CPU属性说明: %user CPU处在用户模式下的时间百分比 %nice CPU处在带NICE值的用户模式下的时间百分比 %sys CPU处在系统模式下的时间百分比 %iowait CPU等待IO完成时间的百分比 %steal 管理程序维护另一个虚拟处理器时，虚拟CPU的无意的等待时间的百分比 %idle 闲置cpu的百分比 提示： 如果%iowait的值过高，表示硬盘存在I/O瓶颈; 如果%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。 如果%idle值如果 持续 很低，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 6.2.2 Device属性说明: rrqm/s 每秒进行 merge 的读操作数目 wrqm/s 每秒进行 merge 的写操作数目 r/s 每秒完成的读 I/O 设备次数 w/s 每秒完成的写 I/O 设备次数 rsec/s 每秒读扇区数 wsec/s 每秒写扇区数 rkB/s 每秒读K字节数 wkB/s 每秒写K字节数 avgrq-sz 平均每次设备I/O操作的数据大小 (扇区) avgqu-sz 平均I/O队列长度 await 平均每次设备I/O操作的等待时间 (毫秒) svctm 平均每次设备I/O操作的服务时间 (毫秒) %util 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比 rrqm/s 和 wrqm/s Merge 将若干个连续地址的IO请求进行合并。来提高IO的效率 rrqm/s 是每秒读（read）请求合并的次数 wrqm/s 是每秒写（write）请求合并的次数 r/s和w/s 在 合并之后（after merge） IO请求的次数 r/s 合并之后每秒读IO的次数 w/s 合并之后每秒写IO的次数 r/s + w/s = IOPS rsec/s（rKB/s、rMB/s）和 wsec/s（wKB/s、wMB/s） sec 是 Sector（扇区） ，为 512Byte KB 和 MB 是通过扇区的 512Byte 进行的换算 avgrq-sz 一块磁盘可能存储数据的同时还存储日志，所以请求的IO大小是不一样的 该参数就是平均的请求数，注意，该值需要 * 512Byte 才是最终的结果，因为该值是以扇区为单位的 avgqu-sz 请求的IO队列的平均长度 （比较重要） HDD可能在4左右，SSD可以达到30左右 await、r_await、w_await IO请求平均等待的时间，单位是ms r_await 和 w_await 分别对应 读IO请求的等待 和 写IO请求的等待 svctm 服务于IO请求的平均时间 man文档中提示不要相信该值，以后会被移除 %util 磁盘是否空闲；不能简单的等同于IO的使用率；该值可以解释为磁盘是否繁忙 如果该值100% 不能简单的等同于磁盘的负载满了，达到了瓶颈 需要综合 avgqu-sz 、 await 等其他指标进行综合判断磁盘是否达到瓶颈 提示： 如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间； 如果 await 远大于 svctm，说明I/O队列太长，io响应太慢，则需要进行必要优化。 如果avgqu-sz比较大，也表示有当量io在等待。 6.3 iotop iotop -u mysql # -u 表示监控哪个user的进程 上述命令只能看到MySQL的线程ID（Thread ID） 需要结合 performance_schema.threads表 中的信息，结合 iotop -u mysql 的输出，才可以知道某个线程的io使用情况 6.3.1 thread id 、pid的关系查询（类似于Oracle的pid于sid的关系） mysql> use performance_schema; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> desc threads; +---------------------+---------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------------------+---------------------+------+-----+---------+-------+ | THREAD_ID | bigint(20) unsigned | NO | | NULL | | -- MySQL内部线程ID | NAME | varchar(128) | NO | | NULL | | | TYPE | varchar(10) | NO | | NULL | | | PROCESSLIST_ID | bigint(20) unsigned | YES | | NULL | | | PROCESSLIST_USER | varchar(32) | YES | | NULL | | | PROCESSLIST_HOST | varchar(60) | YES | | NULL | | | PROCESSLIST_DB | varchar(64) | YES | | NULL | | | PROCESSLIST_COMMAND | varchar(16) | YES | | NULL | | | PROCESSLIST_TIME | bigint(20) | YES | | NULL | | | PROCESSLIST_STATE | varchar(64) | YES | | NULL | | | PROCESSLIST_INFO | longtext | YES | | NULL | | | PARENT_THREAD_ID | bigint(20) unsigned | YES | | NULL | | | ROLE | varchar(64) | YES | | NULL | | | INSTRUMENTED | enum('YES','NO') | NO | | NULL | | | HISTORY | enum('YES','NO') | NO | | NULL | | | CONNECTION_TYPE | varchar(16) | YES | | NULL | | | THREAD_OS_ID | bigint(20) unsigned | YES | | NULL | | -- 操作系统的线程ID +---------------------+---------------------+------+-----+---------+-------+ 17 rows in set (0.00 sec) --thread_id，thread_os_id，processid mysql> select name,type,thread_id,thread_os_id,processlist_id from threads; +----------------------------------------+------------+-----------+--------------+----------------+ | name | type | thread_id | thread_os_id | processlist_id | +----------------------------------------+------------+-----------+--------------+----------------+ | thread/sql/main | BACKGROUND | 1 | 8947 | NULL | | thread/sql/thread_timer_notifier | BACKGROUND | 2 | 8948 | NULL | | thread/innodb/io_ibuf_thread | BACKGROUND | 3 | 8951 | NULL | | thread/innodb/io_log_thread | BACKGROUND | 4 | 8952 | NULL | | thread/innodb/io_read_thread | BACKGROUND | 5 | 8953 | NULL | | thread/innodb/io_read_thread | BACKGROUND | 6 | 8954 | NULL | | thread/innodb/io_read_thread | BACKGROUND | 7 | 8955 | NULL | | thread/innodb/io_read_thread | BACKGROUND | 8 | 8956 | NULL | | thread/innodb/io_write_thread | BACKGROUND | 9 | 8957 | NULL | | thread/innodb/io_write_thread | BACKGROUND | 10 | 8958 | NULL | | thread/innodb/io_write_thread | BACKGROUND | 11 | 8959 | NULL | | thread/innodb/io_write_thread | BACKGROUND | 12 | 8960 | NULL | | thread/innodb/page_cleaner_thread | BACKGROUND | 13 | 8961 | NULL | | thread/innodb/srv_lock_timeout_thread | BACKGROUND | 15 | 8968 | NULL | | thread/innodb/srv_error_monitor_thread | BACKGROUND | 16 | 8969 | NULL | | thread/innodb/srv_monitor_thread | BACKGROUND | 17 | 8970 | NULL | | thread/innodb/srv_master_thread | BACKGROUND | 18 | 8971 | NULL | | thread/innodb/srv_purge_thread | BACKGROUND | 19 | 8972 | NULL | | thread/innodb/srv_worker_thread | BACKGROUND | 20 | 8973 | NULL | | thread/innodb/srv_worker_thread | BACKGROUND | 21 | 8974 | NULL | | thread/innodb/srv_worker_thread | BACKGROUND | 22 | 8975 | NULL | | thread/innodb/buf_dump_thread | BACKGROUND | 23 | 8976 | NULL | | thread/innodb/dict_stats_thread | BACKGROUND | 24 | 8977 | NULL | | thread/semisync/Ack_receiver | BACKGROUND | 25 | 8980 | NULL | | thread/sql/signal_handler | BACKGROUND | 26 | 8987 | NULL | | thread/sql/compress_gtid_table | FOREGROUND | 27 | 8988 | 1 | | thread/sql/one_connection | FOREGROUND | 142 | 9019 | 116 | -- FOREGROUND前台线程 +----------------------------------------+------------+-----------+--------------+----------------+ 27 rows in set (0.00 sec) --processid mysql> show processlist; +-----+------+-----------+--------------------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +-----+------+-----------+--------------------+---------+------+----------+------------------+ | 116 | root | localhost | performance_schema | Query | 0 | starting | show processlist | +-----+------+-----------+--------------------+---------+------+----------+------------------+ 1 row in set (0.00 sec) mysql> select connection_id(); +-----------------+ | connection_id() | +-----------------+ | 116 | +-----------------+ 1 row in set (0.00 sec) 通过 threads表 中的信息，结合 iotop -u mysql 的输出，就可以知道某个线程的io使用情况 6.3.2 innodb_flush_method参数 mysql> show variables like '%innodb_flush_method%'; +---------------------+----------+ | Variable_name | Value | +---------------------+----------+ | innodb_flush_method | O_DIRECT | +---------------------+----------+ 1 row in set (0.00 sec) fwrite / fsync fwrite 是把数据写入文件系统层（Filesystem）（可能有cache），并不能保证写入Disk fsync 可以保证把数据写入到Disk（数据落盘） 只通过 fwrite 写入数据特别快（因为有缓存），但随后调用 fsync 就会很慢，这个速度取决于磁盘的 IOPS 如果不手工执行 fysnc ，当Filesystem的 cache 小于 10% 时，操作系统才会将数据刷入磁盘。所以可能存在数据丢失的风险，比如掉电 O_DIRECT 的设置参数是告诉系统 直接将数据写入磁盘 ，跳过文件系统的缓存。等同于使用 裸设备 的效果 7.提升IOPS性能的手段 通过 RAID 技术 功耗较高 IOPS在2000左右 通过购买共享存储设备 价格非常昂贵 但是比较稳定 底层还是通过RAID实现 直接使用SSD 性能较好的SSD可以达到 万级别的IOPS 建议可以用SSD + RAID5，RAID1+0太奢侈 SSD的IOPS值计算 SSD避免了传统磁盘在寻道和旋转上的时间花费，存储单元寻址开销大大降低，因此IOPS可以非常高，能够达到数万甚至数十万。实际测量中，IOPS数值会受到很多因素的影响，包括I/O负载特征(读写比例，顺序和随机，工作线程数，队列深度，数据记录大小)、系统配置、操作系统、磁盘驱动等等。 因此对比测量磁盘IOPS时，必须在同样的测试基准下进行，即便如何也会产生一定的随机不确定性。通常情况下，IOPS可细分为如下几个指标： Toatal IOPS，混合读写和顺序随机I/O负载情况下的磁盘IOPS，这个与实际I/O情况最为相符，大多数应用关注此指标。 Random Read IOPS，100%随机读负载情况下的IOPS。 Random Write IOPS，100%随机写负载情况下的IOPS。 Sequential Read IOPS，100%顺序负载读情况下的IOPS。 Sequential Write IOPS，100%顺序写负载情况下的IOPS。 IOPS的测试benchmark工具主要有Iometer, IoZone, FIO等，可以综合用于测试磁盘在不同情形下的IOPS。对于应用系统，需要首先确定数据的负载特征，然后选择合理的IOPS指标进行测量和对比分析，据此选择合适的存储介质和软件系统。下面的磁盘IOPS数据来自http://en.wikipedia.org/wiki/IOPS [1]，供基本参考。 二、sysbench 1.基本介绍 简单高效的基准测试工具 Oracle官方也使用该工具对MySQL进行测试 根据互联网应用特点进行测试 可以根据某个具体操作进行测试 最新版本1.1 https://github.com/akopytov/sysbench 还支持Oracle、PostgreSQL的测试 主要包括以下几种方式的测试： cpu性能 磁盘io性能 调度程序性能 内存分配及传输速度 POSIX线程性能 数据库性能(OLTP基准测试) 2.sysbench测试框架 常用测试脚本： oltp.lua – 读写混合测试 select.lua – 读的测试 update_index.lua – 更新索引页测试 update_non_index.lua – 更新非索引页测试 insert.lua – 插入测试 delete.lua – 删除测试 3.sysbench的安装 3.1 下载sysbench git clone https://github.com/akopytov/sysbench.git 3.2 进入目录，生成相关的配置文件 cd sysbench ./autogen.sh 在这儿有个小插曲，执行autogen.sh的时候报错 [root@nazeebo sysbench]# ./autogen.sh autoreconf: Entering directory `.' autoreconf: configure.ac: not using Gettext autoreconf: running: aclocal -I m4 --output=aclocal.m4t Can't exec \"aclocal\": No such file or directory at /usr/share/autoconf/Autom4te/FileUtils.pm line 326. autoreconf: failed to run aclocal: No such file or directory autogen.sh脚本依赖于autoreconf来调用autoconf，automake，aclocal和其它相关工具 所以上述的报错只需要 安装相应的rpm包既可 [root@nazeebo sysbench]# [root@nazeebo sysbench]# ./autogen.sh autoreconf: Entering directory `.' autoreconf: configure.ac: not using Gettext autoreconf: running: aclocal -I m4 autoreconf: configure.ac: tracing autoreconf: configure.ac: not using Libtool autoreconf: running: /usr/bin/autoconf configure.ac:61: error: possibly undefined macro: AC_PROG_LIBTOOL If this token and others are legitimate, please use m4_pattern_allow. See the Autoconf documentation. autoreconf: /usr/bin/autoconf failed with exit status: 1 [root@nazeebo sysbench]# yum install libtool libsysfs-devel 安装了automake，libtool libsysfs-devel后可以正常的执行了 [root@nazeebo sysbench]# ./autogen.sh autoreconf: Entering directory `.' autoreconf: configure.ac: not using Gettext autoreconf: running: aclocal -I m4 autoreconf: configure.ac: tracing autoreconf: running: libtoolize --copy libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, `config'. libtoolize: copying file `config/ltmain.sh' libtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'. libtoolize: copying file `m4/libtool.m4' libtoolize: copying file `m4/ltoptions.m4' libtoolize: copying file `m4/ltsugar.m4' libtoolize: copying file `m4/ltversion.m4' libtoolize: copying file `m4/lt~obsolete.m4' autoreconf: running: /usr/bin/autoconf autoreconf: running: /usr/bin/autoheader autoreconf: running: automake --add-missing --copy --no-force configure.ac:59: installing 'config/ar-lib' configure.ac:45: installing 'config/compile' configure.ac:27: installing 'config/config.guess' configure.ac:27: installing 'config/config.sub' configure.ac:32: installing 'config/install-sh' configure.ac:32: installing 'config/missing' src/Makefile.am: installing 'config/depcomp' parallel-tests: installing 'config/test-driver' autoreconf: Leaving directory `.' 3.3 关联mysql的头文件和库 [root@nazeebo sysbench]# ./configure --with-mysql-includes=/usr/local/mysql/include/ --with-mysql-libs=/usr/local/mysql/lib/ ... =============================================================================== sysbench version : 1.1.0-7c366c6 CC : gcc -std=gnu99 CFLAGS : -O3 -funroll-loops -ggdb3 -march=core2 -Wall -Wextra -Wpointer-arith -Wbad-function-cast -Wstrict-prototypes -Wnested-externs -Wno-format-zero-length -Wundef -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Wredundant-decls -Wcast-align -pthread CPPFLAGS : -D_GNU_SOURCE -I$(top_srcdir)/src -I$(abs_top_builddir)/third_party/luajit/inc -I$(abs_top_builddir)/third_party/concurrency_kit/include LDFLAGS : -L/usr/local/lib LIBS : -lm prefix : /usr/local bindir : ${prefix}/bin libexecdir : ${prefix}/libexec mandir : ${prefix}/share/man datadir : ${prefix}/share MySQL support : yes PostgreSQL support : no LuaJIT : bundled LUAJIT_CFLAGS : -I$(abs_top_builddir)/third_party/luajit/inc LUAJIT_LIBS : $(abs_top_builddir)/third_party/luajit/lib/libluajit-5.1.a -ldl LUAJIT_LDFLAGS : -rdynamic Concurrency Kit : bundled CK_CFLAGS : -I$(abs_top_builddir)/third_party/concurrency_kit/include CK_LIBS : $(abs_top_builddir)/third_party/concurrency_kit/lib/libck.a configure flags : =============================================================================== 3.4 常规性的make && make install [root@nazeebo sysbench]# make #make -j 2 ，其中2表示用几个cpu核心进行编译 [root@nazeebo sysbench]# make install 3.5 配置环境变量，查看版本 [root@nazeebo sysbench]# echo \"export LD_LIBRARY_PATH=/usr/local/mysql/lib/:$LD_LIBRARY_PATH\" >> ~/.bashrc [root@nazeebo sysbench]# source ~/.bashrc [root@nazeebo sysbench]# sysbench --version sysbench 1.1.0-7c366c6 4.sysbench的使用 4.1 sysbench选项说明 --oltp-test-mode=STRING 测试类型：simple(简单select测试),complex(事务测试),nontrx(非事务测试),sp(存储过程) ；默认complex --oltp-reconnect-mode=STRING 连接类型：session(每个线程到测试结束不重新连接),transaction(执行每个事务重新连接),query(每一个查询重新连接),random(随机)；默认 [session] --oltp-sp-name=STRING 指定执行测试的存储过程名 --oltp-read-only=[on|off] 仅执行select测试，默认关闭 --oltp-avoid-deadlocks=[on|off] 更新过程中忽略死锁，默认[off] --oltp-skip-trx=[on|off] 语句以bigin/commit开始结尾，默认[off] --oltp-range-size=N 范围查询的范围大小，默认 [100]，例如begin 100 and 200 --oltp-point-selects=N 单个事务中select查询的数量，默认 [10] --oltp-use-in-statement=N 每个查询中主键查找(in 10个值)的数量，默认 [0] --oltp-simple-ranges=N 单个事务中执行范围查询的数量(SELECT c FROM sbtest WHERE id BETWEEN N AND M)，默认[1] --oltp-sum-ranges=N 单个事务中执行范围sum查询的数量，默认 [1] --oltp-order-ranges=N 单个事务中执行范围order by查询的数量，默认[1] --oltp-distinct-ranges=N 单个事务中执行范围distinct查询的数量，默认[1] --oltp-index-updates=N 单个事务中执行索引更新的操作的数量，默认[1] --oltp-non-index-updates=N 单个事务中执行非索引更新操作的数量，默认[1] --oltp-nontrx-mode=STRING 指定单独非事务测试类型进行测试，默认select {select, update_key, update_nokey, insert, delete} [select] --oltp-auto-inc=[on|off] id列默认自增，默认[on] --oltp-connect-delay=N 指定每一次重新连接延时的时长，默认1秒 [10000] --oltp-user-delay-min=N minimum time in microseconds to sleep after each request [0] --oltp-user-delay-max=N maximum time in microseconds to sleep after each request [0] --oltp-table-name=STRING 指定测试的表名，默认[sbtest] --oltp-table-size=N 指定表的记录大小，默认[10000] --oltp-dist-type=STRING 随机数分布状态。uniform(均匀分布)、gauss(高斯分布)、special(特殊分布)，默认 [special] --oltp-dist-iter=N number of iterations used for numbers generation [12] --oltp-dist-pct=N 启用百分比特殊分布，默认 [1] --oltp-dist-res=N special 百分比[75] --oltp-point-select-mysql-handler=[on|off] Use MySQL HANDLER for point select [off] --oltp-point-select-all-cols=[on|off] select查询测试时select所有列，默认[off] --oltp-secondary=[on|off] 索引不是主键索引而是二级索引，默认[off] --oltp-num-partitions=N 指定表分区的数量，默认 [0] --oltp-num-tables=N 指定测试表的数量，默认[1] General database options: --db-driver=STRING 指定测试数据库类型，默认mysql --db-ps-mode=STRING prepared statements usage mode {auto, disable} [auto] mysql options: --mysql-host=[LIST,...] MySQL server host [localhost] --mysql-port=N MySQL server port [3306] --mysql-socket=STRING MySQL socket --mysql-user=STRING MySQL user [sbtest] --mysql-password=STRING MySQL password [] --mysql-db=STRING MySQL database name [sbtest] --mysql-table-engine=STRING storage engine to use for the test table {myisam,innodb,bdb,heap,ndbcluster,federated} [innodb] --mysql-engine-trx=STRING whether storage engine used is transactional or not {yes,no,auto} [auto] --mysql-ssl=[on|off] use SSL connections, if available in the client library [off] --myisam-max-rows=N max-rows parameter for MyISAM tables [1000000] --mysql-create-options=STRING additional options passed to CREATE TABLE [] oltp测试主要会有以下相关参数的测试,,其它相关参数默认即可，有需求也可以自定义： --mysql-engine-trx=STRING 指定不同的存储引擎测试。 --oltp-test-mode=STRING 测试类型：simple(简单select测试),complex(事务测试),nontrx(非事务测试),sp(存储过程) ；默认complex --oltp-sp-name=STRING 指定存储过程进行语句测试 --oltp-table-size=N 指定表的记录大小，默认[10000] --oltp-num-tables=N 指定测试表的数量，默认[1] 4.2 cpu性能测试 cpu测试主要是进行素数的加法运算，在下面的例子中，指定了最大的素数为 50000，可以根据机器cpu的性能来适当调整数值。 [root@nazeebo bin]# sysbench --test=cpu --cpu-max-prime=50000 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 1 Initializing random number generator from current time Prime numbers limit: 50000 Initializing worker threads... Threads started! CPU speed: events per second: 98.53 General statistics: total time: 10.0047s total number of events: 986 Latency (ms): min: 9.92 avg: 10.14 max: 11.98 95th percentile: 10.46 sum: 10000.88 Threads fairness: events (avg/stddev): 986.0000/0.00 execution time (avg/stddev): 10.0009/0.00 [root@nazeebo bin]# cd /test/ [root@nazeebo test]# sysbench --test=cpu --cpu-max-prime=50000 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 1 Initializing random number generator from current time Prime numbers limit: 50000 Initializing worker threads... Threads started! CPU speed: events per second: 98.72 General statistics: total time: 10.0058s total number of events: 988 Latency (ms): min: 9.93 avg: 10.12 max: 12.01 95th percentile: 10.46 sum: 10001.83 Threads fairness: events (avg/stddev): 988.0000/0.00 execution time (avg/stddev): 10.0018/0.00 4.3 线程测试 [root@nazeebo test]# sysbench --test=threads --num-threads=64 --thread-yields=100 --thread-locks=2 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 64 Initializing random number generator from current time Initializing worker threads... Threads started! General statistics: total time: 10.0051s total number of events: 74954 Latency (ms): min: 0.04 avg: 8.54 max: 252.31 95th percentile: 39.65 sum: 640079.38 Threads fairness: events (avg/stddev): 1171.1562/78.04 execution time (avg/stddev): 10.0012/0.00 [root@nazeebo test]# sysbench --test=threads --num-threads=64 --thread-yields=100 --thread-locks=2 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 64 Initializing random number generator from current time Initializing worker threads... Threads started! General statistics: total time: 10.0048s total number of events: 73762 Latency (ms): min: 0.04 avg: 8.68 max: 236.43 95th percentile: 41.10 sum: 640055.68 Threads fairness: events (avg/stddev): 1152.5312/92.49 execution time (avg/stddev): 10.0009/0.00 4.4 磁盘IO性能测试 4.4.1 准备测试文件 [root@nazeebo test]# sysbench --test=fileio --file-num=4 --file-block-size=8K --file-total-size=2G --file-test-mode=rndrw --file-extra-flags=direct --max-requests=0 --max-time=100 --num-threads=2 prepare WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead WARNING: --max-time is deprecated, use --time instead sysbench 1.0.9 (using system LuaJIT 2.0.4) 4 files, 524288Kb each, 2048Mb total Creating files for the test... Extra file open flags: 3 Creating file test_file.0 Creating file test_file.1 Creating file test_file.2 Creating file test_file.3 2147483648 bytes written in 217.06 seconds (9.44 MiB/sec). [root@nazeebo test]# [root@nazeebo test]# ll total 2097168 -rw------- 1 root root 536870912 Jul 24 16:04 test_file.0 -rw------- 1 root root 536870912 Jul 24 16:05 test_file.1 -rw------- 1 root root 536870912 Jul 24 16:06 test_file.2 -rw------- 1 root root 536870912 Jul 24 16:07 test_file.3 4.4.2 开始测试 [root@nazeebo test]# sysbench --test=fileio --file-num=4 --file-block-size=8K --file-total-size=2G --file-test-mode=rndrw --file-extra-flags=direct --max-requests=0 --max-time=30 --num-threads=4 --report-interval=3 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead WARNING: --max-time is deprecated, use --time instead sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 4 Report intermediate results every 3 second(s) Initializing random number generator from current time Extra file open flags: 3 4 files, 512MiB each 2GiB total file size Block size 8KiB Number of IO requests: 0 Read/Write ratio for combined random IO test: 1.50 Periodic FSYNC enabled, calling fsync() each 100 requests. Calling fsync() at the end of test, Enabled. Using synchronous I/O mode Doing random r/w test Initializing worker threads... Threads started! [ 3s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.61/s latency (ms,95%): 2.184 [ 6s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.67/s latency (ms,95%): 1.960 [ 9s ] reads: 9.67 MiB/s writes: 6.45 MiB/s fsyncs: 81.34/s latency (ms,95%): 2.032 [ 12s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.67/s latency (ms,95%): 1.996 [ 15s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.67/s latency (ms,95%): 2.032 [ 18s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.66/s latency (ms,95%): 1.891 [ 21s ] reads: 9.46 MiB/s writes: 6.31 MiB/s fsyncs: 81.33/s latency (ms,95%): 2.861 [ 24s ] reads: 9.47 MiB/s writes: 6.32 MiB/s fsyncs: 81.34/s latency (ms,95%): 2.264 [ 27s ] reads: 9.68 MiB/s writes: 6.45 MiB/s fsyncs: 82.66/s latency (ms,95%): 2.389 [ 30s ] reads: 9.69 MiB/s writes: 6.46 MiB/s fsyncs: 82.67/s latency (ms,95%): 2.264 File operations: reads/s: 1234.25 writes/s: 822.80 fsyncs/s: 82.26 Throughput: read, MiB/s: 9.64 written, MiB/s: 6.43 General statistics: total time: 30.0020s total number of events: 64187 Latency (ms): min: 0.02 avg: 1.87 max: 93.20 95th percentile: 2.18 sum: 119914.00 Threads fairness: events (avg/stddev): 16046.7500/174.99 execution time (avg/stddev): 29.9785/0.00 上述测试随机读写的速度分别在9.64MB/s，6.43MB/s （9.64MB/s 1024 / 8KB =1233.92）换算后得到的值就是IOPS，约等于上面的1234.25。 （6.43MB/s 1024 / 8KB =823.04）换算后得到的值就是IOPS，约等于上面的822.80。 4.4.3 cleanup测试文件 [root@nazeebo test]# sysbench --test=fileio --file-num=4 --file-block-size=8K --file-total-size=2G --file-test-mode=rndrw --file-extra-flags=direct --max-requests=0 --max-time=100 --num-threads=2 cleanup WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead WARNING: --max-time is deprecated, use --time instead sysbench 1.0.9 (using system LuaJIT 2.0.4) Removing test files... [root@nazeebo test]# ls [root@nazeebo test]# 4.5 内存测试 指定本次测试整个过程是在内存中传输20G 的数据量，每个 block 大小为 8K。 [root@nazeebo test]# sysbench --test=memory --memory-block-size=8k --memory-total-size=20G run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. sysbench 1.0.9 (using system LuaJIT 2.0.4) Running the test with following options: Number of threads: 1 Initializing random number generator from current time Running memory speed test with the following options: block size: 8KiB total size: 20480MiB operation: write scope: global Initializing worker threads... Threads started! Total operations: 2621440 (1040027.08 per second) 20480.00 MiB transferred (8125.21 MiB/sec) General statistics: total time: 2.5185s total number of events: 2621440 Latency (ms): min: 0.00 avg: 0.00 max: 0.12 95th percentile: 0.00 sum: 1867.25 Threads fairness: events (avg/stddev): 2621440.0000/0.00 execution time (avg/stddev): 1.8673/0.00 4.6 OLTP测试 4.6.1 准备数据 执行模式为complex，使用了10个表，每个表有10万条数据，客户端的并发线程数为10，执行时间为120秒，每10秒生成一次报告。 [root@nazeebo sysbench]# sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --db-driver=mysql --mysql-host=nazeebo --mysql-port=3306 --mysql-user=root --mysql-password=123456 --oltp-test-mode=complex --oltp-tables-count=10 --oltp-table-size=100000 --threads=10 --time=120 --report-interval=10 prepare sysbench 1.0.9 (using system LuaJIT 2.0.4) Creating table 'sbtest1'... Inserting 100000 records into 'sbtest1' Creating secondary indexes on 'sbtest1'... Creating table 'sbtest2'... Inserting 100000 records into 'sbtest2' Creating secondary indexes on 'sbtest2'... Creating table 'sbtest3'... Inserting 100000 records into 'sbtest3' Creating secondary indexes on 'sbtest3'... Creating table 'sbtest4'... Inserting 100000 records into 'sbtest4' Creating secondary indexes on 'sbtest4'... Creating table 'sbtest5'... Inserting 100000 records into 'sbtest5' Creating secondary indexes on 'sbtest5'... Creating table 'sbtest6'... Inserting 100000 records into 'sbtest6' Creating secondary indexes on 'sbtest6'... Creating table 'sbtest7'... Inserting 100000 records into 'sbtest7' Creating secondary indexes on 'sbtest7'... Creating table 'sbtest8'... Inserting 100000 records into 'sbtest8' Creating secondary indexes on 'sbtest8'... Creating table 'sbtest9'... Inserting 100000 records into 'sbtest9' Creating secondary indexes on 'sbtest9'... Creating table 'sbtest10'... Inserting 100000 records into 'sbtest10' Creating secondary indexes on 'sbtest10'... [root@nazeebo sysbench]# 4.6.2 开始测试 [root@nazeebo test]# sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --db-driver=mysql --mysql-host=nazeebo --mysql-port=3306 --mysql-user=root --mysql-password=123456 --oltp-test-mode=complex --oltp-tables-count=10 --oltp-table-size=100000 --threads=10 --time=120 --report-interval=10 run >> /test/mysbtest.log 打开log查看： Initializing random number generator from current time Initializing worker threads... Threads started! [ 10s ] thds: 10 tps: 408.79 qps: 8194.76 (r/w/o: 5737.04/1639.15/818.58) lat (ms,95%): 37.56 err/s: 0.00 reconn/s: 0.00 [ 20s ] thds: 10 tps: 501.80 qps: 10033.31 (r/w/o: 7023.91/2005.80/1003.60) lat (ms,95%): 31.94 err/s: 0.00 reconn/s: 0.00 [ 30s ] thds: 10 tps: 512.10 qps: 10240.38 (r/w/o: 7168.98/2047.20/1024.20) lat (ms,95%): 31.37 err/s: 0.00 reconn/s: 0.00 [ 40s ] thds: 10 tps: 506.10 qps: 10123.40 (r/w/o: 7086.07/2025.12/1012.21) lat (ms,95%): 31.94 err/s: 0.00 reconn/s: 0.00 [ 50s ] thds: 10 tps: 518.51 qps: 10365.70 (r/w/o: 7255.67/2073.22/1036.81) lat (ms,95%): 30.81 err/s: 0.00 reconn/s: 0.00 [ 60s ] thds: 10 tps: 512.90 qps: 10260.06 (r/w/o: 7182.17/2051.89/1026.00) lat (ms,95%): 30.81 err/s: 0.00 reconn/s: 0.00 [ 70s ] thds: 10 tps: 494.97 qps: 9899.78 (r/w/o: 6930.16/1979.68/989.94) lat (ms,95%): 30.81 err/s: 0.00 reconn/s: 0.00 [ 80s ] thds: 10 tps: 466.83 qps: 9339.69 (r/w/o: 6536.52/1869.52/933.66) lat (ms,95%): 30.26 err/s: 0.00 reconn/s: 0.00 [ 90s ] thds: 10 tps: 520.30 qps: 10404.67 (r/w/o: 7284.85/2079.21/1040.61) lat (ms,95%): 30.26 err/s: 0.00 reconn/s: 0.00 [ 100s ] thds: 10 tps: 518.90 qps: 10380.23 (r/w/o: 7265.22/2077.21/1037.80) lat (ms,95%): 30.26 err/s: 0.00 reconn/s: 0.00 [ 110s ] thds: 10 tps: 510.68 qps: 10211.31 (r/w/o: 7148.02/2041.92/1021.36) lat (ms,95%): 31.37 err/s: 0.00 reconn/s: 0.00 [ 120s ] thds: 10 tps: 515.91 qps: 10319.65 (r/w/o: 7223.07/2064.85/1031.72) lat (ms,95%): 30.81 err/s: 0.00 reconn/s: 0.00 SQL statistics: queries performed: read: 838432 write: 239552 other: 119776 total: 1197760 transactions: 59888 (499.03 per sec.) queries: 1197760 (9980.60 per sec.) ignored errors: 0 (0.00 per sec.) reconnects: 0 (0.00 per sec.) General statistics: total time: 120.0071s total number of events: 59888 Latency (ms): min: 6.18 avg: 20.03 max: 943.21 95th percentile: 31.37 sum: 1199820.15 Threads fairness: events (avg/stddev): 5988.8000/37.32 execution time (avg/stddev): 119.9820/0.00 结果统计信息就在最后几句中。 4.6.3 清除测试数据 [root@nazeebo test]# sysbench /usr/share/sysbench/tests/include/oltp_legacy/oltp.lua --db-driver=mysql --mysql-host=nazeebo --mysql-port=3306 --mysql-user=root --mysql-password=123456 cleanup sysbench 1.0.9 (using system LuaJIT 2.0.4) Dropping table 'sbtest1'... Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:25 "},"17.performancetest.html":{"url":"17.performancetest.html","title":"17.性能测试","keywords":"","body":" 一、性能测试 1.TPC-C 2.tpcc-mysql 2.1 tpcc-mysql的安装 2.2 tpcc-mysql 测试 3.mysqlslap 一、性能测试 1.TPC-C 专门针对联机交易处理系统（OLTP系统）的 规范 该系统需要处理的交易事务主要为以下几种：（偏向于电商类） 新订单（New‐Order） ：客户输入一笔新的订货交易； 支付操作（Payment） ：更新客户帐户余额以反映其支付状况； 发货（Delivery） ：发货（模拟批处理交易）； 订单状态查询（Order‐Status） ：查询客户最辢交易的状态； 库存状态查询（Stock‐Level） ：查询仓库库存状况，以便能够及时补货 衡量单位： tpmC – transaction per minute 测试出来的TPS比较低，所以乘以60，数据比较好看 模拟线上业务，比较贴近实际2.tpcc-mysql 由Percona公司开发的tpcc测试工具，仅针对于MySQL数据库进行测试，和sysbench不同，TPCC测试中，数据库的总容量是在慢慢变大的（ 所以到后面，性能会慢慢下降 ）。 下面是tpcc-mysql的ER图，以及各数据表之间的关系比例 2.1 tpcc-mysql的安装 2.1.1 git clone [root@nazeebo test]# git clone https://github.com/Percona-Lab/tpcc-mysql.git Cloning into 'tpcc-mysql'... remote: Counting objects: 392, done. remote: Total 392 (delta 0), reused 0 (delta 0), pack-reused 392 Receiving objects: 100% (392/392), 202.81 KiB | 125.00 KiB/s, done. Resolving deltas: 100% (216/216), done. [root@nazeebo test]# ll drwxr-xr-x 6 root root 4096 Jul 24 17:16 tpcc-mysql [root@nazeebo test]# cd tpcc-mysql/ [root@nazeebo tpcc-mysql]# ll total 44 -rw-r--r-- 1 root root 1621 Jul 24 17:16 add_fkey_idx.sql --step2:创建索引 -rw-r--r-- 1 root root 317 Jul 24 17:16 count.sql -rw-r--r-- 1 root root 3105 Jul 24 17:16 create_table.sql --step1:创建表 -rw-r--r-- 1 root root 194 Jul 24 17:16 Dockerfile -rw-r--r-- 1 root root 763 Jul 24 17:16 drop_cons.sql -rw-r--r-- 1 root root 1079 Jul 24 17:16 load_multi_schema.sh -rw-r--r-- 1 root root 573 Jul 24 17:16 load.sh -rw-r--r-- 1 root root 2302 Jul 24 17:16 README.md drwxr-xr-x 2 root root 4096 Jul 24 17:16 schema2 drwxr-xr-x 5 root root 4096 Jul 24 17:16 scripts drwxr-xr-x 2 root root 4096 Jul 24 17:16 src 2.1.2 编译，生成tpcc_load和tpcc_start工具 [root@nazeebo tpcc-mysql]# cd src/ [root@nazeebo src]# ls delivery.c load.c Makefile ordstat.c payment.c rthist.h sb_percentile.h sequence.h spt_proc.c support.c trans_if.h driver.c main.c neword.c parse_port.h rthist.c sb_percentile.c sequence.c slev.c spt_proc.h tpc.h [root@nazeebo src]# make cc -w -O3 -g -I. `mysql_config --include` -c load.c cc -w -O3 -g -I. `mysql_config --include` -c support.c cc load.o support.o `mysql_config --libs_r` -lrt -o ../tpcc_load cc -w -O3 -g -I. `mysql_config --include` -c main.c cc -w -O3 -g -I. `mysql_config --include` -c spt_proc.c cc -w -O3 -g -I. `mysql_config --include` -c driver.c cc -w -O3 -g -I. `mysql_config --include` -c sequence.c cc -w -O3 -g -I. `mysql_config --include` -c rthist.c cc -w -O3 -g -I. `mysql_config --include` -c sb_percentile.c cc -w -O3 -g -I. `mysql_config --include` -c neword.c cc -w -O3 -g -I. `mysql_config --include` -c payment.c cc -w -O3 -g -I. `mysql_config --include` -c ordstat.c cc -w -O3 -g -I. `mysql_config --include` -c delivery.c cc -w -O3 -g -I. `mysql_config --include` -c slev.c cc main.o spt_proc.o driver.o support.o sequence.o rthist.o sb_percentile.o neword.o payment.o ordstat.o delivery.o slev.o `mysql_config --libs_r` -lrt -o ../tpcc_start [root@nazeebo src]# cd .. [root@nazeebo tpcc-mysql]# ll total 312 -rw-r--r-- 1 root root 1621 Jul 24 17:16 add_fkey_idx.sql -rw-r--r-- 1 root root 317 Jul 24 17:16 count.sql -rw-r--r-- 1 root root 3105 Jul 24 17:16 create_table.sql -rw-r--r-- 1 root root 194 Jul 24 17:16 Dockerfile -rw-r--r-- 1 root root 763 Jul 24 17:16 drop_cons.sql -rw-r--r-- 1 root root 1079 Jul 24 17:16 load_multi_schema.sh -rw-r--r-- 1 root root 573 Jul 24 17:16 load.sh -rw-r--r-- 1 root root 2302 Jul 24 17:16 README.md drwxr-xr-x 2 root root 4096 Jul 24 17:16 schema2 drwxr-xr-x 5 root root 4096 Jul 24 17:16 scripts drwxr-xr-x 2 root root 4096 Jul 24 17:19 src -rwxr-xr-x 1 root root 81112 Jul 24 17:19 tpcc_load -rwxr-xr-x 1 root root 188640 Jul 24 17:19 tpcc_start 2.1.3 创建表，生成数据 1.先提前创建好库tpcc1，然后使用脚本create_table.sql创建表 root@nazeebo tpcc-mysql]# mysql -u root -p123456 -S /tmp/mysql.sock tpcc [server]: nazeebo [port]: 3306 [DBname]: tpcc [user]: root [pass]: 123456 [warehouse]: 2 TPCC Data Load Started... Loading Item .................................................. 5000 .................................................. 10000 .................................................. 15000 .................................................. 20000 .................................................. 25000 .................................................. 30000 .................................................. 35000 .................................................. 40000 .................................................. 45000 .................................................. 50000 .................................................. 55000 .................................................. 60000 .................................................. 65000 .................................................. 70000 .................................................. 75000 .................................................. 80000 .................................................. 85000 .................................................. 90000 .................................................. 95000 .................................................. 100000 Item Done. ... 省略大部分输出 ... ...DATA LOADING COMPLETED SUCCESSFULLY. 3.创建完成后创建索引 [root@nazeebo tpcc-mysql]# mysql -u root -p -S /tmp/mysql.sock tpcc 2.1.4 检查生成的数据 mysql> use tpcc Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> select * from warehouse; +------+-----------+----------------+----------------------+--------------------+---------+-----------+-------+-----------+ | w_id | w_name | w_street_1 | w_street_2 | w_city | w_state | w_zip | w_tax | w_ytd | +------+-----------+----------------+----------------------+--------------------+---------+-----------+-------+-----------+ | 1 | SGjfdBiF6 | f0gUgEmWUpQOx | W9TDbXY1lFhMRNcVIFVy | BCTgeG62BHWJkj | IG | 955868834 | 0.18 | 300000.00 | | 2 | wtBvxidw | SWSdQDVap2wJah | aqHCF6QCyZ5 | FipF8JfjktCKgEHzoy | Nm | 397751947 | 0.17 | 300000.00 | +------+-----------+----------------+----------------------+--------------------+---------+-----------+-------+-----------+ 2 rows in set (0.00 sec) mysql> select count(1) from district; +----------+ | count(1) | +----------+ | 20 | -- 因为是1:10的关系，有2个仓库，就有20个地区 +----------+ 1 row in set (0.00 sec) mysql> select count(1) from customer; +----------+ | count(1) | +----------+ | 60000 | -- 因为是1:30000，所以有2个仓库，就有60000个用户 +----------+ 1 row in set (0.01 sec) 以上就是将测试的数据生成好了，接下来就可以进行测试了。 注意： 测试之前，建议先 备份tpcc的数据库 ，然后开始测试，因为tpcc测试时，数据量会越来越多；当你修改部分参数以及优化后，想要做对比测试时，就不能在原来的基础上进行测试（因为数据量变大了），需要用备份的tpcc库进行还原后，再做测试。最简单的是直接停机，拷贝走datadir目录。 2.2 tpcc-mysql 测试 2.2.1 预热 [root@nazeebo tpcc-mysql]# mysql -uroot -p123456 -S /tmp/mysql.sock tpcc 2.2.2 开始测试 [root@nazeebo tpcc-mysql]# ./tpcc_start -h nazeebo -P 3306 -d tpcc -u root -p 123456 -w 2 -c 16 -r 10 -l 60 *************************************** *** ###easy### TPC-C Load Generator *** *************************************** option h with value 'nazeebo' option P with value '3306' option d with value 'tpcc' option u with value 'root' option p with value '123456' option w with value '2' option c with value '16' option r with value '10' option l with value '60' [server]: nazeebo [port]: 3306 [DBname]: tpcc [user]: root [pass]: 123456 [warehouse]: 2 [connection]: 16 [rampup]: 10 (sec.) [measure]: 60 (sec.) RAMP-UP TIME.(10 sec.) MEASURING START. --下面这每隔10秒打印的数据，就是tpcc的5个动作，订单、支付、发货、订单查询、库存查询 10, trx: 1482, 95%: 47.294, 99%: 73.085, max_rt: 170.466, 1476|247.195, 148|41.253, 148|393.725, 149|71.717 20, trx: 1533, 95%: 43.427, 99%: 61.898, max_rt: 105.618, 1536|197.600, 153|11.631, 153|204.132, 153|66.841 30, trx: 1520, 95%: 46.998, 99%: 65.954, max_rt: 81.930, 1520|167.517, 153|9.448, 153|207.713, 152|58.870 40, trx: 1587, 95%: 41.297, 99%: 53.775, max_rt: 79.465, 1585|159.549, 158|9.081, 159|187.199, 159|64.726 50, trx: 1502, 95%: 41.707, 99%: 54.504, max_rt: 87.930, 1503|175.694, 150|6.721, 149|170.767, 151|62.315 60, trx: 1586, 95%: 43.077, 99%: 54.798, max_rt: 85.671, 1588|168.550, 159|15.743, 159|192.450, 158|67.230 STOPPING THREADS................ [0] sc:0 lt:9210 rt:0 fl:0 avg_rt: 27.6 (5) [1] sc:0 lt:9208 rt:0 fl:0 avg_rt: 75.7 (5) [2] sc:900 lt:21 rt:0 fl:0 avg_rt: 1.6 (5) [3] sc:0 lt:921 rt:0 fl:0 avg_rt: 149.0 (80) [4] sc:184 lt:738 rt:0 fl:0 avg_rt: 32.2 (20) in 60 sec. [0] sc:0 lt:9210 rt:0 fl:0 [1] sc:0 lt:9208 rt:0 fl:0 [2] sc:900 lt:21 rt:0 fl:0 [3] sc:0 lt:921 rt:0 fl:0 [4] sc:184 lt:738 rt:0 fl:0 (all must be [OK]) [transaction percentage] Payment: 43.47% (>=43.0%) [OK] Order-Status: 4.35% (>= 4.0%) [OK] Delivery: 4.35% (>= 4.0%) [OK] Stock-Level: 4.35% (>= 4.0%) [OK] [response time (at least 90% passed)] New-Order: 0.00% [NG] * Payment: 0.00% [NG] * Order-Status: 97.72% [OK] Delivery: 0.00% [NG] * Stock-Level: 19.96% [NG] * 9210.000 TpmC tps = 9210/60≈154 3.mysqlslap mysqlslap 是官方提供的性能测试工具 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:24 "},"18.replication.html":{"url":"18.replication.html","title":"18.主从复制","keywords":"","body":" 一、概述 1.主从复制用途 2.主从部署的必要条件 3.复制原理 4.主从复制存在的问题 5.复制类型 6.复制重要参数 log_bin server-id server-uuid binlog_format read only sync_binlog gtid_mode enforce_gtid_consistency log_slave_updates master_info_repository relay_log_info_repository relay_log relay_log_recovery binlog_gtid_simple_recovery slave_skip_errors relay log binlog-do-db binlog-ignore-db replicate_do_table replicate_ignore_table replicate_do_db replicate_ignore_db replicate-wild-do-table replicate-wild-ignore-table slave_parallel_type slave_parallel_workers slave_net_timeout 7.复制模式 7.1 异步复制 7.2 半同步复制 7.3 GTID复制 7.4 级联复制 7.5 组复制 一、概述 MySQL天生支持replication，这个是它最大的优势。后面很多高可用的玩法都是基于最基本的主从复制的原理来的。因此，掌握主从复制非常重要！ 1.主从复制用途 实时灾备，用于故障切换 读写分离，提供查询服务 备份，避免影响业务 2.主从部署的必要条件 主库开启binlog日志（设置log-bin参数） 主从server-id不同 从库服务器能连同主库 3.复制原理 主从复制原理如图： 复制过程： 从库有两个线程，一个I/O线程，一个SQL线程 从库的I/O线程去请求主库的binlog 主库把数据的更改记录到自己的binlog 主库会生成一个log dump线程，用来给从库的I/O线程传binlog 从库得到主库发送的binlog并写入到自己的relay log中 从库的SQL线程会读取relay log，并解析成具体的操作执行，重做应用中继日志中的SQL语句，达到主从的数据一致 4.主从复制存在的问题 主库宕机之后，数据可能会丢失 从库只有一个sql Thread，主库是可以并发的，当写压力大时，复制很可能延时 5.复制类型 单向主从 双向主从 级联主从 一主多从 多主一从 6.复制重要参数 log_bin log_bin = on 搭建主从复制，必须开启二进制日志 需要注意的是，--log-bin选项设置的是log_bin_basename，而非log_bin 发散一个： -- 查询bin-log是否开启 SHOW VARIABLES LIKE '%log_bin%'; -- 显示第一个bin-log的信息 SHOW BINLOG EVENTS; -- 获取bin-log列表 SHOW BINARY LOGS; -- 查询某个bin-log信息 SHOW BINLOG EVENTS IN 'bin-log.000001'; -- 查看mysql服务器下面bin-log二进制文件方法: mysqlbinlog /u01/mysql/log/BIN-log.000009 再来个实际的例子，瞬间明了： mysql> show variables like '%log_bin%'; +---------------------------------+---------------------------------+ | Variable_name | Value | +---------------------------------+---------------------------------+ | log_bin | ON | | log_bin_basename | /u01/mysql/mysql_data/bin | | log_bin_index | /u01/mysql/mysql_data/bin.index | | log_bin_trust_function_creators | OFF | | log_bin_use_v1_row_events | OFF | | sql_log_bin | ON | +---------------------------------+---------------------------------+ 6 rows in set (0.00 sec) server-id 要保证主从的server-id不一致 server-uuid uuid存放在数据目录的auto.cnf文件下[root@nazeebodan mysql_data]# pwd /u01/mysql/mysql_data [root@nazeebodan mysql_data]# cat auto.cnf [auto] server-uuid=fbde5555-a76a-11e8-b670-00163e0463a7 binlog_format binlog_format = row 二进制的日志记录格式。 其可取值包括：STATEMENT、ROW和MIXED，分别代表的是基于语句的日志记录格式、基于行的日志记录格式和混合型日志记录格式。 如果使用unhealthy格式，则MySQL服务器将根据具体情况在基于语句的和基于行的日志记录格式之间自动切换。默认格式为STATEMENT。 运行时，如果要更改此参数或者会话值，客户端必须拥有SUPER权限。 rbr的优缺点： RBR的优点： 任何情况都可以被复制，这对复制来说是最安全可靠的 和其他大多数数据库系统的复制技术一样 多数情况下，从服务器上的表如果有主键的话，复制就会快了很多 复制以下几种语句时的行锁更少： INSERT ... SELECT 包含 AUTO_INCREMENT 字段的 INSERT 没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句 执行 INSERT，UPDATE，DELETE 语句时锁更少 从服务器上采用多线程来执行复制成为可能 RBR的缺点： binlog 大了很多 复杂的回滚时 binlog 中会包含大量的数据 主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题 UDF 产生的大 BLOB 值会导致复制变慢 无法从 binlog 中看到都复制了写什么语句 当在非事务表上执行一段堆积的SQL语句时，最好采用 SBR 模式，否则很容易导致主从服务器的数据不一致情况发生 read only 设置从库只读，避免在从库上进行写操作 但是对super admin的账号没有限制 在5.7新增加了一个参数super_read_only，开启该参数，连super admin 的账号也没有写的权限 sync_binlog sync_binlog = 1 默认值为0 像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log N>0 ： 每向二进制日志文件写入N条SQL或N个事务后，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去 N=0 ： 不主动刷新二进制日志文件的数据到磁盘上，而是由操作系统决定； 如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。 一般与innodb_flush_log_at_trx_commit同时设置 推荐配置组合： N=1,1 — 适合数据安全性要求非常高，而且磁盘IO写能力足够支持业务，比如充值消费系统； N=1,0 — 适合数据安全性要求高，磁盘IO写能力支持业务不富余，允许备库落后或无复制； N=2,0或2,m(0 N=0,0 — 磁盘IO写能力有限，无复制或允许复制延迟稍微长点能接受，例如：日志性登记业务；gtid_mode gtid_mode = on GTID是MySQL 5.6的新特性，其全称是Global Transaction Identifier，可简化MySQL的主从切换以及Failover。GTID用于在binlog中唯一标识一个事务。当事务提交时，MySQL Server在写binlog的时候，会先写一个特殊的Binlog Event，类型为GTID_Event，指定下一个事务的GTID，然后再写事务的Binlog。主从同步时GTID_Event和事务的Binlog都会传递到从库，从库在执行的时候也是用同样的GTID写binlog，这样主从同步以后，就可通过GTID确定从库同步到的位置了。也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过File_name和File_position找点儿了。 GTID(Global Transaction ID)是对于一个已提交事务的编号，并且是一个全局唯一的编号。 GTID实际上是由UUID+TID组成的。其中UUID是一个MySQL实例的唯一标识。TID代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。下面是一个GTID的具体形式： 3E11FA47-71CA-11E1-9E33-C80AA9429562:23 配置方式为gtid_mode=ON/OFF gtid_mode的类型为枚举类型，枚举值可以为ON和OFF，所以应该通过ON或者OFF来控制gtid_mode，不要把它配置成0或者1，否则结果可能不符合预期 开启gtid_mode时，log-bin和log-slave-updates也必须开启，否则MySQL Server拒绝启动 除此以外，enforce-gtid-consistency也必须开启，否则MySQL Server也拒绝启动。enforce-gtid-consistency是因为开启grid_mode以后，许多MySQL的SQL和GTID是不兼容的，比如开启ROW 格式时，CREATE TABLE ... SELECT，在binlog中会形成2个不同的事务，GTID无法唯一。另外在事务中更新MyISAM表也是不允许的。 enforce_gtid_consistency enforce_gtid_consistency = 1 与gtid一起使用 开始该参数，保证数据的一致性 log_slave_updates log_slave_updates 与gtid一起使用 将master服务器上获取数据变更的信息记录到从服务器的二进制文件中 master_info_repository master_info_repository = TABLE 从服务器是将主服务器的日志信息写入文件，还是写入表 如果该值为FILE（默认值），则从服务器日志文件有—master-info-file选项指定 如果该值为TABLE，则服务器会把日志记录到mysql.slave_master_inro表中 此参数是在MySQL 5.6.2里引入的 relay_log_info_repository relay_log_info_repository = TABLE 从服务器是将中继日志信息写入文件，还是写入表 如果该值为FILE（默认值），那么从服务器会把日志记录到—relay-log-info-file选项所指定的文件里 如果该值为TABLE，那么服务器会把日志记录到mysql.slave_relay_log_info_file表里 此参数的在MySQL 5.6.2里引入的 relay_log relay_log = relay.log 中继日志文件的名字 relay_log_recovery relay_log_recovery = 1 默认是禁用的 此参数在从服务器崩溃之后非常有用 在启动时启用它，可以使从服务器删除所有的还未处理的中继日志，并再次从主服务器获取它们 binlog_gtid_simple_recovery binlog_gtid_simple_recovery = 1 影响GTID的一个参数: 5.7.6以下中默认simplified_binlog_gtid_recovery=false 5.7.6以上中默认binlog_gtid_simple_recovery=true slave_skip_errors slave_skip_errors = ddl_exist_errors 用于指定一个错误列表 在列表里的错误出现时，从服务器会忽略它们，而不是将复制过程挂起。（不过，与利用这个选项来忽略错误的做法相比，还是找出问题的根源并彻底解决更好。） 如果此参数的值为all，则会忽略所有的错误。 否则，此参数的值应该是以逗号分隔的一个或者多个出错编号。 relay log 从库的IO线程从读库读取而来的binlog内容 binlog-do-db 选择性的复制某个、某些数据库 binlog-ignore-db 选择性的不复制某个、某些数据库 replicate_do_table 只复制指定的表，在从库上使用 replicate_ignore_table 不复制指定的表，在从库上使用 replicate_do_db 只复制指定的数据库，在从库上使用 replicate_ignore_db 不复制指定的数据库，在从库上使用 replicate-wild-do-table 使用通配符复制指定的表，如复制scott下面的emp开头的表 =scott.emp% replicate-wild-ignore-table 使用通配符不复制指定的表 slave_parallel_type 5.7.2引入 两个值，一个是database，一个是logical_clock 基于组提交的并行复制 slave_parallel_workers 设置多个线程并发执行relay log中主库提交的事务，最大值为1024 slave_net_timeout 该参数是设置在多少秒没有收到主库传来的binlog之后，从库认为是网络超时，这时从库的IO线程会重新连接主库。 5.7.7开始默认是60秒 7.复制模式 7.1 异步复制 在主节点执行和提交事务，然后把变化量异步的发送到从节点，行复制的重新执行主节点的SQL语句，这是一个 shared-nothing 的系统，默认情况下所有 server 成员都有一个完整的数据副本。 配置方法 7.2 半同步复制 半同步复制，它在协议中添加了一个同步步骤。 这意味着主节点在提交时需要等待从节点确认它已经接收到事务。只有这样，主节点才能继续提交操作。 配置方法 7.3 GTID复制 简介： GTID是MySQL 5.6的新特性，其全称是Global Transaction Identifier，可简化MySQL的主从切换以及Failover。GTID用于在binlog中唯一标识一个事务。当事务提交时，MySQL Server在写binlog的时候，会先写一个特殊的Binlog Event，类型为GTID_Event，指定下一个事务的GTID，然后再写事务的Binlog。主从同步时GTID_Event和事务的Binlog都会传递到从库，从库在执行的时候也是用同样的GTID写binlog，这样主从同步以后，就可通过GTID确定从库同步到的位置了。也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过File_name和File_position找点儿了。 GTID(Global Transaction ID)是对于一个已提交事务的编号，并且是一个全局唯一的编号。 GTID实际上是由UUID+TID组成的。其中UUID是一个MySQL实例的唯一标识。TID代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。下面是一个GTID的具体形式： 3E11FA47-71CA-11E1-9E33-C80AA9429562:23 在服务器上查询uuid： mysql> show global variables like 'server_uuid'; +---------------+--------------------------------------+ | Variable_name | Value | +---------------+--------------------------------------+ | server_uuid | fbde5555-a76a-11e8-b670-00163e0463a7 | +---------------+--------------------------------------+ 1 row in set (0.00 sec) 在服务器上uuid的自动生成位置： [root@nazeebodan mysql_data]# pwd /u01/mysql/mysql_data [root@nazeebodan mysql_data]# cat auto.cnf [auto] server-uuid=fbde5555-a76a-11e8-b670-00163e0463a7 更多详细的可以参考官方文档：http://dev.mysql.com/doc/refman/5.6/en/replication-gtids-concepts.html GTID的意义 假设现在没有GTID 当Master宕机后，一个Slave 被提升为New Master ，如果需要继续维持复制关系，就需要把另外两个Slave的CHANGE MASTER 指向New Master ； 那问题来了，原来Slave是指向Master 的Filename_M + Position_M 的位置，现在要指向New Master 上新的Filename_N + Position_N 的位置，这两个位置是比较难对应起来的; 此时两个Slave要继续复制（CHANGE MASTER）会比较麻烦。 使用GTID 和上面一样的场景，两个Slave需要重新指向New Master ，由于使用了GTID ，目前Slave-A 获取到的日志对应的GTID=G_A ， Slave-B 获取到的日志对应的GTID=G_B ; 此时New Master 上是存在G_A 和 G_B （通过选举出来的，获取的日志应该是最多的），那两个Slave就可以直接使用G_A和G_B 这两个GTID，通过指向New Master 接着继续复制； GTID的作用 那么GTID功能的目的是什么呢？具体归纳主要有以下两点： 根据GTID可以知道事务最初是在哪个实例上提交的 GTID的存在方便了Replication的Failover 这里详细解释下第二点。可以看下在MySQL 5.6的GTID出现以前replication failover的操作过程。假设我们有一个如下图的环境 此时，Server A的服务器宕机，需要将业务切换到Server B上。同时，我们又需要将Server C的复制源改成Server B。复制源修改的命令语法很简单即CHANGE MASTER TO MASTER_HOST='xxx', MASTER_LOG_FILE='xxx', MASTER_LOG_POS=nnnn。而难点在于，由于同一个事务在每台机器上所在的binlog名字和位置都不一样，那么怎么找到Server C当前同步停止点，对应Server B的master_log_file和master_log_pos是什么的时候就成为了难题。这也就是为什么M-S复制集群需要使用MMM,MHA这样的额外管理工具的一个重要原因。 这个问题在5.6的GTID出现后，就显得非常的简单。由于同一事务的GTID在所有节点上的值一致，那么根据Server C当前停止点的GTID就能唯一定位到Server B上的GTID。甚至由于MASTER_AUTO_POSITION功能的出现，我们都不需要知道GTID的具体值，直接使用CHANGE MASTER TO MASTER_HOST='xxx', MASTER_AUTO_POSITION命令就可以直接完成failover的工作。 搭建步骤 可以参考官方给出的搭建步骤：http://dev.mysql.com/doc/refman/5.6/en/replication-gtids-howto.html 基于GTID的复制： GTID的配置： [mysqld] log_bin = bin.log gtid_mode = ON log_slave_updates = 1 enforce_gtid_consistency = 1 MySQL 5.6 必须开启参数log_slave_updates （5.6版本的限制） MySQL 5.6 升级到gtid模式需要停机重启 MySQL 5.7 版本开始可以不开启log_slave_updates MySQL 5.7.6 版本开始可以在线升级成gtid模式 GTID的限制： 不支持非事务引擎（从库报错，stopslave; start slave; 忽略） 不支持create table … select 语句复制（主库直接报错） 不允许在一个SQL同时更新一个事务引擎和非事务引擎的表 在一个复制组中，必须要求统一开启CTID或是关闭GTID 开启GTID需要重启（5.7中可能不需要） 开启GTID后，就不在使用原来的传统的复制方式 对于createtemporary table 和drop temporary table语句不支持 不支持sql_slave_skip_counter7.4 级联复制 介绍 MySQL B 从MySQL A 上复制， MySQL C 从MySQL B 上复制，此时MySQL B 上就要开启log_slave_updates 如果MySQL B 上不启用log_slave_updates ，则不会产生binlog ，没有binlog 则无法提供复制； log_bin 参数是当有直接对数据库进行操作的时候，产生binlog， 对复制产生的操作不会产生binlog （仅有relay-log）级联复制的场景 1.跨机房的复制 在跨机房搭建复制时，如果MySQL A 挂了， MySQL B 提升为New Master ，此时MySQL C 是不需要去做CHANGE MASTER 操作的。 缺点是复制的延迟会更大（跨机房的延迟本来就很难避免）。 2.库的拆分 当MySQL A 压力很大的时候，需要把DB_A 拆分出去，就可以使用级联复制，让DB_A 形成单独的库。 7.5 组复制 简介： 基于传统异步复制和半同步复制的缺陷——数据的一致性问题无法保证，MySQL官方在5.7.17版本正式推出组复制（MySQL Group Replication，简称MGR）。 由若干个节点共同组成一个复制组，一个事务的提交，必须经过组内大多数节点（N / 2 + 1）决议并通过，才能得以提交。如上图所示，由3个节点组成一个复制组，Consensus层为一致性协议层，在事务提交过程中，发生组间通讯，由2个节点决议(certify)通过这个事务，事务才能够最终得以提交并响应。 引入组复制，主要是为了解决传统异步复制和半同步复制可能产生数据不一致的问题。组复制依靠分布式一致性协议(Paxos协议的变体)，实现了分布式下数据的最终一致性，提供了真正的数据高可用方案(是否真正高可用还有待商榷)。其提供的多写方案，给我们实现多活方案带来了希望。 MGR的解决方案现在具备的特性： 数据一致性保障：确保集群中大部分节点收到日志 多节点写入支持：多写模式下支持集群中的所有节点都可以写入 Fault Tolerance: 确保系统发生故障（包括脑裂）依然可用，双写对系统无影响 组复制实现了基于复制协议PAXOS的多主更新 复制组由多个 server成员构成，并且组中的每个 server 成员可以独立地执行事务。但所有读写（RW）事务只有在冲突检测成功后才会提交。只读（RO）事务不需要在冲突检测，可以立即提交。 对于任何 RW 事务，提交操作并不是由始发 server 单向决定的，而是由组来决定是否提交。准确地说，在始发 server 上，当事务准备好提交时，该 server 会广播写入值（已改变的行）和对应的写入集（已更新的行的唯一标识符）。然后会为该事务建立一个全局的顺序。最终，这意味着所有 server 成员以相同的顺序接收同一组事务。因此，所有 server 成员以相同的顺序应用相同的更改，以确保组内一致。 组复制能够根据在一组 server 中复制系统的状态来创建具有冗余的容错系统。因此，只要它不是全部或多数 server 发生故障，即使有一些 server 故障，系统仍然可用，最多只是性能和可伸缩性降低，但它仍然可用。server 故障是孤立并且独立的。它们由组成员服务来监控，组成员服务依赖于分布式故障检测系统，其能够在任何 server 自愿地或由于意外停止而离开组时发出信号。 它们是由一个分布式恢复程序来确保当有 server 加入组时，它们会自动更新组信息到最新。并且多主更新确保了即使在单个服务器故障的情况下也不会阻止更新，不必进行 server故障转移。因此，MySQL 组复制保证数据库服务持续可用。 值得注意的一点是，尽管数据库服务可用，但当有一个 server 崩溃时，连接到它的客户端必须定向或故障转移到不同的 server。这不是组复制要解决的问题。连接器，负载均衡器，路由器或其他形式的中间件更适合处理这个问题。 MGR的解决方案目前的不足 仅支持InnoDB表，并且每张表一定要有一个主键，用于做write set的冲突检测； 必须打开GTID特性，二进制日志格式必须设置为ROW，用于选主与write set COMMIT可能会导致失败，类似于快照事务隔离级别的失败场景 目前一个MGR集群最多支持9个节点 不支持外键于save point特性，无法做全局间的约束检测与部分部分回滚 二进制日志不支持binlog event checksum Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:22 "},"19.haintro.html":{"url":"19.haintro.html","title":"19.高可用选型介绍","keywords":"","body":" MySQL高可用选型 一、高可用 1.mha介绍 2.zookeeper/consul 3.mmm 4.keepalive 5.drbd 二、集群/分布式 1.MGR 2.MySQL InnoDB Cluster 3.Percona XtraDB Cluster 4.MariaDB Galera Cluster 三、中间件 1.MySQLProxy 2.MyCat 3.ProxySQL 4.KingShard 5.MaxScale 6.OneProxy MySQL高可用选型 按照自己的理解，将MySQL的HA分为三类：基于原生复制的高可用，脱离原生复制的集群分布式，以及中间件。 本篇将简单介绍相应的产品或组件。 一、高可用 基于原生的高可用，包括： mha consul/zookeeper mmm keepalive drbd 1.mha介绍 MHA是一套MySQL高可用管理软件，除了检测Master宕机后，提升候选Slave为New Master之外（漂虚拟IP），还会自动让其他Slave与New Master 建立复制关系。 MHA Manager可以单独部署在一台独立的机器上，并管理多个master-slave集群。 各组件作用： MHA Manager：MHA的管理节点，负责检测MySQL的状态，以及管理MySQL的复制关系； Master：MySQL对外提供的服务（ 通过 VIP ）的主节点； Slave(M)：MySQL候选主节点，本质上为一个Slave节点，只是在Master宕机后，会被提升为New Master ； Slave N：MySQL从机节点，对外可以提供只读服务； 工作原理 1.当Master宕机后，MHA Manager会让Slave(M) 提升为New Master ，然后修改Slave N 的复制关系（ CHANGE MASTER ），指向New Master ； MHA Manager检测Master是否宕机， 不会简单的只检查自身与Master之间的直连状态; MHA Manager会透过其他Slave节点去检测Master，进行二次探测，最大限度的避免脑裂的发生； 比如说，检测到Master宕机了，MHA Manager会透过Slave(M) 检测是否为宕机； 如果检测后仍为宕机状态，会继续透过Slave1...SlaveN 进行探测，只有在透过所有节点检测到Master宕机了，才真的认为Master宕机了； 以上操作步骤的前提是，MHA Manager到所有MySQL节点的SSH免密码登录要打通； 2.最后将提供对外服务的VIP漂移到New Master 上，继续对外提供服务； 3.一个MHA Manager可以管理多个MySQL的Master-Slave集群（通过不同的app.conf） MHA Failover过程 1.从宕机崩溃的Master节点保存二进制日志事件（binlog events）； 此种情况为MySQL挂了，但是服务器没挂，还是可以通过SSH连接过去； 如果服务器彻底宕机了，该步骤略过； 2.识别含有最新的更新的Slave节点； 3.应用差异的中继日志（relay-log）到其他的Slave； 4.应用从Master保存的二进制日志事件（binlog events）； 如果之前Master彻底宕机了，就没有保存的binlog，该步骤略过； 5.提升一个 Slave 为新的 Master（New）； 6.使其他的Slave 连接新的 Master（New） 进行复制； 从上面的步骤看， MHA无法完全保证数据不会丢； MySQL 5.7 之前数据不丢的前提是Master服务器还可以被MHA Manager进行SSH连接，通过应用保存的binlog 的方式来保证。 MySQL 5.7 之后通过无损复制， 仅仅是减少了丢数据的可能性，假如此时的状态为切成异步的状态，那就和之前一样了（可以设置超时的时间很大）； 当Master恢复的时候，最后一部分数据是否需要Flashback，MHA也是不负责这个事情，需要人工介入。 2.zookeeper/consul zk介绍 Zookeeper/cosul使用分布式算法保证集群数据的一致性，使用zookeeper/consul可以有效的保证proxy的高可用性，可以较好的避免网络分区现象的产生。 consul介绍 consul是HashiCorp公司（曾经开发过vgrant） 推出的一款开源工具， 基于go语言开发， 轻量级， 用于实现分布式系统的服务发现与配置。 与其他类似产品相比， 提供更“一站式”的解决方案。 consul内置有KV存储， 服务注册/发现， 健康检查， HTTP+DNS API， Web UI等多种功能。官网： https://www.consul.io/其他同类服务发现与配置的主流开源产品有:zookeeper和ETCD。 consul的优势： 支持多数据中心， 内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障, zookeeper和 etcd 均不提供多数据中心功能的支持 支持健康检查. etcd 不提供此功能. 支持 http 和 dns 协议接口. zookeeper 的集成较为复杂,etcd 只支持 http 协议. 有DNS功能， 支持REST API 官方提供web管理界面, etcd 无此功能. 部署简单， 运维友好， 无依赖， go的二进制程序copy过来就能用了， 一个程序搞定， 可以结合ansible来推送。 consul的架构图： 优缺点： 优点： 较好的保证了整个系统的高可用性，包括proxy、MySQL; 扩展性较好，可以扩展为大规模集群; 缺点： 数据一致性仍然依赖于原生的mysql半同步复制; 引入zk/consul，整个系统的逻辑变得更加复杂;3.mmm MMM（Master-Master replication manager for MySQL）是一套支持双主故障切换和双主日常管理的脚本程序。MMM使用Perl语言开发，主要用来监控和管理MySQL Master-Master（双主）复制，虽然叫做双主复制，但是业务上同一时刻只允许对一个主进行写入，另一台备选主上提供部分读服务，以加速在主主切换时刻备选主的预热，可以说MMM这套脚本程序一方面实现了故障切换的功能，另一方面其内部附加的工具脚本也可以实现多个slave的read负载均衡。 MMM提供了自动和手动两种方式移除一组服务器中复制延迟较高的服务器的虚拟ip，同时它还可以备份数据，实现两节点之间的数据同步等。由于MMM无法完全的保证数据一致性，所以MMM适用于对数据的一致性要求不是很高，但是又想最大程度的保证业务可用性的场景。对于那些对数据的一致性要求很高的业务，非常不建议采用MMM这种高可用架构。 优点： 稳定和成熟的开源产品，经过了时间的考验 核心技术是mysql自己的技术，只是使用脚本程序来控制，所以在原理上比较容易理解，而且管理能够更智能化。 安装简单，配置简单，使用简单 功能强大 （HA，failover，tools套件，cluster模式可以一个monitor管理多个mmm组） 缺点： 由于架构里只有一个写入点，所以扩展性是有限的，但是对一般中型企业够用了。 解决方案：对于大应用可以采取垂直拆分到多个mmm架构的方式，使用mmm cluster来管理。 对于读写分离和读负载均衡还是要程序来开发或者使用其他工具完成。 无法完全的保证数据一致，只用于对数据的一致性要求不是很高的业务 4.keepalive MySQL双主复制，即互为Master-Slave(只有一个Master提供写操作)，可以实现数据库服务器的热备，但是一个Master宕机后不能实现动态切换。使用Keepalived，可以通过虚拟IP，实现双主对外的统一接口以及自动检查、失败切换机制，从而实现MySQL数据库的高可用方案。 keepalived是集群管理中保证集群高可用的一个软件解决方案，其功能类似于heartbeat，用来防止单点故障。 keepalived是以VRRP协议为实现基础的，VRRP全称VirtualRouter Redundancy Protocol，即虚拟路由冗余协议。 keepalived主要有三个模块，分别是core 、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。 5.drbd DRBD 采用Heartbeat双机热备软件来保证数据库的高稳定性和连续性，数据的一致性由DRBD这个工具来保证。默认情况下只有一台mysql在工作，当主mysql服务器出现问题后，系统将自动切换到备机上继续提供服务，当主数据库修复完毕，又将服务切回继续由主mysql提供服务。 两个重要组件： DRBD(Distributed Replicated Block Device)是一个基于块设备级别在远程服务器直接同步和镜像数据的软件，用软件实现的、无共享的、服务器之间镜像块设备内容的存储复制解决方案。它可以实现在网络中两台服务器之间基于块设备级别的实时镜像或同步复制(两台服务器都写入成功)/异步复制(本地服务器写入成功)，相当于网络的RAID1，由于是基于块设备(磁盘，LVM逻辑卷)，在文件系统的底层，所以数据复制要比cp命令更快。DRBD已经被MySQL官方写入文档手册作为推荐的高可用的方案之一。 heartbeat可以资源(VIP地址及程序服务)从一台有故障的服务器快速的转移到另一台正常的服务器提供服务，heartbeat和keepalived相似，heartbeat可以实现failover功能，但不能实现对后端的健康检查。方案优缺点 优点：安全性高、稳定性高、可用性高，出现故障自动切换。 缺点：只有一台服务器提供服务，成本相对较高，不方便扩展，可能会发生脑裂。 生产环境不推荐使用，DRBD会使数据库性能下降很厉害。 方案适用场景： 适用于数据库访问量不太大，短期内访问量增长不会太快，对数据库可用性要求非常高的场景。 heartbeat和keepalived应用场景及区别 对于web，db，负载均衡(lvs,haproxy,nginx)等，heartbeat和keepalived都可以实现 lvs最好和keepalived结合，因为keepalived最初就是为lvs产生的，(heartbeat没有对RS的健康检查功能，heartbeat可以通过ldircetord来进行健康检查的功能) mysql双主多从，NFS/MFS存储，他们的特点是需要数据同步，这样的业务最好使用heartbeat，因为heartbeat有自带的drbd脚本 无数据同步的应用程序高可用可选择keepalived，有数据同步的应用程序高可用可选择heartbeat 二、集群/分布式 基于集群或者分布式的HA包括： Mysql Group Replication Mysql InnoDB Cluster Percona XtraDB Cluster MariaDB Galera Cluster 1.MGR 可以参考阿里的数据库内核月报，关于mgr的文档。 http://mysql.taobao.org/monthly/2017/08/01/ 简介： 基于传统异步复制和半同步复制的缺陷——数据的一致性问题无法保证，MySQL官方在5.7.17版本正式推出组复制（MySQL Group Replication，简称MGR）。 由若干个节点共同组成一个复制组，一个事务的提交，必须经过组内大多数节点（N / 2 + 1）决议并通过，才能得以提交。如上图所示，由3个节点组成一个复制组，Consensus层为一致性协议层，在事务提交过程中，发生组间通讯，由2个节点决议(certify)通过这个事务，事务才能够最终得以提交并响应。 引入组复制，主要是为了解决传统异步复制和半同步复制可能产生数据不一致的问题。组复制依靠分布式一致性协议(Paxos协议的变体)，实现了分布式下数据的最终一致性，提供了真正的数据高可用方案(是否真正高可用还有待商榷)。其提供的多写方案，给我们实现多活方案带来了希望。 MGR的解决方案现在具备的特性： 数据一致性保障：确保集群中大部分节点收到日志 多节点写入支持：多写模式下支持集群中的所有节点都可以写入 Fault Tolerance: 确保系统发生故障（包括脑裂）依然可用，双写对系统无影响 组复制实现了基于复制协议PAXOS的多主更新 复制组由多个 server成员构成，并且组中的每个 server 成员可以独立地执行事务。但所有读写（RW）事务只有在冲突检测成功后才会提交。只读（RO）事务不需要在冲突检测，可以立即提交。 对于任何 RW 事务，提交操作并不是由始发 server 单向决定的，而是由组来决定是否提交。准确地说，在始发 server 上，当事务准备好提交时，该 server 会广播写入值（已改变的行）和对应的写入集（已更新的行的唯一标识符）。然后会为该事务建立一个全局的顺序。最终，这意味着所有 server 成员以相同的顺序接收同一组事务。因此，所有 server 成员以相同的顺序应用相同的更改，以确保组内一致。 组复制能够根据在一组 server 中复制系统的状态来创建具有冗余的容错系统。因此，只要它不是全部或多数 server 发生故障，即使有一些 server 故障，系统仍然可用，最多只是性能和可伸缩性降低，但它仍然可用。server 故障是孤立并且独立的。它们由组成员服务来监控，组成员服务依赖于分布式故障检测系统，其能够在任何 server 自愿地或由于意外停止而离开组时发出信号。 它们是由一个分布式恢复程序来确保当有 server 加入组时，它们会自动更新组信息到最新。并且多主更新确保了即使在单个服务器故障的情况下也不会阻止更新，不必进行 server故障转移。因此，MySQL 组复制保证数据库服务持续可用。 值得注意的一点是，尽管数据库服务可用，但当有一个 server 崩溃时，连接到它的客户端必须定向或故障转移到不同的 server。这不是组复制要解决的问题。连接器，负载均衡器，路由器或其他形式的中间件更适合处理这个问题。 MGR的解决方案目前的不足 仅支持InnoDB表，并且每张表一定要有一个主键，用于做write set的冲突检测； 必须打开GTID特性，二进制日志格式必须设置为ROW，用于选主与write set COMMIT可能会导致失败，类似于快照事务隔离级别的失败场景 目前一个MGR集群最多支持9个节点 不支持外键于save point特性，无法做全局间的约束检测与部分部分回滚 二进制日志不支持binlog event checksum 2.MySQL InnoDB Cluster MySQL InnoDB Cluster解决方案其实是由MySQL的几个不同产品和技术组成的，比如MySQL Shell, MySQL Router, Group Replication. 一组MySQL服务器可以配置为一个MySQL集群。在默认的单主节点模式下，集群服务器具有一个读写主节点和多个只读辅节点。辅助服务器是主服务器的副本。客户端应用程序通过MySQL Router连接到主服务程序。如果主服务连接失败，则次要的节点自动提升为主节点，MySQL Router请求到新的主节点。InnoDB Cluster不提供NDB Cluster支持。 3.Percona XtraDB Cluster 官网地址：https://www.percona.com/doc/percona-xtradb-cluster/5.7/intro.html 名词： WS：write set 写数据集 IST：Incremental State Transfer 增量同步 SST：State Snapshot Transfer 全量同步 UUID：节点状态改变及顺序的唯一标识。 GTID：Global Transaction ID ，由UUID和偏移量组成。wsrep api 中定义的集群内全局事务id。 WSREP API：在DBMS和wsrep provider 之间提供接口。 Galera wsrep provider： 完成事务在集群内的广播：本地事务发送给其他节点验证，接收其他节点事件本地验证并返回结果 应用从其他节点接收并全局验证通过的事件到本地。 集群内通信，节点存活的检测，pc的选举等 脑裂，为避免节点失效导致pc选举失败整个集群不可用，建议节点数至少为3 多点写入时的锁冲突检测机制 等待队列中事务的并发提交 工作原理： 节点在接收sql 请求后，对于ddl 操作，在commit之前，由WSREP API 调用galera 库进行集群内广播，所有其他节点验证成功后事务在集群所有节点进行提交，反之rollback。pxc 保证整个集群所有数据的强一致性，满足CAP理论中满足：Consistency 和 Availability。 复制的过程： 上图为复制示意图 galera的group communication层实现统一全局数据同步策略和集群内所有事务的排序，便于生成GTID。 对于每一个节点有2方面工作：完成数据同步 和 完成与其他节点的通信 galera 的replication 层完成数据同步，由slave queue 和applier 组成。在事务的同步过程中，事务在队列中以及应用线程中时于节点本地产生锁冲突处理方式。replication 模块的效率直接影响整个集群的写入性能。 同步过程中，本地事务和等待队列中的锁冲突： innodb内部使用悲观锁，保证事务的成功进行和提交。 pxc中使用乐观锁，以避免在每个节点获取锁以及网路开销，在写入节点上，事务在提交之前与单点的innodb一样，到达提交点时，向集群其他节点广播（galera 库完成 并发）事物并等待各节点验证结果，如果所有节点都返回成功，则提交，反之，回滚。 pxc 中先提交的事物成功，其他事务（本地或其他节点同步）将回滚或报死锁错误。 验证过程 上图为验证示意图 验证过程中，节点在接收到其他节点writeset后，在本地做冲突验证并返回验证结果。 节点状态机：Regular Transitions: 状态机变化阶段： OPEN: 节点启动成功，尝试连接到集群，如果失败则根据配置退出或创建新的集群 PRIMARY: 节点处于集群PC中，尝试从集群中选取donor进行数据同步 JOINER: 节点处于等待接收/接收数据文件状态，数据传输完成后在本地加载数据 JOINED: 节点完成数据同步工作，尝试保持和集群进度一致 SYNCED：节点正常提供服务：数据的读写，集群数据的同步，新加入节点的sst请求 DONOR：节点处于为新节点准备或传输集群全量数据状态，对客户端不可用。 状态机变化因素： 新节点加入集群 节点故障恢复 节点同步实效 PXC提供的特性 同步复制，事务要么在所有节点提交或不提交 多主复制，可以在任意节点进行写操作 在从服务器上并行应用事件，真正意义上的并行复制 节点自动配置 数据一致性，不再是异步复制 兼容性: 完全兼容已有的系统（innodb引擎，优化器执行计划，完全相同的优化思路） 最小化的迁移（非常方便的从现有系统迁移到PXC） 快速的回退版本(无锁化，非常容易的恢复到非PXC系统) 限制: 只支持INNODB表 不允许大事务的产生（否则的话后果很严重） 写性能取决于最差的节点 不能解决热点更新问题 乐观锁控制 对于写密集型应用需要控制单个节点的大小，单个节点数据越大，新加节点如果采用自动添加可能产生很大抖动（添加节点建议用备份或者备份+binlog 进行IST(Incremental State Transfer)增量同步 优缺点 优点： 高可用性，节点不可用不影响集群正常运行。 强一致性，可以将读扩展到多个节点上。 节点的增加数据同步自动化（IST,SST）。 可实现多点读写，但写压力仍要同步到所有节点。 缺点： 由于ddl需全局验证通过，则集群性能由集群中最差性能节点决定。 为保证一致性，galera 总是优先保证数据一致性，在多点并发写时，锁冲突问题严重 新节点加入或延后较大的节点重新加入需全量拷贝数据（sst），作为donor的节点在同步过程中无法提供读写 数据冗余度为节点数 4.MariaDB Galera Cluster MariaDB集群是MariaDB同步多主机集群，仅支持XtraDB/InnoDB存储引擎（虽然有对MyISAM实验支持 - 看wsrep_replicate_myisam系统变量） XtraDB存储引擎是由Percona开发的一款MySQL数据库的高性能存储引擎，其目的是用来代替InnoDB存储引擎，可用于需要更高性能的环境。> 可以看作是InnoDB存储引擎的增强版本，它在InnoDB上进行了大量的修改和patched，它完全兼容InnoDB，且提供了很多InnoDB不具备的有用的功能。 例如： 在多核CPU上面的性能和伸缩性要更好； 对于内存的分配和使用也要更好； 也解除了InnoDB的很多限制； 提供了比InnoDB更多的配置和性能监控参数 主要功能 同步复制 --- Galera主从复制是同步的，底层依赖rsync； Active-active multi-master 拓扑逻辑，即所有节点可以同时读写数据库； 可对集群中任一节点进行数据读写 自动的节点成员控制，故障节点自动从集群中移除 新节点加入数据自动复制 真正的并行复制，基于行级 直接客户端连接，原生的 MySQL 接口 每个节点都包含完整的数据副本 多台数据库中数据同步由 wsrep 接口实现优势 因为是多主，所以不存在Slavelag(延迟) 不存在丢失事务的情况 同时具有读和写的扩展能力 更小的客户端延迟 节点间数据是同步的,而Master/Slave模式是异步的,不同slave上的binlog可能是不同的 局限性 目前的复制仅仅支持InnoDB和xtradb存储引擎,任何写入其他引擎的表，包括mysql.*（这个的存储引擎是myisam，8.0后替换为innodb）表将不会复制,但是DDL语句会被复制的,因此创建用户将会被复制,但是insert into mysql.user…将不会被复制的. DELETE操作不支持没有主键的表,没有主键的表在不同的节点顺序将不同,如果执行SELECT…LIMIT…将出现不同的结果集. 在多主环境下LOCK/UNLOCK TABLES不支持,以及锁函数GET_LOCK(), RELEASE_LOCK()… 查询日志不能保存在表中。如果开启查询日志，只能保存到文件中。 允许最大的事务大小由wsrep_max_ws_rows和wsrep_max_ws_size定义。任何大型操作将被拒绝。如大型的LOAD DATA操作。 由于集群是乐观的并发控制，事务commit可能在该阶段中止。如果有两个事务向在集群中不同的节点向同一行写入并提交，失败的节点将中止。对 于集群级别的中止，集群返回死锁错误代码(Error: 1213 SQLSTATE: 40001 (ER_LOCK_DEADLOCK)) XA事务不支持，由于在提交上可能回滚。 整个集群的写入吞吐量是由最弱的节点限制，如果有一个节点变得缓慢，那么整个集群将是缓慢的。为了稳定的高性能要求，所有的节点应使用统一的硬件。 集群节点建议最少3个。 如果DDL语句有问题将破坏集群说明 Galera集群的复制功能基于Galeralibrary实现,为了让MySQL与Galera library通讯，特别针对MySQL开发了wsrep API。 官方参考： https://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/ 三、中间件 第三方或者官方提供的中间件，包括： MySQLProxy MyCat ProxySQL(Percona) KingShard MaxScale(MariaDB) OneProxy 1.MySQLProxy mysql-proxy是mysql官方提供的mysql中间件服务，上游可接入若干个mysql-client，后端可连接若干个mysql-server。 它使用mysql协议，任何使用mysql-client的上游无需修改任何代码，即可迁移至mysql-proxy上。 mysql-proxy最基本的用法，就是作为一个请求拦截，请求中转的中间层： 进一步的，mysql-proxy可以分析与修改请求。拦截查询和修改结果，需要通过编写Lua脚本来完成。 mysql-proxy允许用户指定Lua脚本对请求进行拦截，对请求进行分析与修改，它还允许用户指定Lua脚本对服务器的返回结果 进行修改，加入一些结果集或者去除一些结果集均可。 所以说，根本上，mysql-proxy是一个官方提供的框架，具备良好的扩展性，可以用来完成： sql拦截与修改 性能分析与监控 读写分离 请求路由 2.MyCat 架构图如下： Mycat官网：http://www.mycat.io/ 介绍： MyCat是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。 工作原理： MySQL节点开启主从复制的配置方案，并将主节点配置为Mycat的dataHost里的writeNode，从节点配置为readNode，同时Mycat内部定期对一个dataHost里的所有writeHost与readHost节点发起心跳检测，正常情况下，Mycat会将第一个writeHost作为写节点，所有的DML SQL会发送给此节点，若Mycat开启了读写分离，则查询节点会根据读写分离的策略发往readHost(+writeHost)执行，当一个dataHost里面配置了两个或多个writeHost的情况下，如果第一个writeHost宕机，则Mycat会在默认的3次心跳检查失败后，自动切换到下一个可用的writeHost执行DML SQL语句，并在conf/dnindex.properties文件里记录当前所用的writeHost的index（第一个为0，第二个为1，依次类推）。 另外，由于Mycat自身是属于无状态的中间件（除了主从切换过程中记录的dnindex.properties文件），因此Mycat很容易部署为集群方式，提供高可用方案。 MyCat的关键特点： 支持SQL92标准 支持MySQL、Oracle、DB2、SQL Server、PostgreSQL等DB的常见SQL语法 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster 基于Nio实现，有效管理线程，解决高并发问题 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数,支持跨库分页 支持单库内部任意join，支持跨库2表join，甚至基于caltlet的多表join 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询 支持多租户方案。 支持分布式事务（弱xa） 支持XA分布式事务（1.6.5） 支持全局序列号，解决分布式下的主键生成问题 分片规则丰富，插件化开发，易于扩展 强大的web，命令行监控 支持前端作为MySQL通用代理，后端JDBC方式支持Oracle、DB2、SQL Server 、 mongodb 、巨杉 支持密码加密 支持服务降级 支持IP白名单 支持SQL黑名单、sql注入攻击拦截 支持prepare预编译指令（1.6） 支持非堆内存(Direct Memory)聚合计算（1.6） 支持PostgreSQL的native协议（1.6） 支持mysql和oracle存储过程，out参数、多结果集返回（1.6） 支持zookeeper协调主从切换、zk序列、配置zk化（1.6） 支持库内分表（1.6） 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版） 3.ProxySQL ProxySQL是一个高性能的MySQL中间件，拥有强大的规则引擎。 官方文档：https://github.com/sysown/proxysql/wiki/ 下载地址：https://github.com/sysown/proxysql/releases 特点： 连接池，而且是 multiplexing 主机和用户的最大连接数限制 自动下线后端DB 延迟超过阀值 ping 延迟超过阀值 网络不通或宕机 强大的规则路由引擎 实现读写分离 查询重写 sql流量镜像 支持prepared statement 支持Query Cache 支持负载均衡，与gelera结合自动failover 运行时： C++写的，性能应该不是问题 运行时分admin进程与proxy进程, 一般 6032 端口是 admin 进程。6033是proxy admin的目标是热配置生效，不必重启proxy。能直接使用mysql客户端简单的sql操作生效 整体配置可以从proxysql.cnf读，admin配置可以从proxysql-admin.cnf 热load进来 配置为runtime\\memory\\disk\\config-file的多层管理概念，详看官方wiki有介绍 配置以mysql的内存表方式存于内存，能通过 SAVE、LOAD 指令保存配置与加载配置 工作原理 ProxySQL从应用程序接收一个连接,通过它可以进行一个简单的SELECT或更复杂的事务。 ProxySQL获取每个查询,将其传递给查询处理器,处理它们,识别查询是否已被镜像,复制ProxySQL内部对象的整个MySQL会话,并将其与镜像队列(指的是镜像线程池)相关联。 如果池是空闲的(在并发线程集中有可用的线程插槽),则立即处理查询。 如果没有,查询将停留在队列中。如果队列已满,查询将丢失。 无论从查询返回什么,都会放到到/dev/null,因此没有结果集传回给客户端。 服务器的整个处理过程不是没有性能消耗的。如果检查CPU利用率,将看到ProxySQL中的 “mirroring” 实际上使CPU利用率翻倍了。这意味着由于资源争用,服务器A上的流量(traffic)会受到影响。 4.KingShard kingshard是一个由Go开发高性能MySQL Proxy项目，kingshard在满足基本的读写分离的功能上，致力于简化MySQL分库分表操作；能够让DBA通过kingshard轻松平滑地实现MySQL数据库扩容。 kingshard的性能是直连MySQL性能的80%以上。 github地址： https://github.com/flike/kingshard 适合应用场景 读写分离问题。由于前端应用访问量增加，单台MySQL不足以支撑整个系统的写入和查询操作。这时候，我们不得不将一些耗时的查询操作分散到多个slave上。 单表容量问题。如果在系统设计之初，没有考虑到分表问题。随着数据量的增长，单表容量越来越大。见过单表容量5亿条记录，然后一个简单的delete操作都会引起系统慢日志，而且有可能导致MySQL IO瞬发性的飙升。大家可能会想到，在查询的字段上加上索引，但当数据量增长到这么大的时候，即使加上索引效果也不明显了。归根结底，就是单表数据量太大，导致MySQL即使通过索引定位数据，仍然需要扫描很多记录。 数据库的运维问题。如果在代码中配置主库和从库host，系统运行当然也是没问题的。但这样大大增加了运维工作的压力，比如：MySQL数据库IO压力由于访问量的增加居高不下，DBA需要添加一台slave，这时候就不得不修改代码，然后打包并上线。 连接池。前端应用频繁连接MySQL，由此给MySQL带来的额外性能消耗也是不容忽视的。如果通过增加一个连接池，每个DB缓存一定数量的MySQL连接，当有应用需要连接后端的MySQL，直接从连接池里取出一个已建好的连接来发送SQL请求，这样会大大加快数据查询速度。而且可以降低MySQL的性能消耗。 SQL日志。在程序出现问题时，希望得到一些SQL日志，比如，什么时刻哪条SQL发送到哪一台DB上了。通过查看这种日志能够帮助快速定位问题。 主要功能 基础功能 支持SQL读写分离。 支持透明的MySQL连接池，不必每次新建连接。 支持平滑上线DB或下线DB，前端应用无感知。 支持多个slave，slave之间通过权值进行负载均衡。 支持强制读主库。 支持主流语言（java,php,python,C/C++,Go)SDK的mysql的prepare特性。 支持到后端DB的最大连接数限制。 支持SQL日志及慢日志输出。 支持SQL黑名单机制。 支持客户端IP访问白名单机制，只有白名单中的IP才能访问kingshard。 支持字符集设置。 支持last_insert_id功能。 支持热加载配置文件，动态修改kingshard配置项（具体参考管理端命令）。 支持以Web API调用的方式管理kingshard。 支持多用户模式，不同用户之间的表是权限隔离的，互补感知。 sharding功能 支持按整数的hash和range分表方式。 支持按年、月、日维度的时间分表方式。 支持跨节点分表，子表可以分布在不同的节点。 支持跨节点的count,sum,max和min等聚合函数。 支持单个分表的join操作，即支持分表和另一张不分表的join操作。 支持跨节点的order by,group by,limit等操作。 支持将sql发送到特定的节点执行。 支持在单个节点上执行事务，不支持跨多节点的分布式事务。 支持非事务方式更新（insert,delete,update,replace）多个node上的子表。 工作流程 读取配置文件并启动，在配置文件中设置的监听端口监听客户端请求。 收到客户端连接请求后，启动一个goroutine单独处理该请求。 首选进行登录验证，验证过程完全兼容MySQL认证协议，由于用户名和密码在配置文件中已经设置好，所以可以利用该信息验证连接请求是否合法。 当用户名和密码都正确时，转入下面的步骤，否则返回出错信息给客户端。 认证通过后，客户端发送SQL语句。 kingshard对客户端发送过来的SQL语句，进行词法和语义分析，识别出SQL的类型和生成SQL的路由计划。如果有必要还会改写SQL，然后转发到相应的DB。也有可能不做词法和语义分析直接转发到相应的后端DB。如果转发SQL是分表且跨多个DB，则每个DB对应启动一个goroutine发送SQL和接收该DB返回的结果。 接收并合并结果，然后转发给客户端。 优势和特点 可以轻松地应对mysql扩容和缩容。由于kingshard的采用了两级映射的分表方案 ，相对于其他开源Proxy，在扩容和缩容方面有很大的优势。 kingshard的安装和使用不依赖于其他第三方组件，这样使得kingshard更容易部署和使用。 kingshard在降低管理和运维后端DB方面 5.MaxScale MaxScale是MariaDB开发的一个数据库智能代理服务，一直看好的开源数据库MariaDB的又一利器。MaxScale允许根据数据库 SQL 语句将请求转向目标一个到多个服务器，可设定各种复杂程度的转向规则。MaxScale 设计用于透明的提供数据库的负载均衡和高可用性，同时提供高度可伸缩和灵活的架构，支持不同的协议和路由决策。简单的讲就是使用MaxScale可以轻松解决mariaDB读写分离的问题。 另外，MaxScale是插件式结构，允许用户开发适合自己的插件。 MaxScale的基础组成 认证插件：提供了登录认证功能，MaxScale 会读取并缓存数据库中 user 表中的信息，当有连接进来时，先从缓存信息中进行验证，如果没有此用户，会从后端数据库中更新信息，再次进行验证 协议插件：包括客户端连接协议，和连接数据库的协议 路由插件：决定如何把客户端的请求转发给后端数据库服务器，读写分离和负载均衡的功能就是由这个模块实现的 监控插件：对各个数据库服务器进行监控，例如发现某个数据库服务器响应很慢，那么就不向其转发请求了 日志和过滤插件：提供简单的数据库防火墙功能，可以对SQL进行过滤和容错 6.OneProxy 官网：http://www.onexsoft.com/proxy.html 介绍： 摘自官网： MySQL的逻辑复制技术可轻松构建多个数据副本来提供服务，并可以消除数据库单点，但需要应用作出相应的代码调整，才能充分利用它的优势。而网络交换机/路由器在理解TCP协议和目的IP地址的情况下，可以帮助人们轻松地组建大大小小的网络， OneProxy for MySQL在理解MySQL通信协议和SQL语句分析的基础上，可以帮助轻松组建数据库集群，避免代价昂贵的应用代码调整。 OneProxy for MySQL可以复用不同应用到后端数据库的连接，有效降低数据库的并发连接数；可以即时踢除不可用的节点，将应用请求转发到其他可用节点，保证业务服务的稳定性。 可透明地将查询语句分发到多个MySQL备库执行，用读写分离方案支持上千万的并发访问；也可以根据SQL语句中的值进行分库分表路由， 均匀分散到多个MySQL主库上，以支持每秒上百万个小事务的并发执行；可实时透明地分析流量数据，统计SQL和事务的运行时间，分析事务的结构，得到各种不同维度的实时性能报告； 还可以进行流理QoS控制，作为数据库防火墙抵挡SQL注入式攻击；根据分片的SQL并行执行，解决了大数据量下的汇总统计性能问题；跨多分片的结果集合并， 极大地简化了应用程序的开发工作量。 OneProxy for MySQL使用C&C++开发，充分利用高性能的异步网络事件编程框架，使单个OneProxy实例可支持高达40W的QPS/TPS；并可充分利用和管理内存，无Java类语言的内存回收问题，确保7x24的稳定性； 内置的守护进程模式和HA VIP机制，可以轻松实现Proxy的多机高可用；平民软件完全自主编写源代码，可以迅速分析和解决运行过程中的可能遇到的问题和故障；并可配合Galera Cluster或MySQL Group Replication 集群技术实现故障的快速切换。 功能及限制： 1.透明连接池： 不支持使用“use”命令来切换当前数据库， 出于性能考虑，我们不想在每次取得连接或归还连接时进行还原，这个操作需要一次额外的网络IO；如果要访问不同数据库下的表，请使用不同的用户进行连接（不同用户可提定不同的默认数据库），或者在表名前面加上库名进行访问（比如：db.tablename）。 不支持set命令，但除“set autocommit={0|1}”外，因为这些操作会影响会话的上下文，除非放在事务中（由开发人员自己负责）。 不支持带传出参数的存贮过程调用，实际上是通过执行几句“SET”语句来声明会话级变量，以进行参数传递的，如果不在一个事务中，则不同的调用就不能保证使用的是同一个连接了（除非放在事务中），故而OneProxy默认禁止存贮过程调用。 不支持客户端级别和服务器端级别的Prepared接口，因为绑定变量及语句都是会话级别的。请不用担心，MySQL JDBC驱动本身就不是真正的Prepared接口的（除非显式指定了“useServerPrepStmts”参数）；针对PHP PDO编程接口，请在连接数据库时指定“ATTR_EMULATE_PREPARES”选项，使用拼接SQL的方式进行底层交互（并不会影响安全性，增加SQL注放攻击的概率）。对于Web应用来讲连接池相对更重要，并且使用真正的Prepared接口需要更多的网络调用来完成一个SQL来回，并不利于性能。 2.自动故障切换 3.读写分离 4.水平分库分表 不支持多列分区，分区键只支持单个列，分区和子分区的列可以不同。这个限制可以让中间件的分区定位代码更加高效。 分区键的值必须是常量，在SQL中为分区键指定值是必须是明确的值，不能是函数或表达式。 分区键不支持OR语句，其允许单值查找（“where pkey = xxx”），可以是多值列表比较（“where pkey in (1,2,3)”），或区间查找（“where pkey >; … and pkey & 分区键不允许为空，并且不应当被程序后续更新， OneProxy无法检测出更新后的目标值是否符合分区配置，也不支持分区之间的记录移动。 对于“insert”和“replace”语句，请显式指定字段列表，例如：“insert into xxx (col1, col2,…) values (…,…)”。 分区键类型可以是“int”、 “char”、 “date”或“timestamp”中的一种，其中“date”表示不含时间信息的日期（如“2015-11-11”），而“timestamp”表示带时间的日期（如“2015-11-11 00:00:00”）。 5.结果集合并 临时结果集有大小限制，目前是100万行，以避免用完内存，可以通过“proxy-cache-rows”选项进行调整。 不支持count distinct，对某个字段统计维一值个数（“count(distinct …)”）的操作。 不支持avg，对字段求平均值（”avg(…)”）不被直接支持，请转换成计数（“count(…)”）和求和（“sum(…)”）两个操作，再作除法。 不支持having不支持分组汇总下的“having xxx”条件过滤。 不支持跨实例join。 跨库关联查询，仅仅支持按相同维度分表的分表。 6.并行查询 仅支持拆分的表 7.安全控制和SQL审计 8.SQL防火墙 9.OneProxy自身高可用 需要依赖VIP 10.分布式sequence 11.SQL关联度分析 12.事务监控　 开发注意事项：（别人的总结，网上找的，和上面类似） 不支持 Server Side Cursor 接口，比如 mysql C API 里的 Prepare、Bind、 Execute调用接口 不支持 use命令切换数据库 默认禁止 CALL, PREPARE, EXECUTE, DEALLOCATE 命令，也就是说不能用存储过程 单库（单实例）分表–insert/update/delete要加字段名，如insert into t1(id,name) values(1,’张三’); 单库（单实例）分表–目前分了N张表，如果以自增id做关联查询，那么每张表的自增id都是从1开始，在与其他表join关联查询时，数据会不准确 单库（单实例）分表–当where条件有分区列时，值不能有函数转换，也不能有算术表达式，必须是原子值，否则结果不准确 分库分表（多实例）–不支持垮库join，例如user_0表在10.0.0.1机器里，现在要join关联查询10.0.0.2机器里的money_detail表，不支持 分库分表（多实例）–不支持分布式事务，例如user_0表在10.0.0.1机器里，user_1表在10.0.0.2机器里，现在想同时update更新两张表，不支持 读写分离 –默认读操作全部访问slave，如果想强制走主库，例如涉及金钱类的查询操作，SQL改为select /master/ from t1 where id=1; 分库分表/分表 –where条件带分区列时，直接命中该表，如果未带分区列，会逐一扫描所有分表（单线程），考虑性能问题，要加并行查询（多线程），SQL改为select /parallel/ from t1 where name=’李四’; 并行查询会增加额外的CPU消耗 分表规则：支持range（范围）,hash（取模）,hash规则要提前规划好，具体分多少张表，如前期分64张表，1年后想扩容128张表，数据需要重新导出导入，成本非常高，目前二级分表还不支持。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2019-01-21 18:02:11 "},"20.performance.html":{"url":"20.performance.html","title":"20.优化","keywords":"","body":" 一、性能诊断方法论 1、性能问题 2、解决方案 2.1 测量任务所花费的时间 2.2 对结果进行统计和排序，将重要的任务排到前面 3、对应用程序进行性能剖析 3.1 影响因素 3.2 工具 4、剖析MySQL查询 4.1 剖析服务器负载 4.2 剖析单条查询 4.3 使用性能剖析 5、诊断间歇性问题 5.1 单条查询问题还是服务器问题 5.2 捕获诊断数据 6、其他剖析工具 二、优化方向 1. 服务器及OS优化 1.1 文件系统 1.2 内核参数 1.3 硬件提升 1.4 my.cnf启动顺序 2. MySQL参数调整 2.1 内存参数 2.2 事务日志相关 2.3 IO参数 2.4 其他参数 2.5 最重要的参数选项调整建议 3. SQL优化 4. 表架构优化 4.1 选择优化的数据类型 4.2 表设计原则 4.3 表的范式优化 4.4 表的反范式优化 4.5 数据库表的垂直拆分 4.6 数据库表的水平拆分 5. 索引优化 5.1 如何选择合适的列建立索引 5.2 索引优化SQL的方法 5.3 索引维护的方法 6.管理维护方向的优化 一、性能诊断方法论 1、性能问题 如何确认服务器是否达到了性能最佳状态 找出某条语句为什么执行不够快 卡死等某些间歇性疑难故障 周期性变化还是偶尔 检查mysql的io和cpu利用比例 效果 -------------------------> 硬件、系统配置、数据库表结构、索引 2、解决方案 2.1 测量任务所花费的时间 执行时间 服务器需要做大量的工作，从而导致大量消耗CPU 可以参考 Percona Toolkit中的pt-collect 等待时间 在等待某些资源被释放 GDB的堆栈跟踪 pt-pmp剖析器2.2 对结果进行统计和排序，将重要的任务排到前面 3、对应用程序进行性能剖析 3.1 影响因素 外部资源，比如调用了外部的Web服务或搜索引擎 应用需要处理大量的数据，比如分析一个超大的XML文件 在循环中执行昂贵操作，比如滥用正则 使用了低效算法，比如暴力搜索算法3.2 工具 New Relic的软件即服务(software-as-a-service)产品4、剖析MySQL查询 4.1 剖析服务器负载 捕获查询到日志文件中 分析查询日志4.2 剖析单条查询 使用 show profile测量耗费时间和查询执行状态变更相关数据 使用慢查询日志 使用Performance Schema 使用 show status4.3 使用性能剖析 5、诊断间歇性问题 5.1 单条查询问题还是服务器问题 使用show global status 使用show processlist 使用查询日志5.2 捕获诊断数据 5.2.1 一个可靠且实时的触发器，就是什么时候问题会出现 可以使用工具 Percona Toolkit的pt-stalk5.2.2 收集什么样的数据 系统状态 CPU利用率 磁盘使用率和可用空间 ps的输出采样 内存利用率5.2.3 解释结果数据 检查问题是否真的发生了，避免误报 是否有非常明显的跳跃性变化 将Percona Toolkit中pt-mysql-summary和pt-summary的输出结果打包，用pt-sift快速检查收集到的样本数据 什么导致资源性能低下 资源过度使用，余量不足以正常工作 资源没有被正确配置 资源已经损坏或者失灵6、其他剖析工具 使用USER_STATISTICS表 可以查找使用得最多或者使用得最少的表和索引 可以查找出从未使用的索引，可以考虑删除之 可以看看复制用户的CONNECTED_TIME和BUSY_TIME，以确认复制是否会很难跟上主库的进度 使用strace 调查系统调用情况 二、优化方向 1. 服务器及OS优化 1.1 文件系统 文件数限制: /etc/security/limit.conf soft nofile 65535 hard nofile 65535 磁盘调度策略: /sys/block/devname/queue/scheduler 使用deadline/noop这两种I/O调度器，千万别用cfq（它不适合跑DB类服务）； echo deadline > /sys/block/devname/queue/scheduler 使用xfs文件系统，千万别用ext3；ext4勉强可用，但业务量很大的话，则一定要用xfs； ext4 echo '/dev/sda1/ext4 native,nodiratime,data=writeback 1 1' >> /etc/fstab 文件系统mount参数中增加：noatime, nodiratime, nobarrier几个选项（nobarrier是xfs文件系统特有的）； 1.2 内核参数 修改/etc/sysctl.conf 增加tcp支持的队列数 net.ipv4.tcp_max_syn_backlog = 65535 减少断开连接时，资源回收 net.ipv4.tcp_max_tw_backets = 8000 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 10 将vm.swappiness设置为5-10左右即可，甚至设置为0（RHEL 7以上则慎重设置为0，除非你允许OOM kill发生），以降低使用SWAP的机会； vm.dirty_background_ratio设置为5-10，将vm.dirty_ratio设置为它的两倍左右，以确保能持续将脏数据刷新到磁盘，避免瞬间I/O写，产生严重等待（和MySQL中的innodb_max_dirty_pages_pct类似）； 将net.ipv4.tcp_tw_recycle、net.ipv4.tcp_tw_reuse都设置为1，减少TIME_WAIT，提高TCP效率； 另外，可以参考Oracle的内核参数的调整 fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 #kernel.shmmax = 4398046511104 //一般设置为系统内存75%单位是字节 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048586 1.3 硬件提升 BIOS的调整 选择Performance Per Watt Optimized(DAPC)模式，发挥CPU最大性能，跑DB这种通常需要高运算量的服务就不要考虑节电了； 关闭C1E和C States等选项，目的也是为了提升CPU效率； Memory Frequency（内存频率）选择Maximum Performance（最佳性能）； 内存设置菜单中，启用Node Interleaving，避免NUMA问题； CPU 非计算密集型 - 多核 计算密集型 - 高频 如何选择CPU MySQL 有一些工作只能使用到单核CPU MySQL 对CPU多核的支持并不是核数越多就越快 内存 磁盘 使用SSD或者PCIe SSD设备，至少获得数百倍甚至万倍的IOPS提升； 购置阵列卡同时配备CACHE及BBU模块，可明显提升IOPS（主要是指机械盘，SSD或PCIe SSD除外。同时需要定期检查CACHE及BBU模块的健康状况，确保意外时不至于丢失数据）； 有阵列卡时，设置阵列写策略为WB，甚至FORCE WB（若有双电保护，或对数据安全性要求不是特别高的话），严禁使用WT策略。并且闭阵列预读策略，基本上是鸡肋，用处不大； 尽可能选用RAID-10，而非RAID-5； 使用机械盘的话，尽可能选择高转速的，例如选用15KRPM，而不是7.2KRPM的盘，不差几个钱的； 常用RAID级别简介 RAID0: 也称为条带，就是把多个磁盘链接为一个磁盘使用，这个级别IO最好 RAID1: 也称为镜像，要求至少两个硬盘，第个磁盘的数据都是一样的 RAID5: 也是把多个磁盘当作一个磁盘使用，至少3块硬盘，数据读写时会建立奇偶校验信息，并且奇偶检验信息和相对应的数据分别存储于不同的磁盘上，当RAID5的一个磁盘数据发生损坏时，利用剩下的数据和相应的奇偶检验信息去恢复被损坏的数据是完全没有问题的 推荐使用RAID1+0：就是RAID1和RAID0的结合，同时具备两个级别的优缺点。一般建议数据库使用这个级别 网络 万兆网卡 1.4 my.cnf启动顺序 注意：如果多个位置存在 配置文件，则后面的会覆盖前面的 [root@nazeebodan ~]# mysqld --verbose --help | grep -A 1 'Default options' Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf 2. MySQL参数调整 2.1 内存参数 线程独享 sort_buffer_size join_buffer_size read_buffer_size read_rnd_buffer_size 线程共享 innodb_buffer_pool_size key_buffer_size tmp_table_size max_head_table_size 2.2 事务日志相关 innodb_log_file_size innodb_log_files_in_group innodb_log_buffer_size innodb_flush_log_at_trx_commit 2.3 IO参数 innodb_flush_method = O_DIRECT innodb_file_per_table = 1 innodb_doublewrite = 1 delay_key_write innodb_read_io_threads innodb_read_io_threads innodb_io_capacity innodb_flush_neighbors sync_binlog 2.4 其他参数 expire_logs_days max_allowed_packet skip_name_resolve read_only skip_slave_start sql_mode max_connections 2.5 最重要的参数选项调整建议 选择Percona或MariaDB版本的话，强烈建议启用thread pool特性，可使得在高并发的情况下，性能不会发生大幅下降。此外，还有extra_port功能，非常实用， 关键时刻能救命的。还有另外一个重要特色是 QUERY_RESPONSE_TIME 功能，也能使我们对整体的SQL响应时间分布有直观感受； 设置default-storage-engine=InnoDB，也就是默认采用InnoDB引擎，强烈建议不要再使用MyISAM引擎了，InnoDB引擎绝对可以满足99%以上的业务场景； 调整innodb_buffer_pool_size大小，如果是单实例且绝大多数是InnoDB引擎表的话，可考虑设置为物理内存的50% ~ 90%左右； 根据实际需要设置innodb_flush_log_at_trx_commit、sync_binlog的值。如果要求数据不能丢失，那么两个都设为1。如果允许丢失一点数据，则可分别设为2和10。而如果完全不用care数据是否丢失的话（例如在slave上，反正大不了重做一次），则可都设为0。这三种设置值导致数据库的性能受到影响程度分别是：高、中、低，也就是第一个会另数据库最慢，最后一个则相反； 设置innodb_file_per_table = 1，使用独立表空间，我实在是想不出来用共享表空间有什么好处了； 设置innodb_data_file_path = ibdata1:1G:autoextend，千万不要用默认的10M，否则在有高并发事务时，会受到不小的影响； 设置innodb_log_file_size=256M，设置innodb_log_files_in_group=2，基本可满足90%以上的场景； 设置long_query_time = 1，而在5.5版本以上，已经可以设置为小于1了，建议设置为0.05（50毫秒），记录那些执行较慢的SQL，用于后续的分析排查； 根据业务实际需要，适当调整max_connection（最大连接数）、max_connection_error（最大错误数，建议设置为10万以上，而open_files_limit、innodb_open_files、table_open_cache、table_definition_cache这几个参数则可设为约10倍于max_connection的大小； 常见的误区是把tmp_table_size和max_heap_table_size设置的比较大，曾经见过设置为1G的，这2个选项是每个连接会话都会分配的，因此不要设置过大，否则容易导致OOM发生；其他的一些连接会话级选项例如：sort_buffer_size、join_buffer_size、read_buffer_size、read_rnd_buffer_size等，也需要注意不能设置过大； 由于已经建议不再使用MyISAM引擎了，因此可以把key_buffer_size设置为32M左右，并且强烈建议关闭query cache功能； 3. SQL优化 SQL优化内容较多，单独一章 4. 表架构优化 4.1 选择优化的数据类型 数据类型的选择重点在于合适二字，如何确定选择的数据类型是否合适？ 使用可以存下你的数据的最小的数据类型 使用简单的数据类型。int要比varchar类型处理更加简单 尽可能的使用not null定义字段 尽量少使用text类型，非用不可时最好考虑分表 4.1.1 浮点类型 精确 DECIMAL MySQL自身实现，运算较慢 不精确 DOUBLE、FLOAT CPU直接支持，运算较快 提升效率方法 在数据量较大时，使用BIGINT代替DECIMAL。乘以相应倍数即可。 *4.1.2 VARCHAR和CHAR类型 VARCHAR 字符串列的最大长度比平均长度大很多 列的更新很少，所以碎片不是问题 使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储 CHAR 存储很短的字符串 经常变更4.1.3 BLOB和TEXT类型 存储类型 是否有排序规则和字符集 BLOB 二进制 否 TEXT 字符 是 4.1.4 使用枚举代替字符串类型 优点 ENUM和ENUM关联会很快 缺点 避免使用数字作为枚举常量，双重性容易导致混乱 字符串列表是固定的，添加或删除字符串必须使用ALTER TABLE 4.2 表设计原则 更小的通常更好 字段长度满足需求前提下，尽可能选择长度小的。此外，字段属性尽量都加上NOT NULL约束，可一定程度提高性能 简单就好 尽可能不使用TEXT/BLOB类型，确实需要的话，建议拆分到子表中，不要和主表放在一起，避免SELECT * 的时候读性能太差。 读取数据时，只选取所需要的列，不要每次都SELECT *，避免产生严重的随机读问题，尤其是读到一些TEXT/BLOB列； 尽量避免NULL 查询越频繁的表应该设计越简单 查询越频繁的关联表应该多考虑冗余 4.3 表的范式优化 范式化是指数据库设计的规范，目前说到范式化一般就是指第三设计模式，要求数据表中不存在非关键字段对任意候选关键字段的传递函数依赖规则符合第三范式 4.4 表的反范式优化 反范式化是指为了查询效率的考虑把原本符合第三范式的表适当的增加冗余，以达到优化查询效率的目的，反范式化是一种以空间换时间的操作 4.5 数据库表的垂直拆分 所谓垂直拆分，就是把原来一个有很多列的表拆分成多个表，这解决了表的宽度问题。 通常垂直拆分可以按以下几个原则进行： 把不常用的字段单独放到一个表中 把大字段独立存入到一个表中 把经常一起使用的字段放到一起 4.6 数据库表的水平拆分 5. 索引优化 5.1 如何选择合适的列建立索引 在where从句，group by从句，on 从句中出现的列 索引字段越小越好 离散度大的列放到联合索引的前面 5.2 索引优化SQL的方法 重复及冗余的索引 重复索引是指相同的列以相同顺序建立的同类型的索引，如下表中primary key和ID列上的索引就是重复索引 create table test( id int not null primary key, name varchar(10) not null, title varchar(50) not null, unique(id) ) engine = innodb; 推荐使用工具：pt-duplicate-key-checker 使用方法 pt-duplicate-key-checker -uroot -p123456 -p3306 -hnazeebo 复合索引 最常用的放在最前面，与where顺序无关 5.3 索引维护的方法 索引是不可更改的，想更改必须删除重新建 目前MySQL官方还没有记录索引使用情况的功能，但是在PerconMySQL和MariaDB中可以通过INDEX_STATISTICS表查看那些索引没有被使用，但是在MySQL中目前只能通过慢查询日志配合pt-index-usage工具来进行索引使用情况的分析 pt-index-usage -uroot -p'passwd' mysql-slow.log 6.管理维护方向的优化 通常地，单表物理大小不超过10GB，单表行数不超过1亿条，行平均长度不超过8KB，如果机器性能足够，这些数据量MySQL是完全能处理的过来的，不用担心性能问题，这么建议主要是考虑ONLINE DDL的代价较高； 不用太担心mysqld进程占用太多内存，只要不发生OOM kill和用到大量的SWAP都还好； 在以往，单机上跑多实例的目的是能最大化利用计算资源，如果单实例已经能耗尽大部分计算资源的话，就没必要再跑多实例了； 定期使用pt-duplicate-key-checker检查并删除重复的索引 定期使用pt-index-usage工具检查并删除使用频率很低的索引； 定期采集slow query log，用pt-query-digest工具进行分析，可结合Anemometer系统进行slow query管理以便分析slow query并进行后续优化工作； 可使用pt-kill杀掉超长时间的SQL请求，Percona版本中有个选项 innodb_kill_idle_transaction也可实现该功能； 使用pt-online-schema-change来完成大表的ONLINE DDL需求； 定期使用pt-table-checksum、pt-table-sync来检查并修复mysql主从复制的数据差异； Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 07:07:29 "},"21.sqltunning.html":{"url":"21.sqltunning.html","title":"21.SQL优化","keywords":"","body":" 一、查询SQL执行流程 二、相关工具 三、SQL查询分析器explain使用说明 四、优化方向 1.limit优化 2.查询缓存 3.join优化 4.排序优化 5.子查询优化 6.其他： 一、查询SQL执行流程 1.DB客户端发送SQL请求给DB服务端 2.DB服务端检查是否可以在查询缓存(QC)中命中 3.DB服务端进行SQL解析,预处理,再由优化器生成对应的执行计划 4.DB服务端Server层根据执行计划,调用存储引擎API来查询数据 5.DB服务端Server层将结果返回给客户端 二、相关工具 慢查询日志: slow.log 慢查询日志分析: pt-query-digest SQL执行计划分析: explain SQL耗时分析: show profile 三、SQL查询分析器explain使用说明 select_type simple，没有union或子查询 primary，嵌套中最外层 union/union result/dependent union/dependent union derived 衍生，导出，子查询产生临时表 subquery 子查询第一个select语句 type const，最多一条，system 特例仅有一条 eq_ref，一种索引访问，仅返回1条，且索引为unique，primary ref，返回多条，索引的是最左前缀，可以用于=<> ref_or_null, 针对null index_merger，索引合并优化 5.1以后支持的，一个表可以使用多个索引 index intersect unique_subquery，替换in子查询 index_subquery 替换in子查询 range，用index检索范围的行 index，全扫描索引 ALL Extra Using filesort 看到这个的时候，查询就需要优化了，MySQL需要进行额外的步骤来发现如何对返回的数据进行排序，它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行 Using temporary 看到这个说也说明查询需要优化了，这里MySQL需要创建一个临时的表来存储结果，这通常发生在对不同的列集进行order by上，而不是group by上 count()和max()函数的优化 Not exists Using index Using index condition Using where possible_keys key 实际使用的索引 key_len，key的长度 ref 使用哪个列与key一起选择行 key_len 使用索引的长度，在不丢失精度的前提下，长度越短越好 ref 显示索引的那一列被使用了，如果可能的话，是一个常数 rows MySQL认为必须检查的，用来返回请求数的行数 四、优化方向 1.limit优化 当与order by 字段联合使用时，若排序字段有重复，需要增加排序列，否则数据会错 limit通常用于分布处理，时常会伴随order by从句使用，因此大多时候会使用filesort，这样会造成大量的IO问题 2.查询缓存 建议关闭查询缓存，使用redis等nosql来代替 3.join优化 确保on和using字句有索引，考虑关联顺序 索引where和排序冲突的时候，改成关联表方式或者子查询 mysql5.6之前的一般需要改子查询为关联表 走索引不一定都快，区分度不够的索引可用考虑用复合索引 多值 max，改为group后max join 时要考虑类型一致，char型要考虑字符集一致，时间类型没走索引，要注意隐世转换 select in 会被改写为exists，造成查询缓慢，可改成关联join查询 驱动表的选择，认清关联字段索引，可用straight_join验证猜想 query cache并不适合更新，插入，删除非常大的应用 group by，order by 只涉及表中一个列 order by +limit 将limit，order by内嵌，限制join数量和保证index排序 join时 尽量将条件内嵌，先过滤后join。 知道仅有一条时，用limit 1 限制 not in或not exits 可转换为外连接或等值连接 某些情况下 or 可用用union all 或union 代替 4.排序优化 单表查询，若file sort 则可以用强制使用索引排序，或者用自关联方式 需要where+sort 或者多个sort 做联合索引，并考虑加上排序 sort buffer 与group by 连用时 用order by null 禁用排序 别名 若和字段重复也会影响排序优化 索引长度导致不能优化 相关参数 A. sort_buffer_size 排序缓存 B. read_rnd_buffer_size 第二次排序缓存 C. max_length_for_sort_data 带普通列的最大排序约束 file sort过程-普通&双路排序 取出字段a和每行的物理id（tid），然后在sort_buffer_size 中排序 根据排序好的tid从磁盘中拿到行数据，放到read_rnd_buffer_size中 file sort过程-冗余单路排序 区别是第一次是拿到所有相关数据而不只是TID，所以不用二次去磁盘取 file sort 优化 增加相关参数大小 增强tempdir 指向的文件系统io 5.子查询优化 通常情况下，需要把子查询优化为join查询，但是在优化时需要注意关键键是否有一对多的关系，需要注意重复数据 6.其他： 所有的InnoDB表都设计一个无业务用途的自增列做主键，对于绝大多数场景都是如此，真正纯只读用InnoDB表的并不多，真如此的话还不如用TokuDB来得划算； 字段长度满足需求前提下，尽可能选择长度小的。此外，字段属性尽量都加上NOT NULL约束，可一定程度提高性能； 尽可能不使用TEXT/BLOB类型，确实需要的话，建议拆分到子表中，不要和主表放在一起，避免SELECT * 的时候读性能太差。 读取数据时，只选取所需要的列，不要每次都SELECT *，避免产生严重的随机读问题，尤其是读到一些TEXT/BLOB列； 对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引； 通常情况下，子查询的性能比较差，建议改造成JOIN写法； 多表联接查询时，关联字段类型尽量一致，并且都要有索引； 多表连接查询时，把结果集小的表（注意，这里是指过滤后的结果集，不一定是全表数据量小的）作为驱动表； 多表联接并且有排序时，排序字段必须是驱动表里的，否则排序列无法用到索引； 多用复合索引，少用多个独立索引，尤其是一些基数（Cardinality）太小（比如说，该列的唯一值总数少于255）的列就不要创建独立索引了； 类似分页功能的SQL，建议先用主键关联，然后返回结果集，效率会高很多； Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:34:16 "},"22.mysqlfaq.html":{"url":"22.mysqlfaq.html","title":"22.MySQL_FAQ","keywords":"","body":" 1.恢复被误删的表 2.MySQL中为什么既有redo log又有binlog，二者的作用一致吗？ 3.新创建了一个用户 'xxx'@'%'为什么登不进去 4.修改lower_case_table_names 导致的drop database失败 问题分析 5.mysql 远程连接不上，由于bind-address问题 6.MySQL中GTID的create table xxx as select 限制和解决方案 7.找出锁等待 服务器级别的锁等待 存储引擎innodb中锁等待以及哪个线程持有锁 查询有多少查询被哪些线程阻塞 8.为什么InnoDB表要建议用自增列做主键 9.为什么生产上建议关闭query cache 10.processlist中哪些状态要引起关注 11.修改my.cnf配置不生效 问题 原因 12.如何将两个表名互换 13.Spring框架中调用存储过程失败 14.MySQL复制中slave延迟监控 1.恢复被误删的表 前提： mysql开启了bin log日志 1.找到bin log的位置 找到 最近被修改的bin log ：master-bin.00000xxx 如果误删除跨越了好几个binlog，那么找回数据的时候就必须一个个的binlog去找回了 2.将这一段时间所有执行的sql语句存入到 待恢复的 sql文件中。 mysqlbinlog --start-date='2017-07-28 19:00:00' --stop-date='2017-07-28 209:00:00' binlog的位置 > restore_20170728.sql 3. 新建一个临时库，在手工去掉 delete 语句之后 source 2.MySQL中为什么既有redo log又有binlog，二者的作用一致吗？ binlog 是Server层记录的日志，主要用于复制(replication)，记录的是DML操作的日志。 redo log是innodb存储引擎的日志，记录的也是DML操作的变化，但二者的格式不一样。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。 binlog适用于多个存储引擎，而redo/undo是innodb特有的。 顺便提一下，redo用于重做(保证事务的持久性)，undo用于回滚(保证事务的原子性)、mvcc，还有一句绕口的：undo 也会产生 redo 来保证undo log的可靠性。 3.新创建了一个用户 'xxx'@'%'为什么登不进去 [root@nazeebo softdb]# mysql -ubkadmin -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 1045 (28000): Access denied for user 'bkadmin'@'localhost' (using password: YES) [root@nazeebo softdb]# mysql -uroot -p123456 mysql> select Host,user from mysql.user; +-------------+-------------------+ | Host | user | +-------------+-------------------+ | % | bkadmin | | % | nainai | | % | root | | % | select_role_group | | % | sure | | % | system | | % | yeye | | 127.0.0.1 | nazeebo | | 127.0.0.1 | root | | 192.168.0.% | lowa | | ::1 | root | | localhost | | | localhost | mysql.session | | localhost | mysql.sys | | localhost | root | | nazeebo | | | nazeebo | root | +-------------+-------------------+ drop 掉 ''@'localhost'可以正常登入 mysql> drop user ''@'localhost'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) [root@nazeebo softdb]# mysql -ubkadmin -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 56 Server version: 5.7.22-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> 4.修改lower_case_table_names 导致的drop database失败 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sbtest | | sys | | test | | test_lowa | | tpcc1 | +--------------------+ 9 rows in set (0.00 sec) mysql> drop database tpcc1; ERROR 1010 (HY000): Error dropping database (can't rmdir './tpcc1', errno: 39) 问题分析 mysqld 在执行 drop database 操作的时候，是调用 mysql_rm_db 这个函数，在删除时先把db下的所有表都删掉，然后再把db删掉。为了找出对应db下的所有表，mysqld 是通过遍历数据库目录下的文件来做的，具体是用 find_db_tables_and_rm_known_files 这个函数，遍历数据库目录下的所有文件，然后构造出要 drop 的table列表，然而在构造删除列表过程中，会有这样一个判断: if (lower_case_table_names) table_list->table_name_length= my_casedn_str(files_charset_info, table_list->table_name); 意思就是如果lower_case_table_names非0的话，就把 table_name 转成小写的， 在list表都删除完后，调用rm_dir_w_symlink来删除db目录，此时tpcc目录下还有对应的文件，这个函数会调用系统的 rmdir 函数，而当目录非空的时候，rmdir是执行失败的。 所以我们看到最终的错误提示 Error dropping database (can't rmdir './db1', errno: 39) 5.mysql 远程连接不上，由于bind-address问题 刚安装了mysql服务器，使用远程管理工具总是连接不上 还是连接不上，于是怀疑是防火墙问题，便将防火墙关service iptables stop 再次telnet，还是没办法连上这个端口，然后通过netstat查看3306的端口状态是怎么样的 netstat -apn|grep 3360 tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN 3783/mysqld 终于发现了一个比较奇怪的东西，注意127.0.0.1:3306这一列。监听端口正常，但却绑定了本地回旋地址，难怪总是连接不上。 修改mysql的配置文件/etc/my.conf，将bind-address后面增加远程访问IP地址或者禁掉这句话就可以让远程机登陆访问了。 修改参数后要重启mysql服务service mysql restart 6.MySQL中GTID的create table xxx as select 限制和解决方案 比如MySQL GTID在5.6试水，5.7已经发展完善，但是还是有一些场景是受限的。比如最常用的一个语句： create table xxx as select 的模式 GTID中create 语句限制的解法： create table xxx as select的语句，其实会被拆分为两部分，create语句和insert语句，但是如果想一次搞定，MySQL会抛出如下的错误。 mysql> create table test_new as select *from test; ERROR 1786 (HY000): Statement violates GTID consistency: CREATE TABLE ... SELECT. 一个方法是MySQL特有的用法 like！ create table xxx as select的方式会被拆分成两部分。 create table xxxx like data_mgr; + insert into xxxx select *from data_mgr; 7.找出锁等待 服务器级别的锁等待 可以通过show processlist看到等待锁的线程id，但是无法知道究竟哪个线程持有锁 可以通过mysqladmin debug 相关等待锁的线程以及谁持有锁可以在错误日志中找到 存储引擎innodb中锁等待以及哪个线程持有锁 SELECT r.trx_id AS waiting_trx_id, r.trx_mysql_thread_id AS waiting_thread, TIMESTAMPDIFF(SECOND, r.trx_wait_started, CURRENT_TIMESTAMP) AS wait_time, r.trx_query AS waiting_query, l.lock_table AS waiting_table_lock, b.trx_id AS blocking_trx_id, b.trx_mysql_thread_id AS blocking_thread, SUBSTRING(p.host,1,INSTR(p.host, ':') -1 ) AS blocking_host, SUBSTRING(p.host, INSTR(p.host, ':') +1 ) AS block_port, IF(p.command=\"Sleep\",p.time,0) AS idle_in_trx, b.trx_query AS blcoking_query from information_schema.innodb_lock_waits AS w INNER JOIN information_schema.innodb_trx AS b ON b.trx_id=w.blocking_trx_id INNER JOIN information_schema.innodb_trx AS r ON r.trx_id = w.requesting_trx_id INNER JOIN information_schema.innodb_locks AS l ON w.requested_lock_id = l.lock_id LEFT JOIN information_schema.processlist AS p ON p.id = b.trx_mysql_thread_id ORDER BY wait_time DESC\\G 查询有多少查询被哪些线程阻塞 如果因为线程在一个事务中空闲而正在遭受大量的锁操作，下面查询显示存储引擎层有多少查询被哪些线程阻塞。 SELECT CONCAT('thread ', b.trx_mysql_thread_id, ' from ',p.host) AS who_blocks, IF (p.command = \"Sleep\",p.time, 0) AS idle_in_trx, MAX(TIMESTAMPDIFF(SECOND,r.trx_wait_started,NOW())) AS max_wait_time, COUNT(*) AS num_waiters FROM information_schema.innodb_lock_waits as w inner join information_schema.innodb_trx as b on b.trx_id = w.blocking_trx_id inner join information_schema.innodb_trx as r on r.trx_id = w.requesting_trx_id left join information_schema.processlist as p on p.id = b.trx_mysql_thread_id group by who_blocks order by num_waiters desc\\G 8.为什么InnoDB表要建议用自增列做主键 InnoDB引擎表的一些关键特征： InnoDB引擎表是基于B+树的索引组织表(IOT)； 每个表都需要有一个聚集索引(clustered index)； 所有的行记录都存储在B+树的叶子节点(leaf pages of the tree)； 基于聚集索引的增、删、改、查的效率相对是最高的； 如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择其作为聚集索引； 如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引； 如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。 综上总结，如果InnoDB表的数据写入顺序能和B+树索引的叶子节点顺序一致的话，这时候存取效率是最高的，也就是下面这几种情况的存取效率最高： 使用自增列(INT/BIGINT类型)做主键，这时候写入顺序是自增的，和B+数叶子节点分裂顺序一致； 该表不指定自增列做主键，同时也没有可以被选为主键的唯一索引(上面的条件)，这时候InnoDB会选择内置的ROWID作为主键，写入顺序和ROWID增长顺序一致； 除此以外，如果一个InnoDB表又没有显示主键，又有可以被选择为主键的唯一索引，但该唯一索引可能不是递增关系时(例如字符串、UUID、多字段联合唯一索引的情况)，该表的存取效率就会比较差。 实际情况是如何呢？经过简单TPCC基准测试，修改为使用自增列作为主键与原始表结构分别进行TPCC测试，前者的TpmC结果比后者高9%倍，足见使用自增列做InnoDB表主键的明显好处，其他更多不同场景下使用自增列的性能提升可以自行对比测试下。 9.为什么生产上建议关闭query cache Query Cache（查询缓存，以下简称QC）存储SELECT语句及其产生的数据结果，特别适用于：频繁提交同一个语句，并且该表数据变化不是很频繁的场景，例如一些静态页面，或者页面中的某块不经常发生变化的信息。QC有可能会从InnoDB Buffer Pool或者MyISAM key buffer里读取结果。 由于QC需要缓存最新数据结果，因此表数据发生任何变化（INSERT、UPDATE、DELETE或其他可能产生数据变化的操作），都会导致QC被刷新。 根据MySQL官方的测试，QC的优劣分别是： 1、如果对一个表执行简单的查询，但每次查询都不一样的话，打开QC后，性能反而下降了13%左右。但通常实际业务中，通常不会只有这种请求，因此实际影响应该比这个小一些。 2、如果对一个只有一行数据的表进行查询，则可以提升238%，这个效果还是非常不错的。 因此，如果是在一个更新频率非常低而只读查询频率非常高的场景下，打开QC还是比较有优势的，其他场景下，则不建议使用。而且，QC一般也维持在100MB以内就够了，没必要设置超过数百MB。 QC严格要求2次SQL请求要完全一样，包括SQL语句，连接的数据库、协议版本、字符集等因素都会影响，下面几个例子中的SQL会被认为是完全不一样而不会使用同一个QC内存块： mysql> set names latin1; SELECT * FROM table_name; mysql> set names latin1; select * from table_name; mysql> set names utf8; select * from table_name; 此外，QC也不适用于下面几个场景： 子查询或者外层查询； 存储过程、存储函数、触发器、event中调用的SQL，或者引用到这些结果的； 包含一些特殊函数时，例如：BENCHMARK()、CURDATE()、CURRENT_TIMESTAMP()、NOW()、RAND()、UUID()等等； 读取mysql、INFORMATION_SCHEMA、performance_schema 库数据的； 类似SELECT…LOCK IN SHARE MODE、SELECT…FOR UPDATE、SELECT..INTO OUTFILE/DUMPFILE、SELECT..WHRE…IS NULL等语句； SELECT执行计划用到临时表（TEMPORARY TABLE）； 未引用任何表的查询，例如 SELECT 1+1 这种； 产生了 warnings 的查询； SELECT语句里加了 SQL_NO_CACHE 关键字； 更加奇葩的是，MySQL在从QC中取回结果前，会先判断执行SQL的用户是否有全部库、表的SELECT权限，如果没有，则也不会使用QC。 相比下面这个，其实上面所说的都不重要。 最为重要的是，在MySQL里QC是由一个全局锁在控制，每次更新QC的内存块都需要进行锁定。 例如，一次查询结果是20KB，当前 query_cache_min_res_unit 值设置为 4KB（默认值就是4KB，可调整），那么么本次查询结果共需要分为5次写入QC，每次都要锁定，可见其成本有多高。 我们可以通过 PROFILING 功能来查看 QC 相关的一些锁竞争，例如像下面这样的： • Waiting for query cache lock • Waiting on query cache mutex 或者，也可以通过执行 SHOW PROCESSLIST 来看线程的状态，例如： checking privileges on cached query 检查用户是否有权限读取QC中的结果集 checking query cache for query 检查本次查询结果是否已经存储在QC中 invalidating query cache entries 由于相关表数据已经修改了，因此将QC中的内存记录被标记为失效 sending cached result to client 从QC中，将缓存后的结果返回给客户程序 storing result in query cache 将查询结果缓存到QC中 如果可以频繁看到上述几种状态，那么说明当前QC基本存在比较重的竞争。 以上那么多，总结一下其实核心要点就一个： 如果线上环境中99%以上都是只读，很少有更新，再考虑开启QC吧，否则，就别开了。 关闭方法很简单，有两种： 同时设置选项 query_cache_type = 0 和 query_cache_size = 0； 如果用源码编译MySQL的话，编译时增加参数 --without-query-cache 即可； 10.processlist中哪些状态要引起关注 状态 建议 copy to tmp table 执行ALTER TABLE修改表结构时建议：放在凌晨执行或者采用类似pt-osc工具 Copying to tmp table 拷贝数据到内存中的临时表，常见于GROUP BY操作时建议：创建适当的索引 Copying to tmp table on disk 临时结果集太大，内存中放不下，需要将内存中的临时表拷贝到磁盘上，形成 sql***.MYD、sql***.MYI（在5.6及更高的版本，临时表可以改成InnoDB引擎了，可以参考选项default_tmp_storage_engine）建议：创建适当的索引，并且适当加大sort_buffer_size/tmp_table_size/max_heap_table_size Creating sort index 当前的SELECT中需要用到临时表在进行ORDER BY排序建议：创建适当的索引 Creating tmp table 创建基于内存或磁盘的临时表，当从内存转成磁盘的临时表时，状态会变成：Copying to tmp table on disk建议：创建适当的索引，或者少用UNION、视图(VIEW)、子查询(SUBQUERY)之类的，确实需要用到临时表的时候，可以在session级临时适当调大 tmp_table_size/max_heap_table_size 的值 Reading from net 表示server端正通过网络读取客户端发送过来的请求建议：减小客户端发送数据包大小，提高网络带宽/质量 Sending data 从server端发送数据到客户端，也有可能是接收存储引擎层返回的数据，再发送给客户端，数据量很大时尤其经常能看见备注：Sending Data不是网络发送，是从硬盘读取，发送到网络是Writing to net(建议：通过索引或加上LIMIT，减少需要扫描并且发送给客户端的数据量) Sorting result 正在对结果进行排序，类似Creating sort index，不过是正常表，而不是在内存表中进行排序建议：创建适当的索引 statistics 进行数据统计以便解析执行计划，如果状态比较经常出现，有可能是磁盘IO性能很差建议：查看当前io性能状态，例如iowait Waiting for global read lock FLUSH TABLES WITH READ LOCK整等待全局读锁建议：不要对线上业务数据库加上全局读锁，通常是备份引起，可以放在业务低谷期间执行或者放在slave服务器上执行备份 Waiting for tables,Waiting for table flush FLUSH TABLES, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, OPTIMIZE TABLE等需要刷新表结构并重新打开建议：不要对线上业务数据库执行这些操作，可以放在业务低谷期间执行 Waiting for lock_type lock 等待各种类型的锁：• Waiting for event metadata lock• Waiting for global read lock • Waiting for schema metadata lock• Waiting for stored function metadata lock• Waiting for stored procedure metadata lock• Waiting for table level lock• Waiting for table metadata lock• Waiting for trigger metadata lock建议：比较常见的是上面提到的global read lock以及table metadata lock，建议不要对线上业务数据库执行这些操作，可以放在业务低谷期间执行。如果是table level lock，通常是因为还在使用MyISAM引擎表，赶紧转投InnoDB引擎吧，别再老顽固了 11.修改my.cnf配置不生效 问题 修改了 my.cnf 配置文件后，却不生效，这是怎么回事? 原因 我们注意到，这里只说了修改 my.cnf，并没有说清楚其绝对路径是哪个文件。也就是说，有可能修改的不是正确路径下的my.cnf文件。 在MySQL中，是允许存在多个 my.cnf 配置文件的，有的能对整个系统环境产生影响，例如：/etc/my.cnf。有的则只能影响个别用户，例如：~/.my.cnf。 MySQL读取各个my.cnf配置文件的先后顺序是： /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf 其他自定义路径下的my.cnf，例如：/data/mysql/yejr_3306/my.cnf 不管是mysqld服务器端程序，还是mysql客户端程序，都可以采用下面两个参数来自行指定要读取的配置文件路径： –defaults-file=#， 只读取指定的文件（不再读取其他配置文件） –defaults-extra-file=#， 从其他优先级更高的配置文件中读取全局配置后，再读取指定的配置文件（有些选项可以覆盖掉全局配置从的设定值） 因此，可以看到，如果修改的是非“著名”目录下的 my.cnf，有可能看起来是不生效的，需要自行指定，或者统一放在 /etc/my.cnf 下，采用多实例的方式来管理即可。 12.如何将两个表名互换 从MySQL手册里能找到方法：同时锁定2个表，不允许写入，然后对调表名。 LOCK TABLES t1 WRITE, t2 WRITE; ALTER TABLE t1 RENAME TO t3; ALTER TABLE t2 RENAME TO t1; ALTER TABLE t3 RENAME TO t2; UNLOCK TABLES; 13.Spring框架中调用存储过程失败 Spring框架中，调用存储过程同时还需要show create procedure权限，对于普通用户而言，还要授予 select on mysql.proc 权限才能正常 14.MySQL复制中slave延迟监控 在MySQL复制环境中，我们通常只根据 Seconds_Behind_Master 的值来判断SLAVE的延迟。这么做大部分情况下尚可接受，但并不够准确，而应该考虑更多因素。 首先，我们先看下SLAVE的状态： mysql> show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event *** Master_Log_File: mysql-bin.000327 Read_Master_Log_Pos: 668711237 Relay_Log_File: mysql-relay-bin.002999 Relay_Log_Pos: 214736858 Relay_Master_Log_File: mysql-bin.000327 Slave_IO_Running: Yes Slave_SQL_Running: Yes *** Skip_Counter: 0 Exec_Master_Log_Pos: 654409041 Relay_Log_Space: 229039311 *** Seconds_Behind_Master: 3296 *** 可以看到 Seconds_Behind_Master 的值是 3296，也就是SLAVE至少延迟了 3296 秒。 再来看下SLAVE上的2个REPLICATION进程状态： mysql> show full processlist\\G *************************** 1. row *************************** Id: 6 User: system user Host: db: NULL Command: Connect Time: 22005006 State: Waiting for master to send event Info: NULL *************************** 2. row *************************** Id: 7 User: system user Host: db: NULL Command: Connect Time: 3293 State: Updating Info: UPDATE ** SET ** WHERE ** 可以看到SQL线程一直在执行UPDATE操作，注意到 Time 的值是 3293，看起来像是这个UPDATE操作执行了3293秒，一个普通的SQL而已，肯定不至于需要这么久。 实际上，在REPLICATION进程中，Time 这列的值可能有几种情况： SQL线程当前执行的binlog（实际上是relay log）中的timestamp和IO线程最新的timestamp的差值，这就是通常大家认为的 Seconds_Behind_Master 值，并不是某个SQL的实际执行耗时； SQL线程当前如果没有活跃SQL在执行的话，Time值就是SQL线程的idle time； 而IO线程的Time值则是该线程自从启动以来的总时长（多少秒），如果系统时间在IO线程启动后发生修改的话，可能会导致该Time值异常，比如变成负数，或者非常大。 来看下面几个状态： #设置pager，只查看关注的几个status值 mysql> pager cat | egrep -i 'system user|Exec_Master_Log_Pos|Seconds_Behind_Master|Read_Master_Log_Pos' #这是没有活跃SQL的情况，Time值是idle time，并且 Seconds_Behind_Master 为 0 mysql> show processlist; show slave status\\G | 6 | system user | | NULL | Connect | 22004245 | Waiting for master to send event | NULL | | 7 | system user | | NULL | Connect | 13 | Has read all relay log;** Read_Master_Log_Pos: 445167889 Exec_Master_Log_Pos: 445167889 Seconds_Behind_Master: 0 #和上面一样 mysql> show processlist; show slave status\\G | 6 | system user | | NULL | Connect | 22004248 | Waiting for master to send event | NULL | | 7 | system user | | NULL | Connect | 16 | Has read all relay log;** Read_Master_Log_Pos: 445167889 Exec_Master_Log_Pos: 445167889 Seconds_Behind_Master: 0 #这时有活跃SQL了，Time值是和 Seconds_Behind_Master 一样，即SQL线程比IO线程“慢”了1秒 mysql> show processlist; show slave status\\G | 6 | system user | | NULL | Connect | 22004252 | Waiting for master to send event | NULL | | 7 | system user | | floweradmin | Connect | 1 | Updating | update ** Read_Master_Log_Pos: 445182239 Exec_Master_Log_Pos: 445175263 Seconds_Behind_Master: 1 #和上面一样 mysql> show processlist; show slave status\\G | 6 | system user | | NULL | Connect | 22004254 | Waiting for master to send event | NULL | | 7 | system user | | floweradmin | Connect | 1 | Updating | update ** Read_Master_Log_Pos: 445207174 Exec_Master_Log_Pos: 445196837 Seconds_Behind_Master: 1 最后我们如何正确判断SLAVE的延迟情况： 首先看 Relay_Master_Log_File 和 Master_Log_File 是否有差异； 如果Relay_Master_Log_File 和 Master_Log_File 是一样的话，再来看Exec_Master_Log_Pos 和 Read_Master_Log_Pos 的差异，对比SQL线程比IO线程慢了多少个binlog事件； 如果Relay_Master_Log_File 和 Master_Log_File 不一样，那说明延迟可能较大，需要从MASTER上取得binlog status，判断当前的binlog和MASTER上的差距； 因此，相对更加严谨的做法是： 在第三方监控节点上，对MASTER和SLAVE同时发起SHOW BINARY LOGS和SHOW SLAVE STATUS\\G的请求，最后判断二者binlog的差异，以及 Exec_Master_Log_Pos 和 Read_Master_Log_Pos 的差异。 例如： 在MASTER上执行SHOW BINARY LOGS 的结果是： +------------------+--------------+ | Log_name | File_size | +------------------+--------------+ | mysql-bin.000009 | 1073742063 | | mysql-bin.000010 | 107374193 | +------------------+--------------+ 而在SLAVE上执行SHOW SLAVE STATUS\\G 的结果是： Master_Log_File: mysql-bin.000009 Read_Master_Log_Pos: 668711237 Relay_Master_Log_File: mysql-bin.000009 Slave_IO_Running: Yes Slave_SQL_Running: Yes *** Exec_Master_Log_Pos: 654409041 *** Seconds_Behind_Master: 3296 *** 这时候，SLAVE实际的延迟应该是： mysql-bin.000009 这个binlog中的binlog position 1073742063 和 SLAVE上读取到的binlog position之间的差异延迟，即： 1073742063 - 654409041 = 419333022 个binlog event 并且还要加上 mysql-bin.000010这个binlog已经产生的107374193个binlog event，共 107374193 + 419333022 = 526707215 个binlog event Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 07:10:06 "},"fulu.html":{"url":"fulu.html","title":"附录","keywords":"","body":"下面的附录为一些杂项。。。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-27 11:21:47 "},"f_lvsvsnginxvshaproxy.html":{"url":"f_lvsvsnginxvshaproxy.html","title":"附录1-三大软负载均衡器对比","keywords":"","body":" 一、LVS LVS优缺点 二、Ngnix nginx优缺点 三、HAProxy haproxy优缺点 四、三大主流软件负载均衡器适用业务场景： 衡量负载均衡器好坏的几个重要因素： 负载均衡能力： Nginx和LVS对比的总结 现在对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术 一、LVS 抗负载能力强。抗负载能力强、性能高，能达到F5硬件的60%；对内存和cpu资源消耗比较低 工作在网络4层，通过vrrp协议转发（仅作分发之用），具体的流量由linux内核处理，因此没有流量的产生。 稳定性、可靠性好，自身有完美的热备方案；（如：LVS+Keepalived） 应用范围比较广，可以对所有应用做负载均衡； 不支持正则处理，不能做动静分离。 支持负载均衡算法：rr（轮循）、wrr（带权轮循）、lc（最小连接）、wlc（权重最小连接） 配置复杂，对网络依赖比较大，稳定性很高。 LVS优缺点 优点： 负载能力强。工作在4层，内存、cpu消耗低 配置低、减少人为错误 应用面广，几乎可以为所有应用提供负载均衡 缺点： 不支持正则表达式，不能实现动静分离 不支持url健康检查 二、Ngnix 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构； Nginx对网络的依赖比较小，理论上能ping通就就能进行负载功能； Nginx安装和配置比较简单，测试起来比较方便； 也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发； 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。 Nginx对请求的异步处理可以帮助节点服务器减轻负载； Nginx仅能支持http、https和Email协议，这样就在适用范围较小。 不支持Session的直接保持，但能通过ip_hash来解决。、对Big request header的支持不是很好， 支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、Ip-hash（Ip哈希） Nginx还能做Web服务器即Cache功能。 nginx优缺点 优点： 工作在七层， 正则表达式比HAproxy强大 并发量可以达到几万次 nginx还可以作为web服务器使用 缺点： 仅支持http、https、mail协议，应用面小 监控检查仅通过端口，无法使用url检查 三、HAProxy 支持两种代理模式：TCP（四层）和HTTP（七层），支持虚拟主机； 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作 支持url检测后端的服务器出问题的检测会有很好的帮助。 更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现 单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。 HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。 支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie） 不能做Web服务器即Cache。 haproxy优缺点 优点： 可以通过url进行健康检查 效率、负载均衡速度、高于Nginx、低于lvs HAproxy支持TCP，可以对mysql进行负载均衡 调度算法丰富 缺点： 正则弱于Nginx 日志依赖于syslogd，不支持apache日志 四、三大主流软件负载均衡器适用业务场景： 网站建设初期，可以选用Nigix/HAproxy作为反向代理负载均衡（或者流量不大都可以不选用负载均衡），因为其配置简单，性能也能满足一般的业务场景。如果考虑到负载均衡器是有单点问题，可以采用Nginx+Keepalived/HAproxy+Keepalived避免负载均衡器自身的单点问题。 网站并发达到一定程度之后，为了提高稳定性和转发效率，可以使用LVS、毕竟LVS比Nginx/HAproxy要更稳定，转发效率也更高。不过维护LVS对维护人员的要求也会更高，投入成本也更大。 注：Niginx与Haproxy比较：Niginx支持七层、用户量最大，稳定性比较可靠。Haproxy支持四层和七层，支持更多的负载均衡算法，支持session保存等。具体选型看使用场景，目前来说Haproxy由于弥补了一些Niginx的缺点用户量也不断在提升。 衡量负载均衡器好坏的几个重要因素： 会话率 ：单位时间内的处理的请求数 会话并发能力：并发处理能力 数据率：处理数据能力 经过官方测试统计，haproxy 单位时间处理的最大请求数为20000个，可以同时维护40000-50000个并发连接，最大数据处理能力为10Gbps。综合上述，haproxy是性能优越的负载均衡、反向代理服务器。 负载均衡能力： LVS>HAproxy>Nginx 不选择LVS原因： 1.lvs不支持正则表达式，不能实现html网页和php网页分离 2.不支持url健康检查 不选nginx原因： 1.应用面小，不可以对mysql进行负载均衡 2.无法url检查 Nginx和LVS对比的总结 Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所以Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，触碰多了，人为出问题的几率也就会大。 Nginx对网络稳定性的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，这是Nginx的一大优势！Nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。 Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了；LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的。 Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。 Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相当多的资源占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。 Nginx能支持http、https和email（email的功能比较少用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得具体分析，如果是比较小的网站（日PV小于1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS。 现在对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术 第1阶段：利用Nginx或HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择。 第2阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择，Array的应用交付功能非常强大，本人在某项目中使用过，性价比也远高于F5，商用首选！但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。 第3阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer。 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:47:35 "},"f_mysql5.7.html":{"url":"f_mysql5.7.html","title":"附录2-MySQL5.7新特性","keywords":"","body":" Replication InnoDB Optimizer Security Performance Schema GIS Triggers Partitioning SYS (new) JSON (new) Client Programs libmysqlclient Building Misc 参考： http://www.thecompletelistoffeatures.com/ Replication Multi source replication [1] Online GTID migration path [1 2 3] Improved semi-sync performance [1 2] Loss-less semi-sync replication [1 2] Semi-sync can now wait for a configurable number of slaves [1] Intra-schema parallel replication [1] Ability to tune group commit via binlog_group_commit_sync_delay and binlog_group_commit_sync_no_delay_count options. [1 2] Non-blocking SHOW SLAVE STATUS [1 2] Online CHANGE REPLICATION FILTER [1] Online CHANGE MASTER TO without stopping SQL thread [1] Multi-threaded slave ordered commits (Sequential Consistency) [1] Support SLAVE_TRANSACTION_RETRIES in multi-threaded slave mode [1] A WAIT_FOR_EXECUTED_GTID_SET function has been introduced [1 2] Optimize GTIDs for Passive Slaves [1 2] GTID Replication no longer requires log-slave-updates be enabled XA Support when the binary log is turned on [1] GTIDs in the OK packet [1] Better synchronization between dump and user threads when racing for the binlog [1] Improved memory management of Binlog_sender [1] Option to suppress \"unsafe for binlog\" messages in error log [1] Defaults change: binlog_format=ROW Defaults change: sync_binlog=1 Defaults change: binlog_gtid_simple_recovery=1 Defaults change: binlog_error_action=ABORT_SERVER Defaults change: slave_net_timeout=60 InnoDB Online buffer pool resize [1] Improved crash recovery performance [1] Improved read-only transaction scalability [1 2 3 4] Improved read-write transaction scalability [1 2 3 4] Several optimizations for high performance temporary tables [1 2 3 4 5] ALTER TABLE RENAME INDEX only requires meta-data change [1] Increasing VARCHAR size only requires meta-data change [1] ALTER TABLE performance improved [1 2] Multiple page_cleaner threads [1] Optimized buffer pool flushing [1] New innodb_log_checksum_algorithm option [1] Improved NUMA support [1] General Tablespace support [1] Transparent Page Compression [1] innodb_log_write_ahead_size introduced to address potential 'read-on-write' with redo logs [1] Fulltext indexes now support pluggable parsers [1] Support for ngram and MeCab full-text parser plugins [1 2] Fulltext search optimizations [1] Buffer pool dump now supports innodb_buffer_pool_dump_pct [1] The doublewrite buffer is now disabled on filesystems that supports atomic writes (aka Fusion-io support) [1] Page fill factor is now configurable [1] Support for 32K and 64K pages [1] Online undo log truncation [1] Update_time meta data is now updated [1] TRUNCATE TABLE is now atomic [1] Memcached API performance improvements [1] Adaptive hash scalability improvements [1] InnoDB now implements information_schema.files [1] Legacy InnoDB monitor tables have been removed or replaced by global configuration settings InnoDB default row format now configurable [1] InnoDB now drops tables in a background thread [1] InnoDB tmpdir is now configurable [1] InnoDB MERGE_THRESHOLD is now configurable [1] InnoDB page_cleaner threads get priority using setpriority()[1] Defaults change: innodb_file_format=Barracuda Defaults change: innodb_large_prefix=1 Defaults change: innodb_page_cleaners=4 Defaults change: innodb_purge_threads=4 Defaults change: innodb_buffer_pool_dump_at_shutdown=1 Defaults change: innodb_buffer_pool_load_at_startup=1 Defaults change: innodb_buffer_pool_dump_pct=25 Defaults change: innodb_strict_mode=1 Defaults change: innodb_checksum_algorithm=crc32 Defaults change: innodb_default_row_format=DYNAMICOptimizer Improved optimizer cost model, leading to more consistently better query plans [1 2 3 4] Optimizer cost constants are now configurable on a global or per engine basis [1 2] Query parser has been refactored and improved [1] EXPLAIN FOR CONNECTION [1] UNION ALL does not use a temporary table [1 2 3 4] Filesort is now optimized to pack values [1] Subqueries in FROM clause can now be handled same as a view (derived_merge) [1] Queries using row value constructors are now optimized [1 2] Optimizer now supports a new condition filtering optimization [1 2] EXPLAIN FORMAT=JSON now shows cost information [1] Support for STORED and VIRTUAL generated columns (aka functional indexes) [1] Prepared statements refactored internally and performance improved [1 2] New query hints using comment-like /+ / syntax [1] Server-side query rewrite framework [1] ONLY_FULL_GROUP_BY now more standards compliant [1] Support for gb18030 character set [1] Improvements to Dynamic Range access [1] Memory used by the range optimizer is now configurable [1] Defaults change: internal_tmp_disk_storage_engine=INNODB [1] Defaults change: eq_range_index_dive_limit=200 Defaults change: sql_mode=ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES, NO_ZERO_IN_DATE, NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO, NO_AUTO_CREATE_USER, NO_ENGINE_SUBSTITUTION Defaults change: optimizer_switch=condition_fanout_filter=on, derived_merge=on Defaults change: EXTENDED and PARTITIONS keywords for EXPLAIN enabled by defaultSecurity Username size increased to 32 characters [1] Support for IF [NOT] EXISTS clause in CREATE/DROP USER [1] Server option to require secure transport [1] Support for multiple AES Encryption modes [1 2] Support for TLSv1.2 (with OpenSSL) and TLSv1.1 (with YaSSL) [1 2] Support to LOCK/UNLOCK user accounts [1 2] Support for password expiration policy [1 2] Password strength enforcement test database no longer created on installation Anonymous users no longer created on installation Random password generated by default on installation New ALTER USER command SET password='' now accepts a password instead of hash Server now generates SSL keys by default Insecure old_password hash removed [1] Ability to create utility users for stored programs that can not login [1] mysql.user.password field renamed as authentication_string to better describe its current usage. Support for tablespace encryption [1]Performance Schema Scalable memory allocation [1] Overhead has been reduced in client connect/disconnect phases Memory footprint has been reduced pfs_lock implementation has been improved Table IO statistics are now batched for improved performance Memory usage instrumentation Stored programs instrumentation Replication slave instrumentation Metadata Locking (MDL) Instrumentation Transaction instrumentation Prepared Statement instrumentation Stage Progress instrumentation SX-lock and rw_lock instrumentation Thread status and variables Defaults change: performance-schema-consumer-events_statements_history=ONGIS InnoDB supports indexing of spatial datatypes [1] Consistent naming scheme for GIS functions [1] GIS has been refactored internally and is now based on Boost Geometry [1] Geohash functions [1 2] GeoJSON functions [1 2] Functions: ST_Distance_Sphere, ST_MakeEnvelope, ST_IsValid, ST_Validate, ST_Simplify, ST_Buffer and ST_IsSimple [1 2]Triggers Multiple triggers per event per table [1] BEFORE Triggers are not processed for NOT NULL columns [1]Partitioning Index condition pushdown optimization now supported HANDLER command is now supported WITHOUT VALIDATION option now supported for ALTER TABLE ... EXCHANGE PARTITION Support for Transportable Tablespaces Partitioning is now storage-engine native for InnoDBSYS (new) SYS schema bundled by default [1 2] 100 new views, 21 new stored functions and 26 new stored procedures to help understand and interact with Performance Schema and Information Schema [1]JSON (new) Native JSON Data Type [1] JSON Comparator Short-hand JSON_EXTRACT operator (field->\"json_path\") [1] New Document Store (5.7.12) Functions: JSON_ARRAY, JSON_MERGE, JSON_OBJECT for creating JSON values [1] Functions: JSON_CONTAINS, JSON_CONTAINS_PATH, JSON_EXTRACT, JSON_KEYS, JSON_SEARCH for searching JSON values [1] Functions: JSON_ARRAY_APPEND, JSON_ARRAY_INSERT, JSON_INSERT, JSON_QUOTE, JSON_REMOVE, JSON_REPLACE, JSON_UNSET, JSON_UNQUOTE to modify JSON values [1] Functions: JSON_DEPTH, JSON_LENGTH, JSON_TYPE, JSON_VALID to return JSON value attributes [1]Client Programs New mysqlpump utility [1] The mysql client now supports Ctrl+C to clear statement buffer rewrite-db option added to mysqlbinlog [1 2] New mysql_ssl_rsa_setup utility to help set up SSL [1] SSL support added to mysqlbinlog Idempotent mode added to mysqlbinlog Client --ssl changed to now force SSL Enhancements to the innochecksum utility Removal of several outdated/unsafe command line utilities [1] Many Perl command line clients converted to C++ Client Side Protocol Tracing Client API method to reset connection New MySQL Shell (mysqlsh) (separate download)libmysqlclient Restricted export functions to documented MySQL C API Added pkg-config support Removed _r symlinks Changed so version to 20 (from 18)Building Compiler switched to GCC on Solaris MySQL now compiles with Bison 3 (* change also backported) CMake now used to compile on all platforms Unneeded CMake checks have been removed (and unused macros removed from source files) Build support for gcc, clang and MS StudioMisc Server new connection throughput improved considerably [1] mysql_install_db replaced by mysqld --initialize [1] Native support for syslog [1 2] Native support for systemd disabled_storage_engines option allows a block list of engines SET GLOBAL offline_mode=1 [1 2] super_read_only option [1] Detect transaction boundaries Server version token and check [1 SELECT GET_LOCK() can now acquire multiple locks [1 2] Configurable maximum statement execution time on a global and per query basis [1 2] Better handling of connection id rollover DTrace support [1] More consistent IGNORE clause and STRICT mode A number of tables in the mysql schema have moved from MyISAM to InnoDB Server error log format improved to be consistent Extract query digest moved from performance_schema into the server directly Improved scalability of meta data locking Increased control over error log verbosity Stacked Diagnostic Areas The server now supports a \"SHUTDOWN\" command Removed support for custom atomics implementation Removed \"unique option prefix support\" from server and utilities, which allowed options to be configured using multiple names. Removed unsafe ALTER IGNORE TABLE functionality. Syntax remains for compatibility Removed unsafe INSERT DELAYED functionality. Syntax remains for compatibility Removed of outdated sql-bench scripts in distributions Removal of ambiguous YEAR(2) datatype Defaults change: log_warnings=2 Defaults change: table_open_cache_instances=16 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:47:43 "},"f_sampleschema.html":{"url":"f_sampleschema.html","title":"附录3-MySQL的sample数据库安装部署","keywords":"","body":"sample数据库类似Oracle安装时候提供的sample。将最新的dump文件从github上拉下来 [root@nazeebo softdb]# git clone https://github.com/datacharmer/test_db.git Cloning into 'test_db'... remote: Counting objects: 102, done. remote: Total 102 (delta 0), reused 0 (delta 0), pack-reused 102 Receiving objects: 100% (102/102), 68.81 MiB | 63.00 KiB/s, done. Resolving deltas: 100% (54/54), done. [root@nazeebo softdb]# [root@nazeebo softdb]# [root@nazeebo softdb]# [root@nazeebo softdb]# [root@nazeebo softdb]# pwd /softdb [root@nazeebo softdb]# ls dbt2-0.37.50.15.tar.gz sysbench-0.4.12.14 sysbench-0.4.12.14.tar.gz test_db [root@nazeebo softdb]# cd test_db/ [root@nazeebo test_db]# ll total 168340 -rw-r--r-- 1 root root 964 Jun 22 14:24 Changelog -rw-r--r-- 1 root root 7948 Jun 22 14:24 employees_partitioned_5.1.sql -rw-r--r-- 1 root root 6276 Jun 22 14:24 employees_partitioned.sql -rw-r--r-- 1 root root 4193 Jun 22 14:24 employees.sql drwxr-xr-x 2 root root 4096 Jun 22 14:24 images -rw-r--r-- 1 root root 250 Jun 22 14:24 load_departments.dump -rw-r--r-- 1 root root 14159880 Jun 22 14:24 load_dept_emp.dump -rw-r--r-- 1 root root 1090 Jun 22 14:24 load_dept_manager.dump -rw-r--r-- 1 root root 17722832 Jun 22 14:24 load_employees.dump -rw-r--r-- 1 root root 39806034 Jun 22 14:24 load_salaries1.dump -rw-r--r-- 1 root root 39805981 Jun 22 14:24 load_salaries2.dump -rw-r--r-- 1 root root 39080916 Jun 22 14:24 load_salaries3.dump -rw-r--r-- 1 root root 21708736 Jun 22 14:24 load_titles.dump -rw-r--r-- 1 root root 4568 Jun 22 14:24 objects.sql -rw-r--r-- 1 root root 4009 Jun 22 14:24 README.md drwxr-xr-x 2 root root 4096 Jun 22 14:24 sakila -rw-r--r-- 1 root root 272 Jun 22 14:24 show_elapsed.sql -rwxr-xr-x 1 root root 1800 Jun 22 14:24 sql_test.sh -rw-r--r-- 1 root root 4878 Jun 22 14:24 test_employees_md5.sql -rw-r--r-- 1 root root 4882 Jun 22 14:24 test_employees_sha.sql 导入 [root@nazeebo test_db]# mysql -uroot -p123456 验证： [root@nazeebo test_db]# time mysql -uroot -p -t 验证2： mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | employees | | mysql | | performance_schema | | sys | | test | +--------------------+ 6 rows in set (0.00 sec) mysql> use employees Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> show tables; +----------------------+ | Tables_in_employees | +----------------------+ | current_dept_emp | | departments | | dept_emp | | dept_emp_latest_date | | dept_manager | | employees | | salaries | | titles | +----------------------+ 8 rows in set (0.00 sec) 相关的ER图 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 07:17:09 "},"f_youhuakuangjia.html":{"url":"f_youhuakuangjia.html","title":"附录4-MySQL优化框架","keywords":"","body":"MySQL优化框架 SQL语句优化 索引优化 数据库结构优化 InnoDB表优化 MyISAM表优化 Memory表优化 理解查询执行计划 缓冲和缓存 锁优化 MySQL服务器优化 性能评估 MySQL优化内幕 MySQL优化需要在三个不同层次上协调进行：MySQL级别、OS级别和硬件级别。MySQL级别的优化包括表优化、查询优化和MySQL服务器配置优化等，而MySQL的各种数据结构又最终作用于OS直至硬件设备，因此还需要了解每种结构对OS级别的资源的需要并最终导致的CPU和I/O操作等，并在此基础上将CPU及I/O操作需要尽量降低以提升其效率。 数据库层面的优化着眼点： 1、是否正确设定了表结构的相关属性，尤其是每个字段的字段类型是否为最佳。同时，是否为特定类型的工作组织使用了合适的表及表字段也将影响系统性能，比如，数据频繁更新的场景应该使用较多的表而每张表有着较少字段的结构，而复杂数据查询或分析的场景应该使用较少的表而每张表较多字段的结构等。 2、是否为高效进行查询创建了合适的索引。 3、是否为每张表选用了合适的存储引擎，并有效利用了选用的存储引擎本身的优势和特性。 4、是否基于存储引擎为表选用了合适的行格式(row format)。例如，压缩表在读写操作中会降低I/O操作需求并占用较少的磁盘空间，InnoDB支持读写应用场景中使用压缩表，但MyISAM仅能在读环境中使用压缩表。 5、是否使用了合适的锁策略，如在并发操作场景中使用共享锁，而对较高优先级的需求使用独占锁等。同时，还应该考虑存储引擎所支持的锁类型。 6、是否为InnoDB的缓冲池、MyISAM的键缓存以及MySQL查询缓存设定了合适大小的内存空间，以便能够存储频繁访问的数据且又不会引起页面换出。 操作系统和硬件级别的优化着眼点： 1、是否为实际的工作负载选定了合适的CPU，如对于CPU密集型的应用场景要使用更快速度的CPU甚至更多数量的CPU，为有着更多查询的场景使用更多的CPU等。基于多核以及超线程(hyperthreading)技术，现代的CPU架构越来越复杂、性能也越来越强了，但MySQL对多CPU架构的并行计算能力的利用仍然是有着不太尽如人意之处，尤其是较老的版本如MySQL 5.1之前的版本甚至无法发挥多CPU的优势。不过，通常需要实现的CPU性能提升目标有两类：低迟延和高吞吐量。低延迟需要更快速度的CPU，因为单个查询只能使用一颗；而需要同时运行许多查询的场景，多CPU更能提供更好的吞吐能力，然而其能否奏效还依赖于实际工作场景，因为MySQL尚不能高效的运行于多CPU，并且其对CPU数量的支持也有着限制。一般来说，较新的版本可以支持16至24颗CPU甚至更多。 2、是否有着合适大小的物理内存，并通过合理的配置平衡内存和磁盘资源，降低甚至避免磁盘I/O。现代的程序设计为提高性能通常都会基于局部性原理使用到缓存技术，这对于频繁操作数据的数据库系统来说尤其如此——有着良好设计的数据库缓存通常比针对通用任务的操作系统的缓存效率更高。缓存可以有效地延迟写入、优化写入，但并能消除写入，并综合考虑存储空间的可扩展性等，为业务选择合理的外部存储设备也是非常重要的工作。 3、是否选择了合适的网络设备并正确地配置了网络对整体系统系统也有着重大影响。延迟和带宽是网络连接的限制性因素，而常见的网络问题如丢包等，即是很小的丢包率也会赞成性能的显著下降。而更重要的还有按需调整系统中关网络方面的设置，以高效处理大量的连接和小查询。 4、是否基于操作系统选择了适用的文件系统。实际测试表明大部分文件系统的性能都非常接近，因此，为了性能而苦选文件系统并不划算。但考虑到文件系统的修复能力，应该使用日志文件系统如ext3、ext4、XFS等。同时，关闭文件系统的某些特性如访问时间和预读行为，并选择合理的磁盘调度器通常都会给性能提升带来帮助。 5、MySQL为响应每个用户连接使用一个单独的线程，再加内部使用的线程、特殊目的线程以及其它任何由存储引擎创建的线程等，MySQL需要对这些大量线程进行有效管理。Linux系统上的NPTL线程库更为轻量级也更有效率。MySQL 5.5引入了线程池插件，但其效用尚不明朗。 使用InnoDB存储引擎最佳实践： 1、基于MySQL查询语句中最常用的字段或字段组合创建主键，如果没有合适的主键也最好使用AUTO_INCRMENT类型的某字段为主键。 2、根据需要考虑使用多表查询，将这些表通过外键建立约束关系。 3、关闭autocommit。 4、使用事务(START TRANSACTION和COMMIT语句)组合相关的修改操作或一个整体的工作单元，当然也不应该创建过大的执行单元。 5、停止使用LOCK TABLES语句，InnoDB可以高效地处理来自多个会话的并发读写请求。如果需要在一系列的行上获取独占访问权限，可以使用SELECT ... FOR UPDATE锁定仅需要更新的行。 6、启用innodb_file_per_table选项，将各表的数据和索引分别进行存放。 7、评估数据和访问模式是否能从InnoDB的表压缩功能中受益(在创建表时使用ROW_FORMAT=COMPRESSED选项)，如果可以，则应该启用压缩功能。 EXPLAIN语句解析： id:SELECT语句的标识符，一般为数字，表示对应的SELECT语句在原始语句中的位置。没有子查询或联合的整个查询只有一个SELECT语句，因此其id通常为1。在联合或子查询语句中，内层的SELECT语句通常按它们在原始语句中的次序进行编号。但UNION操作通常最后会有一个id为NULL的行，因为UNION的结果通常保存至临时表中，而MySQL需要到此临时表中取得结果。 select_type: 即SELECT类型，有如下值列表： SIMPLE：简单查询，即没有使用联合或子查询； PRIMARY：UNION的最外围的查询或者最先进行的查询； UNION：相对于PRIMARY，为联合查询的第二个及以后的查询； DEPENDENT UNION：与UNION相同，但其位于联合子查询中(即UNION查询本身是子查询)； UNION RESULT：UNION的执行结果； SUBQUERY：非从属子查询，优化器通常认为其只需要运行一次； DEPENDENT SUBQUERY：从属子查询，优化器认为需要为外围的查询的每一行运行一次，如用于IN操作符中的子查询； DERIVED：用于FROM子句的子查询，即派生表查询； table: 输出信息所关系到的表的表名，也有可能会显示为如下格式： ：id为M和N的查询执行联合查询后的结果； ：id为N的查询执行的结果集； type: MySQL官方手册中解释type的作用为“type of join(联结的类型)”，但其更确切的意思应该是“记录(record)访问类型”，因为其主要目的在于展示MySQL在表中找到所需行的方式。通常有如下所示的记录访问类型： system: 表中仅有一行，是const类型的一种特殊情况； const：表中至多有一个匹配的行，该行仅在查询开始时读取一次，因此，该行此字段中的值可以被优化器看作是个常量(constant)；当基于PRIMARY KEY或UNIQUE NOT NULL字段查询，且与某常量进行等值比较时其类型就为const，其执行速度非常快； eq_ref：类似于const，表中至多有一个匹配的行，但比较的数值不是某常量，而是来自于其它表；ed_ref出现在PRIMARY KEY或UNIQUE NOT NULL类型的索引完全用于联结操作中进行等值(=)比较时；这是除了system和const之外最好的访问类型； ref：查询时的索引类型不是PRIMARY KEY或UNIQUE NOT NULL导致匹配到的行可能不惟一，或者仅能用到索引的左前缀而非全部时的访问类型；ref可被用于基于索引的字段进行=或操作； fulltext：用于FULLTEXT索引中用纯文本匹配的方法来检索记录。 ref_or_null：类似于ref，但可以额外搜索NULL值； index_merge：使用“索引合并优化”的记录访问类型，相应地，其key字段(EXPLAIN的输出结果)中会出现用到的多个索引，key_len字段中会出现被使用索引的最长长度列表；将多个“范围扫描(range scan)”获取到的行进行合并成一个结果集的操作即索引合并(index merge)。 unique_subquery：用于IN比较操作符中的子查询中进行的“键值惟一”的访问类型场景中，如 value IN (SELECT primary_key FROM single_table WHERE some_expr)； index_subquery：类似于unique_subquery，但子查询中键值不惟一； range：带有范围限制的索引扫描，而非全索引扫描，它开始于索引里的某一点，返回匹配那个值的范围的行；相应地，其key字段(EXPLAIN的输出结果)中会输出所用到的索引，key_len字段中会包含用到的索引的最长部分的长度；range通常用于将索引与常量进行=、<>、>、>=、、BETWEEN或IN()类的比较操作中； index：同全表扫描(ALL)，只不过是按照索引的次序进行而不行的次序；其优点是避免了排序，但是要承担按索引次序读取整个表的开销，这意味着若是按随机次序访问行，代价将非常大； ALL：“全表扫描”的方式查找所需要的行，如果第一张表的查询类型(EXPLAIN的输出结果)为const，其性能可能不算太坏，而第一张表的查询类型为其它结果时，其性能通常会非常差； Extra: Using where：MySQL服务器将在存储引擎收到数据后进行“后过滤(post-filter)”以限定发送给下张表或客户端的行；如果WHERE条件中使用了索引列，其读取索引时就由存储引擎检查，因此，并非所有带有WHERE子句的查询都会显示“Using where”； Using index：表示所需要的数据从索引就能够全部获取到，从而不再需要从表中查询获取所需要数据，这意味着MySQL将使用覆盖索引；但如果同时还出现了Using where，则表示索引将被用于查找特定的键值； Using index for group-by：类似于Using index，它表示MySQL可仅通过索引中的数据完成GROUP BY或DISTINCT类的查询； Using filesort：表示MySQL会对结果使用一个外部索引排序，而不是从表里按索引次序来读取行； Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:48:20 "},"f_usingprofile4sql.html":{"url":"f_usingprofile4sql.html","title":"附录5-使用profile分析sql","keywords":"","body":" 一、profiler简介 二、使用 1.查看是否已经启用profile，默认是关闭的 2.启用profiling 3.使用示例 3.1 执行一个查询语句 3.2 使用show profile查询最近一条语句的执行信息 3.3 使用show profiles查看在服务器上执行语句的列表。(查询id，花费时间，语句) 3.4 使用show profile查询制定ID的执行信息。 3.5 获取 CPU 和 Block IO 的消耗 3.6 获取其他信息 一、profiler简介 MySQL 的 Query Profiler 是一个使用非常方便的 Query 诊断分析工具，通过该工具可以获取一条Query 在整个执行过程中多种资源的消耗情况，如 CPU，IO，IPC，SWAP 等，以及发生的 PAGE FAULTS，CONTEXT SWITCHE 等等，同时还能得到该 Query 执行过程中 MySQL 所调用的各个函数在源文件中的位置。 二、使用 1.查看是否已经启用profile，默认是关闭的 mysql> select @@profiling; +-------------+ | @@profiling | +-------------+ | 0 | +-------------+ 1 row in set, 1 warning (0.00 sec) 2.启用profiling 变量profiling是session变量，每次使用都需要重新启用。 mysql> set profiling = 1; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> select @@profiling; +-------------+ | @@profiling | +-------------+ | 1 | +-------------+ 1 row in set, 1 warning (0.00 sec) 3.使用示例 3.1 执行一个查询语句 为避免之前已经把 SQL 存放在 QCACHE 中， 建议在执行 SQL 时， 强制 SELECT 语句不进行 QCACHE 检测。 mysql> select sql_no_cache count(*) from user; +----------+ | count(*) | +----------+ | 5 | +----------+ 1 row in set, 1 warning (0.00 sec) 3.2 使用show profile查询最近一条语句的执行信息 mysql> show profile; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000109 | | checking permissions | 0.000009 | | Opening tables | 0.000025 | | init | 0.000020 | | System lock | 0.000022 | | optimizing | 0.000009 | | executing | 0.000010 | | end | 0.000004 | | query end | 0.000006 | | closing tables | 0.000011 | | freeing items | 0.000014 | | cleaning up | 0.000013 | +----------------------+----------+ 12 rows in set, 1 warning (0.01 sec) 3.3 使用show profiles查看在服务器上执行语句的列表。(查询id，花费时间，语句) mysql> show profiles; +----------+------------+-----------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-----------------------------------------+ | 1 | 0.00007625 | elect @@profiling | | 2 | 0.00015775 | select @@profiling | | 3 | 0.00013875 | SELECT DATABASE() | | 4 | 0.00014025 | SELECT DATABASE() | | 5 | 0.00031725 | show databases | | 6 | 0.00024500 | show tables | | 7 | 0.00025050 | select sql_no_cache count(*) from user | +----------+------------+-----------------------------------------+ 7 rows in set, 1 warning (0.00 sec) 3.4 使用show profile查询制定ID的执行信息。 这里分析ID为7的语句。（分析：select sql_no_cache count(*) from user;) mysql> show profile for query 7; +----------------------+----------+ | Status | Duration | +----------------------+----------+ | starting | 0.000109 | | checking permissions | 0.000009 | | Opening tables | 0.000025 | | init | 0.000020 | | System lock | 0.000022 | | optimizing | 0.000009 | | executing | 0.000010 | | end | 0.000004 | | query end | 0.000006 | | closing tables | 0.000011 | | freeing items | 0.000014 | | cleaning up | 0.000013 | +----------------------+----------+ 12 rows in set, 1 warning (0.00 sec) 3.5 获取 CPU 和 Block IO 的消耗 mysql> show profile block io,cpu for query 7; +----------------------+----------+----------+------------+--------------+---------------+ | Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out | +----------------------+----------+----------+------------+--------------+---------------+ | starting | 0.000109 | 0.000054 | 0.000046 | 0 | 0 | | checking permissions | 0.000009 | 0.000005 | 0.000004 | 0 | 0 | | Opening tables | 0.000025 | 0.000013 | 0.000011 | 0 | 0 | | init | 0.000020 | 0.000011 | 0.000009 | 0 | 0 | | System lock | 0.000022 | 0.000012 | 0.000010 | 0 | 0 | | optimizing | 0.000009 | 0.000005 | 0.000004 | 0 | 0 | | executing | 0.000010 | 0.000005 | 0.000005 | 0 | 0 | | end | 0.000004 | 0.000002 | 0.000002 | 0 | 0 | | query end | 0.000006 | 0.000003 | 0.000002 | 0 | 0 | | closing tables | 0.000011 | 0.000006 | 0.000005 | 0 | 0 | | freeing items | 0.000014 | 0.000007 | 0.000006 | 0 | 0 | | cleaning up | 0.000013 | 0.000007 | 0.000006 | 0 | 0 | +----------------------+----------+----------+------------+--------------+---------------+ 12 rows in set, 1 warning (0.00 sec) 3.6 获取其他信息 通过执行SHOW PROFILE *** FOR QUERY n 来获取。 参考：http://dev.mysql.com/doc/refman/5.7/en/show-profile.html。 mysql> show profile all for query 7; mysql> show profile cpu,block io,memory,swaps,context switches,source for query 6; Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:48:04 "},"f_mysqlcheck.html":{"url":"f_mysqlcheck.html","title":"附录6-mysqlcheck的使用","keywords":"","body":" 使用mysqlcheck来检查和修复, 优化表 检查表 使用 mysqlcheck 分析表 使用 mysqlcheck 优化表 使用 mysqlcheck 修复表 常用选项 使用mysqlcheck来检查和修复, 优化表 检查表 检查特定的表 mysqlcheck -c employee dept -uroot -p employee 是库名，dept是表名，还需要输入用户名和密码 检查一个库中的所有表 mysqlcheck -c employee dept -uroot -p 检查某几个库 mysqlcheck -c --databases employess mysql test -uroot -p 检查所有库中的所有表 mysqlcheck -c --all-databases -uroot -p 使用 mysqlcheck 分析表 mysqlcheck -a employee dept -uroot -p 使用 mysqlcheck 优化表 mysqlcheck -o employee dept -uroot -p 注意： OPTIMIZE TABLE运行过程中，MySQL会锁定表。 innodb的引擎应该使用其他方式来完成优化，如： //碎片整理 alter table table_name engine=innodb; //收集表的统计信息 analyze table table_name； 使用 mysqlcheck 修复表 mysqlcheck -r employee dept -uroot -p 常用选项 A, –all-databases 表示所有库 -a, –analyze 分析表 -o, –optimize 优化表 -r, –repair 修复表错误 -c, –check 检查表是否出错 –auto-repair 自动修复损坏的表 -B, –databases 选择多个库 -1, –all-in-1 Use one query per database with tables listed in a comma separated way -C, –check-only-changed 检查表最后一次检查之后的变动 -g, –check-upgrade Check for version dependent changes in the tables -F, –fast Check tables that are not closed properly –fix-db-names Fix DB names –fix-table-names Fix table names -f, –force Continue even when there is an error -e, –extended Perform extended check on a table. This will take a long time to execute. -m, –medium-check Faster than extended check option, but does most checks -q, –quick Faster than medium check option Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:47:48 "},"f_mha.html":{"url":"f_mha.html","title":"附录7-mha配置.md","keywords":"","body":" 1. 环境介绍 2. 配置步骤 2.1.配置3台MySQL服务器1主2从(基于gtid) 2.1.1 在主库上创建复制用户和管理用户: 2.1.2 在两台从库上配置主从复制 2.2 安装相应的perl包 2.2.1 在每个节点安装mha4node 2.2.2 在管理节点安装mha4manager 2.4 对从库进行设置 2.4.1 设置只读 2.4.2 relaylog的清理 2.5 mha管理节点的配置 2.5.1 节点的相关脚本配置 2.5.2 failover脚本的设置 2.5.3 sendmail脚本的设置 2.5.4 mha启动脚本 2.6 互通性和复制的验证 2.6.1 互通性的验证 2.6.2 复制正确性的验证 2.7 启动manager节点： 2.8 检查mha manager的状态： 2.9 配置VIP,添加虚拟Ip地址 3. 验证切换验证 4.节点重新上下步骤 5.其他 1. 环境介绍 ip地址 主机名 角色 192.168.0.175 nazeebo master 192.168.0.176 lowa slave 192.168.0.200 ai2018 slave + manager shell> cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 192.168.0.175 nazeebo 192.168.0.176 lowa 192.168.0.200 ai2018 2. 配置步骤 配置3台MySQL服务器1主2从(基于gtid) 在数据节点和管理节点安装相应的 mha 软件包 安装mha manager 配置ssh的互通 对从库进行一些设置:只读,relaylog清理 在管理节点配置 mha 的配置信息和脚本 添加虚拟IP 2.1.配置3台MySQL服务器1主2从(基于gtid) 2.1.1 在主库上创建复制用户和管理用户: 创建复制用户并授权 SQL> GRANT REPLICATION SLAVE ON *.* TO repluser@192.168.0.176 IDENTIFIED BY 'Oracle123'; SQL> GRANT REPLICATION SLAVE ON *.* TO repluser@192.168.0.200 IDENTIFIED BY 'Oracle123'; SQL> flush privileges; 创建管理用户并授权 SQL> grant all privileges on *.* to 'mhamon'@'192.168.0.200' identified by 'Oracle123'; SQL> flush privileges; 2.1.2 在两台从库上配置主从复制 SQL> CHANGE MASTER TO MASTER_HOST='192.168.0.175', MASTER_USER='repluser', MASTER_PASSWORD='Oracle123', MASTER_AUTO_POSITION=1; 2.2 安装相应的perl包 2.2.1 在每个节点安装mha4node [root@lowa mha4mysql-0.57]# cd mha4mysql-node-0.57 [root@lowa mha4mysql-node-0.57]# ls AUTHORS bin COPYING debian inc lib Makefile.PL MANIFEST META.yml README rpm t [root@lowa mha4mysql-node-0.57]# perl Makefile.PL *** Module::AutoInstall version 1.06 *** Checking for Perl dependencies... [Core Features] - DBI ...loaded. (1.609) - DBD::mysql ...loaded. (4.013) *** Module::AutoInstall configuration finished. Checking if your kit is complete... Looks good Writing Makefile for mha4mysql::node [root@lowa mha4mysql-node-0.57]# make && make install ... 这个安装很简单,基本不会有问题 Node工具包主要包括以下几个工具： save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用这个工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） - 2.2.2 在管理节点安装mha4manager 安装相应的perl包 [root@ai2018 mha4mysql-manager-0.57]# perl -MDBD::mysql -e \"print\\\"module installed\\n\\\"\" module installed [root@ai2018 mha4mysql-manager-0.57]# perl -Config::Tiny -e \"print\\\"module installed\\n\\\"\" Unknown Unicode option letter 'n'. [root@ai2018 mha4mysql-manager-0.57]# ls AUTHORS bin blib COPYING debian inc lib Makefile Makefile.PL MANIFEST META.yml README rpm samples t tests [root@ai2018 mha4mysql-manager-0.57]# perl Makefile.PL *** Module::AutoInstall version 1.06 *** Checking for Perl dependencies... [Core Features] - DBI ...loaded. (1.609) - DBD::mysql ...loaded. (4.013) - Time::HiRes ...loaded. (1.9721) - Config::Tiny ...missing. - Log::Dispatch ...missing. - Parallel::ForkManager ...loaded. (0.7.9) - MHA::NodeConst ...loaded. (0.57) ==> Auto-install the 2 mandatory module(s) from CPAN? [y] y *** Dependencies will be installed the next time you type 'make'. *** Module::AutoInstall configuration finished. Warning: prerequisite Config::Tiny 0 not found. Warning: prerequisite Log::Dispatch 0 not found. Writing Makefile for mha4mysql::manager 这儿遇到了一些问题,manager需要依赖一些perl的包。先是采用yum的方式进行perl相关包的安装,结果不行,后来又把rpm下载下来安装,也不行.. yum install -y perl-DBD-MySQL.x86_64 \\ perl-DBI.x86_64 perl-ExtUtils-CBuilder \\ perl-ExtUtils-MakeMaker perl-CPAN.x86_64 \\ perl-Mail-Sender perl-Log-Dispatch 最后耍了个赖,采用cpanm来进行安装. 安装mha4manager [root@ai2018 mha4mysql-manager-0.57]# pwd /softdb/mha4mysql-0.57/mha4mysql-manager-0.57 [root@ai2018 mha4mysql-manager-0.57]# ls AUTHORS bin blib COPYING debian inc lib Makefile Makefile.PL MANIFEST META.yml README rpm samples t tests [root@ai2018 mha4mysql-manager-0.57]# perl Makefile.PL *** Module::AutoInstall version 1.06 *** Checking for Perl dependencies... [Core Features] - DBI ...loaded. (1.609) - DBD::mysql ...loaded. (4.013) - Time::HiRes ...loaded. (1.9721) - Config::Tiny ...loaded. (2.23) - Log::Dispatch ...loaded. (2.67) - Parallel::ForkManager ...loaded. (0.7.9) - MHA::NodeConst ...loaded. (0.57) *** Module::AutoInstall configuration finished. Generating a Unix-style Makefile Writing Makefile for mha4mysql::manager Writing MYMETA.yml and MYMETA.json [root@ai2018 mha4mysql-manager-0.57]# make && make install ... ... Appending installation info to /usr/lib64/perl5/perllocal.pod manager工具包主要包括以下几个工具： masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况 masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态 masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） masterha_conf_host 添加或删除配置的server信息 2.3 配置ssh互通 采用ssh-copy-id是最方便的手段,如果OS上面没有这个命令,可以先用 yum install openssl/openssl-client 来进行安装 shell> ssh-keygen shell> ssh-copy-id -i /root/.ssh/id_rsa.pub \"-p 10022 root@192.168.0.175\" shell> ssh-copy-id -i /root/.ssh/id_rsa.pub \"-p 10022 root@192.168.0.176\" shell> ssh-copy-id -i /root/.ssh/id_rsa.pub \"-p 10022 root@192.168.0.200\" 或者修改全局的 vim /etc/ssh/ssh_config Port 10022 2.4 对从库进行设置 2.4.1 设置只读 将两台slave服务器设置read_only 从库对外提供读服务，只所以没有写进配置文件，是因为随时slave会提升为master 在两个从库上执行 shell> mysql -uroot -p -e 'set global read_only=1' 2.4.2 relaylog的清理 mha在发生切换的过程中，从库的恢复过程会依赖于relay log的相关信息，所以这里要将relay log的自动清除设置为OFF。在默认情况下，从服务器上的中继日志会在SQL线程执行完毕后被自动删除。 在两个从库上执行 shell> mysql -uroot -p -e 'set global relay_log_purge=0' 2.5 mha管理节点的配置 先来个目录结构 [root@ai2018 mha]# tree /etc/mha /etc/mha ├── app1 │ ├── app1.cnf │ ├── app1.log #manager的日志 │ ├── app1.master_status.health #master的健康检查状态日志 │ └── app2.cnf #备份的app1.cnf ├── bin │ └── mhaCli.sh #mha启动脚本 └── script ├── master_ip_failover #自动切换的脚本 └── sendEmail #发送邮件的脚本,在这儿没有需求,所以没有配置 3 directories, 7 files 2.5.1 节点的相关脚本配置 app1.cnf [server default] manager_log=/etc/mha/app1/app1.log # 设置manager的日志 manager_workdir=/etc/mha/app1/ # 设置manager的工作目录 master_binlog_dir=/u01/mysql/mysql_data # 设置master 保存binlog的位置，以便MHA可以找到master的日志，这里就是mysql的数据目录 master_ip_failover_script=/etc/mha/script/master_ip_failover # 设置自动failover时候的切换脚本 master_ip_online_change_script=/etc/mha/script/master_ip_failover #设置手动failover时候的切换脚本 report_script=/etc/mha/script/sendEmail # 设置发生切换后发送的报警的脚本 remote_workdir=/tmp # 设置远端mysql在发生切换时binlog的保存位置 ping_interval=3 #设置监控主库，发送ping包的时间间隔，默认是3秒，尝试三次没有回应的时候自动进行railover user=mhamon # 设置监控用户 password=Oracle123 # 设置监控用户的密码 repl_user=repluser # 设置复制账号 repl_password=Oracle123 # 设置复制账号的密码 ssh_user=root # 设置ssh的登陆用户 ssh_port=10022 # 设置ssh的端口号 secondary_check_script=/usr/local/bin/masterha_secondary_check -s slave87 -s slave88 [server1] hostname=192.168.0.175 port=3306 master_binlog_dir=/u01/mysql/mysql_data [server2] hostname=192.168.0.176 port=3306 master_binlog_dir=/u01/mysql/mysql_data [server3] hostname=192.168.0.200 port=3306 master_binlog_dir=/u01/mysql/mysql_data 2.5.2 failover脚本的设置 #!/usr/bin/env perl use strict; use warnings FATAL => 'all'; use Getopt::Long; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port ); my $vip = '192.168.0.177/24'; # 设置VIP my $key = '88'; # 此处代表 绑定在 eth2:88上 my $ssh_start_vip = \"/sbin/ifconfig eth2:$key $vip\"; # 开启VIP my $ssh_stop_vip = \"/sbin/ifconfig eth2:$key down\"; # 关闭VIP GetOptions( 'command=s' => \\$command, 'ssh_user=s' => \\$ssh_user, 'orig_master_host=s' => \\$orig_master_host, 'orig_master_ip=s' => \\$orig_master_ip, 'orig_master_port=i' => \\$orig_master_port, 'new_master_host=s' => \\$new_master_host, 'new_master_ip=s' => \\$new_master_ip, 'new_master_port=i' => \\$new_master_port, ); exit &main(); sub main { print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) { my $exit_code = 1; eval { print \"Disabling the VIP on old master: $orig_master_host \\n\"; &stop_vip(); $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; &start_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; exit 0; } else { &usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } sub stop_vip() { return 0 unless ($ssh_user); `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_i p=ip --new_master_port=port\\n\"; } 2.5.3 sendmail脚本的设置 没有需求,找了个sample作为参考 #!/usr/bin/perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL => 'all'; use Mail::Sender; use Getopt::Long; #new_master_host and new_slave_hosts are set only when recovering master succeeded my ( $dead_master_host, $new_master_host, $new_slave_hosts, $subject, $body ); my $smtp='smtp.163.com'; my $mail_from='xxx@163.com'; my $mail_user='xxx@163.com'; my $mail_pass='xxxxxx'; my $mail_to=['xxx@xxx.cn','xxxxx@xxx.cn']; GetOptions( 'orig_master_host=s' => \\$dead_master_host, 'new_master_host=s' => \\$new_master_host, 'new_slave_hosts=s' => \\$new_slave_hosts, 'subject=s' => \\$subject, 'body=s' => \\$body, ); mailToContacts($smtp,$mail_from,$mail_user,$mail_pass,$mail_to,$subject,$body); sub mailToContacts { my ( $smtp, $mail_from, $user, $passwd, $mail_to, $subject, $msg ) = @_; open my $DEBUG, \"> /tmp/monitormail.log\" or die \"Can't open the debug file:$!\\n\"; my $sender = new Mail::Sender { ctype => 'text/plain; charset=utf-8', encoding => 'utf-8', smtp => $smtp, from => $mail_from, auth => 'LOGIN', TLS_allowed => '0', authid => $user, authpwd => $passwd, to => $mail_to, subject => $subject, debug => $DEBUG }; $sender->MailMsg( { msg => $msg, debug => $DEBUG } ) or print $Mail::Sender::Error; return 1; } # Do whatever you want here exit 0; 2.5.4 mha启动脚本 # cat bin/mhaCli.sh #!/bin/bash . /etc/profile . ~/.bash_profile . ~/.bashrc run_num=$(ps -ef|grep masterha_manager |grep -v grep|wc -l) pid_file='/data/mha/app1/app1.master_status.health' start() { if [[ $run_num /data/mha/app1/app1.log 2>&1 & else echo 'mha is already running...' fi } stop() { if [[ $run_num 2.6 互通性和复制的验证 2.6.1 互通性的验证 验证方法: shell> masterha_check_ssh --conf=/etc/mha/app1/app1.cnf 报错: [root@ai2018 .ssh]# masterha_check_ssh --conf=/etc/mha/app1/app1.cnf Mon Mar 26 22:36:57 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Mon Mar 26 22:36:57 2018 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 22:36:57 2018 - [info] Reading server configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 22:36:57 2018 - [info] Starting SSH connection tests.. Mon Mar 26 22:36:58 2018 - [debug] Mon Mar 26 22:36:57 2018 - [debug] Connecting via SSH from root@192.168.0.175(192.168.0.175:10022) to root@192.168.0.176(192.168.0.176:10022).. Mon Mar 26 22:36:57 2018 - [debug] ok. Mon Mar 26 22:36:57 2018 - [debug] Connecting via SSH from root@192.168.0.175(192.168.0.175:10022) to root@192.168.0.200(192.168.0.200:10022).. Mon Mar 26 22:36:58 2018 - [debug] ok. Mon Mar 26 22:36:58 2018 - [debug] Mon Mar 26 22:36:57 2018 - [debug] Connecting via SSH from root@192.168.0.176(192.168.0.176:10022) to root@192.168.0.175(192.168.0.175:10022).. Mon Mar 26 22:36:58 2018 - [debug] ok. Mon Mar 26 22:36:58 2018 - [debug] Connecting via SSH from root@192.168.0.176(192.168.0.176:10022) to root@192.168.0.200(192.168.0.200:10022).. Mon Mar 26 22:36:58 2018 - [debug] ok. Mon Mar 26 22:36:58 2018 - [error][/usr/local/share/perl5/MHA/SSHCheck.pm, ln63] Mon Mar 26 22:36:58 2018 - [debug] Connecting via SSH from root@192.168.0.200(192.168.0.200:10022) to root@192.168.0.175(192.168.0.175:10022).. Permission denied (publickey,password,keyboard-interactive). Mon Mar 26 22:36:58 2018 - [error][/usr/local/share/perl5/MHA/SSHCheck.pm, ln111] SSH connection from root@192.168.0.200(192.168.0.200:10022) to root@192.168.0.175(192.168.0.175:10022) failed! SSH Configuration Check Failed! 正确配置后,验证应该如下: [root@ai2018 ~]# masterha_check_ssh --conf=/etc/mha/app1/app1.cnf Mon Mar 26 23:01:32 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Mon Mar 26 23:01:32 2018 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:01:32 2018 - [info] Reading server configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:01:32 2018 - [info] Starting SSH connection tests.. Mon Mar 26 23:01:33 2018 - [debug] Mon Mar 26 23:01:32 2018 - [debug] Connecting via SSH from root@192.168.0.175(192.168.0.175:10022) to root@192.168.0.176(192.168.0.176:10022).. Mon Mar 26 23:01:33 2018 - [debug] ok. Mon Mar 26 23:01:33 2018 - [debug] Connecting via SSH from root@192.168.0.175(192.168.0.175:10022) to root@192.168.0.200(192.168.0.200:10022).. Mon Mar 26 23:01:33 2018 - [debug] ok. Mon Mar 26 23:01:34 2018 - [debug] Mon Mar 26 23:01:33 2018 - [debug] Connecting via SSH from root@192.168.0.176(192.168.0.176:10022) to root@192.168.0.175(192.168.0.175:10022).. Mon Mar 26 23:01:33 2018 - [debug] ok. Mon Mar 26 23:01:33 2018 - [debug] Connecting via SSH from root@192.168.0.176(192.168.0.176:10022) to root@192.168.0.200(192.168.0.200:10022).. Mon Mar 26 23:01:33 2018 - [debug] ok. Mon Mar 26 23:01:34 2018 - [debug] Mon Mar 26 23:01:33 2018 - [debug] Connecting via SSH from root@192.168.0.200(192.168.0.200:10022) to root@192.168.0.175(192.168.0.175:10022).. Mon Mar 26 23:01:34 2018 - [debug] ok. Mon Mar 26 23:01:34 2018 - [debug] Connecting via SSH from root@192.168.0.200(192.168.0.200:10022) to root@192.168.0.176(192.168.0.176:10022).. Mon Mar 26 23:01:34 2018 - [debug] ok. Mon Mar 26 23:01:34 2018 - [info] All SSH connection tests passed successfully. 2.6.2 复制正确性的验证 报错1 [root@ai2018 app1]# masterha_check_repl --conf=/etc/mha/app1/app1.cnf Mon Mar 26 22:51:18 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Mon Mar 26 22:51:18 2018 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 22:51:18 2018 - [info] Reading server configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 22:51:18 2018 - [info] MHA::MasterMonitor version 0.57. Mon Mar 26 22:51:18 2018 - [info] GTID failover mode = 1 Mon Mar 26 22:51:18 2018 - [info] Dead Servers: Mon Mar 26 22:51:18 2018 - [info] Alive Servers: Mon Mar 26 22:51:18 2018 - [info] 192.168.0.175(192.168.0.175:3306) Mon Mar 26 22:51:18 2018 - [info] 192.168.0.176(192.168.0.176:3306) Mon Mar 26 22:51:18 2018 - [info] 192.168.0.200(192.168.0.200:3306) Mon Mar 26 22:51:18 2018 - [info] Alive Slaves: Mon Mar 26 22:51:18 2018 - [info] 192.168.0.176(192.168.0.176:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 22:51:18 2018 - [info] GTID ON Mon Mar 26 22:51:18 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 22:51:18 2018 - [info] 192.168.0.200(192.168.0.200:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 22:51:18 2018 - [info] GTID ON Mon Mar 26 22:51:18 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 22:51:18 2018 - [info] Current Alive Master: 192.168.0.175(192.168.0.175:3306) Mon Mar 26 22:51:18 2018 - [info] Checking slave configurations.. Mon Mar 26 22:51:18 2018 - [info] Checking replication filtering settings.. Mon Mar 26 22:51:18 2018 - [info] binlog_do_db= , binlog_ignore_db= Mon Mar 26 22:51:18 2018 - [info] Replication filtering check ok. Mon Mar 26 22:51:18 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln427] Error happened on checking configurations. Got MySQL error when checking replication privilege. 29: File './mysql/user.MYD' not found (Errcode: 2 - No such file or directory) query:SELECT Repl_slave_priv AS Value FROM mysql.user WHERE user = ? at /usr/local/share/perl5/MHA/Server.pm line 397 Mon Mar 26 22:51:18 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln525] Error happened on monitoring servers. Mon Mar 26 22:51:18 2018 - [info] Got exit code 1 (Not master dead). MySQL Replication Health is NOT OK! 检查过程 mysql> SELECT Repl_slave_priv AS Value FROM mysql.user WHERE user = 'repluser'; ERROR 29 (HY000): File './mysql/user.MYD' not found (Errcode: 2 - No such file or directory) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | +--------------------+ 1 row in set (0.00 sec) mysql> exit 报错2 [root@ai2018 ~]# masterha_check_repl --conf=/etc/mha/app1/app1.cnf Mon Mar 26 23:01:44 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Mon Mar 26 23:01:44 2018 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:01:44 2018 - [info] Reading server configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:01:44 2018 - [info] MHA::MasterMonitor version 0.57. Mon Mar 26 23:01:44 2018 - [info] GTID failover mode = 1 Mon Mar 26 23:01:44 2018 - [info] Dead Servers: Mon Mar 26 23:01:44 2018 - [info] Alive Servers: Mon Mar 26 23:01:44 2018 - [info] 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:01:44 2018 - [info] 192.168.0.176(192.168.0.176:3306) Mon Mar 26 23:01:44 2018 - [info] 192.168.0.200(192.168.0.200:3306) Mon Mar 26 23:01:44 2018 - [info] Alive Slaves: Mon Mar 26 23:01:44 2018 - [info] 192.168.0.176(192.168.0.176:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 23:01:44 2018 - [info] GTID ON Mon Mar 26 23:01:44 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:01:44 2018 - [info] 192.168.0.200(192.168.0.200:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 23:01:44 2018 - [info] GTID ON Mon Mar 26 23:01:44 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:01:44 2018 - [info] Current Alive Master: 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:01:44 2018 - [info] Checking slave configurations.. Mon Mar 26 23:01:44 2018 - [info] read_only=1 is not set on slave 192.168.0.200(192.168.0.200:3306). Mon Mar 26 23:01:44 2018 - [info] Checking replication filtering settings.. Mon Mar 26 23:01:44 2018 - [info] binlog_do_db= , binlog_ignore_db= Mon Mar 26 23:01:44 2018 - [info] Replication filtering check ok. Mon Mar 26 23:01:44 2018 - [info] GTID (with auto-pos) is supported. Skipping all SSH and Node package checking. Mon Mar 26 23:01:44 2018 - [info] Checking SSH publickey authentication settings on the current master.. Mon Mar 26 23:01:44 2018 - [info] HealthCheck: SSH to 192.168.0.175 is reachable. Mon Mar 26 23:01:44 2018 - [info] 192.168.0.175(192.168.0.175:3306) (current master) +--192.168.0.176(192.168.0.176:3306) +--192.168.0.200(192.168.0.200:3306) Mon Mar 26 23:01:44 2018 - [info] Checking replication health on 192.168.0.176.. Mon Mar 26 23:01:44 2018 - [info] ok. Mon Mar 26 23:01:44 2018 - [info] Checking replication health on 192.168.0.200.. Mon Mar 26 23:01:44 2018 - [info] ok. Mon Mar 26 23:01:44 2018 - [info] Checking master_ip_failover_script status: Mon Mar 26 23:01:44 2018 - [info] /etc/mha/script/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.0.175 --orig_master_ip=192.168.0.175 --orig_master_port=3306 --orig_master_ssh_port=10022 Mon Mar 26 23:01:44 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln427] Error happened on checking configurations. Can't exec \"/etc/mha/script/master_ip_failover\": Permission denied at /usr/local/share/perl5/MHA/ManagerUtil.pm line 68. Mon Mar 26 23:01:44 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln525] Error happened on monitoring servers. Mon Mar 26 23:01:44 2018 - [info] Got exit code 1 (Not master dead). MySQL Replication Health is NOT OK! Mon Mar 26 23:01:44 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln229] Failed to get master_ip_failover_script status with return code 1:0. Mon Mar 26 23:01:44 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln427] Error happened on checking configurations. at /usr/local/bin/masterha_check_repl line 48 Mon Mar 26 23:01:44 2018 - [error][/usr/local/share/perl5/MHA/MasterMonitor.pm, ln525] Error happened on monitoring servers. Mon Mar 26 23:01:44 2018 - [info] Got exit code 1 (Not master dead). MySQL Replication Health is NOT OK! 正确的设置后,验证通过应该如下: [root@ai2018 ~]# masterha_check_repl --conf=/etc/mha/app1/app1.cnf Mon Mar 26 23:02:21 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Mon Mar 26 23:02:21 2018 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:02:21 2018 - [info] Reading server configuration from /etc/mha/app1/app1.cnf.. Mon Mar 26 23:02:21 2018 - [info] MHA::MasterMonitor version 0.57. Mon Mar 26 23:02:21 2018 - [info] GTID failover mode = 1 Mon Mar 26 23:02:21 2018 - [info] Dead Servers: Mon Mar 26 23:02:21 2018 - [info] Alive Servers: Mon Mar 26 23:02:21 2018 - [info] 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:02:21 2018 - [info] 192.168.0.176(192.168.0.176:3306) Mon Mar 26 23:02:21 2018 - [info] 192.168.0.200(192.168.0.200:3306) Mon Mar 26 23:02:21 2018 - [info] Alive Slaves: Mon Mar 26 23:02:21 2018 - [info] 192.168.0.176(192.168.0.176:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 23:02:21 2018 - [info] GTID ON Mon Mar 26 23:02:21 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:02:21 2018 - [info] 192.168.0.200(192.168.0.200:3306) Version=5.7.21-log (oldest major version between slaves) log-bin:enabled Mon Mar 26 23:02:21 2018 - [info] GTID ON Mon Mar 26 23:02:21 2018 - [info] Replicating from 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:02:21 2018 - [info] Current Alive Master: 192.168.0.175(192.168.0.175:3306) Mon Mar 26 23:02:21 2018 - [info] Checking slave configurations.. Mon Mar 26 23:02:21 2018 - [info] read_only=1 is not set on slave 192.168.0.200(192.168.0.200:3306). Mon Mar 26 23:02:21 2018 - [info] Checking replication filtering settings.. Mon Mar 26 23:02:21 2018 - [info] binlog_do_db= , binlog_ignore_db= Mon Mar 26 23:02:21 2018 - [info] Replication filtering check ok. Mon Mar 26 23:02:21 2018 - [info] GTID (with auto-pos) is supported. Skipping all SSH and Node package checking. Mon Mar 26 23:02:21 2018 - [info] Checking SSH publickey authentication settings on the current master.. Mon Mar 26 23:02:21 2018 - [info] HealthCheck: SSH to 192.168.0.175 is reachable. Mon Mar 26 23:02:21 2018 - [info] 192.168.0.175(192.168.0.175:3306) (current master) +--192.168.0.176(192.168.0.176:3306) +--192.168.0.200(192.168.0.200:3306) Mon Mar 26 23:02:21 2018 - [info] Checking replication health on 192.168.0.176.. Mon Mar 26 23:02:21 2018 - [info] ok. Mon Mar 26 23:02:21 2018 - [info] Checking replication health on 192.168.0.200.. Mon Mar 26 23:02:21 2018 - [info] ok. Mon Mar 26 23:02:21 2018 - [info] Checking master_ip_failover_script status: Mon Mar 26 23:02:21 2018 - [info] /etc/mha/script/master_ip_failover --command=status --ssh_user=root --orig_master_host=192.168.0.175 --orig_master_ip=192.168.0.175 --orig_master_port=3306 --orig_master_ssh_port=10022 Unknown option: orig_master_ssh_port IN SCRIPT TEST====/sbin/ifconfig eth2:91 down==/sbin/ifconfig eth2:91 192.168.0.177/24=== Checking the Status of the script.. OK Mon Mar 26 23:02:21 2018 - [info] OK. Mon Mar 26 23:02:21 2018 - [warning] shutdown_script is not defined. Mon Mar 26 23:02:21 2018 - [info] Got exit code 0 (Not master dead). MySQL Replication Health is OK. 2.7 启动manager节点： shell> /etc/mha/bin/mhaCli.sh start 　　 2.8 检查mha manager的状态： shell> masterha_check_status --conf=/etc/mha/app1/app1.cnf 或者： /etc/mha/bin/mhaCli.sh status 2.9 配置VIP,添加虚拟Ip地址 [root@nazeebo mysql_data]# ifconfig eth2:88 192.168.0.177/24 [root@nazeebo mysql_data]# ip addr 1: lo: mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth2: mtu 1500 qdisc mq state UP qlen 1000 link/ether 00:50:56:a5:b0:38 brd ff:ff:ff:ff:ff:ff inet 192.168.0.175/24 brd 192.168.0.255 scope global eth2 inet 192.168.0.177/24 brd 192.168.0.255 scope global secondary eth2:88 inet6 fe80::250:56ff:fea5:b038/64 scope link valid_lft forever preferred_lft forever [root@nazeebo mysql_data]# 3. 验证切换验证 将master节点的数据库停掉,过一会儿看vip是否飘移到新的master的ethx上 4.节点重新上下步骤 当出问题的原master服务器175问题修复好后，此时需要重新上线主机，则可以通过以下方式： 在服务器175上搭建好mysql服务，建议和之前配置参数一致；服务器之间免密。 在现在的master或者slave使用mysqldump将数据备份，加--master-data=2 -A参数 将备份数来的数据在服务器175上进行恢复，完成后执行flush privileges刷新权限。 成后配置GTID的change master操作，start slave即可 将主机的信息添加到mha的配置文件中，以便mha manager检测到新的节点主机 使用mha的测试命令进行测试，成功则启动mha程序即可 5.其他 Copyright © suredandan 2018 all right reserved，powered by GitbookUpdateTime: 2018-11-28 06:47:39 "}}